{
  "best_metric": 0.7279029462738301,
  "best_model_checkpoint": "./results\\checkpoint-2877",
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 14385,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010427528675703858,
      "grad_norm": 5.097677230834961,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.7222,
      "step": 10
    },
    {
      "epoch": 0.020855057351407715,
      "grad_norm": 3.0158815383911133,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.687,
      "step": 20
    },
    {
      "epoch": 0.03128258602711158,
      "grad_norm": 6.171942234039307,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.7101,
      "step": 30
    },
    {
      "epoch": 0.04171011470281543,
      "grad_norm": 11.519227027893066,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.6856,
      "step": 40
    },
    {
      "epoch": 0.05213764337851929,
      "grad_norm": 5.199939250946045,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6895,
      "step": 50
    },
    {
      "epoch": 0.06256517205422316,
      "grad_norm": 7.990784168243408,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.6983,
      "step": 60
    },
    {
      "epoch": 0.072992700729927,
      "grad_norm": 6.307732105255127,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.7082,
      "step": 70
    },
    {
      "epoch": 0.08342022940563086,
      "grad_norm": 16.059253692626953,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.689,
      "step": 80
    },
    {
      "epoch": 0.09384775808133472,
      "grad_norm": 5.51369047164917,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.6893,
      "step": 90
    },
    {
      "epoch": 0.10427528675703858,
      "grad_norm": 3.7559518814086914,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6775,
      "step": 100
    },
    {
      "epoch": 0.11470281543274244,
      "grad_norm": 18.00990867614746,
      "learning_rate": 8.8e-06,
      "loss": 0.6859,
      "step": 110
    },
    {
      "epoch": 0.1251303441084463,
      "grad_norm": 2.5280532836914062,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.6938,
      "step": 120
    },
    {
      "epoch": 0.13555787278415016,
      "grad_norm": 5.867273807525635,
      "learning_rate": 1.04e-05,
      "loss": 0.6856,
      "step": 130
    },
    {
      "epoch": 0.145985401459854,
      "grad_norm": 3.529855966567993,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.69,
      "step": 140
    },
    {
      "epoch": 0.15641293013555788,
      "grad_norm": 4.827919006347656,
      "learning_rate": 1.2e-05,
      "loss": 0.694,
      "step": 150
    },
    {
      "epoch": 0.16684045881126172,
      "grad_norm": 4.311484336853027,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.7157,
      "step": 160
    },
    {
      "epoch": 0.1772679874869656,
      "grad_norm": 4.99680233001709,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.6514,
      "step": 170
    },
    {
      "epoch": 0.18769551616266944,
      "grad_norm": 6.664041519165039,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.6654,
      "step": 180
    },
    {
      "epoch": 0.1981230448383733,
      "grad_norm": 6.938549041748047,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.6884,
      "step": 190
    },
    {
      "epoch": 0.20855057351407716,
      "grad_norm": 4.084677219390869,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.6866,
      "step": 200
    },
    {
      "epoch": 0.21897810218978103,
      "grad_norm": 4.638442516326904,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.6979,
      "step": 210
    },
    {
      "epoch": 0.22940563086548488,
      "grad_norm": 4.049127101898193,
      "learning_rate": 1.76e-05,
      "loss": 0.6731,
      "step": 220
    },
    {
      "epoch": 0.23983315954118875,
      "grad_norm": 5.599887371063232,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.6457,
      "step": 230
    },
    {
      "epoch": 0.2502606882168926,
      "grad_norm": 5.792354106903076,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.6571,
      "step": 240
    },
    {
      "epoch": 0.26068821689259647,
      "grad_norm": 2.299596071243286,
      "learning_rate": 2e-05,
      "loss": 0.6908,
      "step": 250
    },
    {
      "epoch": 0.2711157455683003,
      "grad_norm": 3.6972415447235107,
      "learning_rate": 2.08e-05,
      "loss": 0.6463,
      "step": 260
    },
    {
      "epoch": 0.28154327424400416,
      "grad_norm": 5.992522239685059,
      "learning_rate": 2.1600000000000003e-05,
      "loss": 0.6483,
      "step": 270
    },
    {
      "epoch": 0.291970802919708,
      "grad_norm": 8.869311332702637,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.6193,
      "step": 280
    },
    {
      "epoch": 0.3023983315954119,
      "grad_norm": 10.445903778076172,
      "learning_rate": 2.32e-05,
      "loss": 0.6517,
      "step": 290
    },
    {
      "epoch": 0.31282586027111575,
      "grad_norm": 4.966081619262695,
      "learning_rate": 2.4e-05,
      "loss": 0.6593,
      "step": 300
    },
    {
      "epoch": 0.3232533889468196,
      "grad_norm": 6.090373516082764,
      "learning_rate": 2.4800000000000003e-05,
      "loss": 0.6492,
      "step": 310
    },
    {
      "epoch": 0.33368091762252344,
      "grad_norm": 10.858463287353516,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.6427,
      "step": 320
    },
    {
      "epoch": 0.34410844629822734,
      "grad_norm": 5.976349830627441,
      "learning_rate": 2.6400000000000005e-05,
      "loss": 0.6193,
      "step": 330
    },
    {
      "epoch": 0.3545359749739312,
      "grad_norm": 6.017703056335449,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.6284,
      "step": 340
    },
    {
      "epoch": 0.36496350364963503,
      "grad_norm": 5.016879558563232,
      "learning_rate": 2.8e-05,
      "loss": 0.5713,
      "step": 350
    },
    {
      "epoch": 0.3753910323253389,
      "grad_norm": 3.2898943424224854,
      "learning_rate": 2.8800000000000002e-05,
      "loss": 0.6226,
      "step": 360
    },
    {
      "epoch": 0.3858185610010427,
      "grad_norm": 6.4900031089782715,
      "learning_rate": 2.96e-05,
      "loss": 0.7149,
      "step": 370
    },
    {
      "epoch": 0.3962460896767466,
      "grad_norm": 4.485052585601807,
      "learning_rate": 3.0400000000000004e-05,
      "loss": 0.6047,
      "step": 380
    },
    {
      "epoch": 0.40667361835245047,
      "grad_norm": 6.553409576416016,
      "learning_rate": 3.1200000000000006e-05,
      "loss": 0.647,
      "step": 390
    },
    {
      "epoch": 0.4171011470281543,
      "grad_norm": 8.936062812805176,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.5357,
      "step": 400
    },
    {
      "epoch": 0.42752867570385816,
      "grad_norm": 7.181247234344482,
      "learning_rate": 3.28e-05,
      "loss": 0.6087,
      "step": 410
    },
    {
      "epoch": 0.43795620437956206,
      "grad_norm": 10.591719627380371,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.5446,
      "step": 420
    },
    {
      "epoch": 0.4483837330552659,
      "grad_norm": 5.043483257293701,
      "learning_rate": 3.44e-05,
      "loss": 0.6102,
      "step": 430
    },
    {
      "epoch": 0.45881126173096975,
      "grad_norm": 8.314013481140137,
      "learning_rate": 3.52e-05,
      "loss": 0.5034,
      "step": 440
    },
    {
      "epoch": 0.4692387904066736,
      "grad_norm": 6.824438095092773,
      "learning_rate": 3.6e-05,
      "loss": 0.6158,
      "step": 450
    },
    {
      "epoch": 0.4796663190823775,
      "grad_norm": 6.1703691482543945,
      "learning_rate": 3.680000000000001e-05,
      "loss": 0.6073,
      "step": 460
    },
    {
      "epoch": 0.49009384775808135,
      "grad_norm": 3.9169235229492188,
      "learning_rate": 3.76e-05,
      "loss": 0.6126,
      "step": 470
    },
    {
      "epoch": 0.5005213764337852,
      "grad_norm": 5.288728713989258,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.613,
      "step": 480
    },
    {
      "epoch": 0.5109489051094891,
      "grad_norm": 6.453596591949463,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.5298,
      "step": 490
    },
    {
      "epoch": 0.5213764337851929,
      "grad_norm": 4.911531448364258,
      "learning_rate": 4e-05,
      "loss": 0.5409,
      "step": 500
    },
    {
      "epoch": 0.5318039624608968,
      "grad_norm": 9.349991798400879,
      "learning_rate": 3.997119193374145e-05,
      "loss": 0.5635,
      "step": 510
    },
    {
      "epoch": 0.5422314911366006,
      "grad_norm": 7.569918155670166,
      "learning_rate": 3.99423838674829e-05,
      "loss": 0.6577,
      "step": 520
    },
    {
      "epoch": 0.5526590198123045,
      "grad_norm": 7.3250412940979,
      "learning_rate": 3.991357580122435e-05,
      "loss": 0.6823,
      "step": 530
    },
    {
      "epoch": 0.5630865484880083,
      "grad_norm": 4.787965297698975,
      "learning_rate": 3.98847677349658e-05,
      "loss": 0.6262,
      "step": 540
    },
    {
      "epoch": 0.5735140771637122,
      "grad_norm": 4.379210948944092,
      "learning_rate": 3.9855959668707244e-05,
      "loss": 0.584,
      "step": 550
    },
    {
      "epoch": 0.583941605839416,
      "grad_norm": 15.137112617492676,
      "learning_rate": 3.982715160244869e-05,
      "loss": 0.5813,
      "step": 560
    },
    {
      "epoch": 0.59436913451512,
      "grad_norm": 4.531854629516602,
      "learning_rate": 3.979834353619014e-05,
      "loss": 0.6152,
      "step": 570
    },
    {
      "epoch": 0.6047966631908238,
      "grad_norm": 5.5190629959106445,
      "learning_rate": 3.9769535469931584e-05,
      "loss": 0.5672,
      "step": 580
    },
    {
      "epoch": 0.6152241918665277,
      "grad_norm": 6.060771465301514,
      "learning_rate": 3.974072740367303e-05,
      "loss": 0.5489,
      "step": 590
    },
    {
      "epoch": 0.6256517205422315,
      "grad_norm": 4.839676856994629,
      "learning_rate": 3.971191933741448e-05,
      "loss": 0.6219,
      "step": 600
    },
    {
      "epoch": 0.6360792492179353,
      "grad_norm": 7.7734456062316895,
      "learning_rate": 3.9683111271155924e-05,
      "loss": 0.6086,
      "step": 610
    },
    {
      "epoch": 0.6465067778936392,
      "grad_norm": 7.059825897216797,
      "learning_rate": 3.965430320489737e-05,
      "loss": 0.6214,
      "step": 620
    },
    {
      "epoch": 0.656934306569343,
      "grad_norm": 4.145307540893555,
      "learning_rate": 3.9625495138638824e-05,
      "loss": 0.5546,
      "step": 630
    },
    {
      "epoch": 0.6673618352450469,
      "grad_norm": 8.063146591186523,
      "learning_rate": 3.959668707238027e-05,
      "loss": 0.6081,
      "step": 640
    },
    {
      "epoch": 0.6777893639207507,
      "grad_norm": 6.723316669464111,
      "learning_rate": 3.956787900612172e-05,
      "loss": 0.5706,
      "step": 650
    },
    {
      "epoch": 0.6882168925964547,
      "grad_norm": 4.10468053817749,
      "learning_rate": 3.9539070939863164e-05,
      "loss": 0.5361,
      "step": 660
    },
    {
      "epoch": 0.6986444212721585,
      "grad_norm": 5.425206661224365,
      "learning_rate": 3.951026287360461e-05,
      "loss": 0.5727,
      "step": 670
    },
    {
      "epoch": 0.7090719499478624,
      "grad_norm": 5.807816982269287,
      "learning_rate": 3.948145480734606e-05,
      "loss": 0.5823,
      "step": 680
    },
    {
      "epoch": 0.7194994786235662,
      "grad_norm": 3.667297601699829,
      "learning_rate": 3.945264674108751e-05,
      "loss": 0.5734,
      "step": 690
    },
    {
      "epoch": 0.7299270072992701,
      "grad_norm": 4.510761737823486,
      "learning_rate": 3.942383867482896e-05,
      "loss": 0.6238,
      "step": 700
    },
    {
      "epoch": 0.7403545359749739,
      "grad_norm": 7.349979400634766,
      "learning_rate": 3.9395030608570405e-05,
      "loss": 0.5042,
      "step": 710
    },
    {
      "epoch": 0.7507820646506778,
      "grad_norm": 6.627303600311279,
      "learning_rate": 3.936622254231185e-05,
      "loss": 0.6594,
      "step": 720
    },
    {
      "epoch": 0.7612095933263816,
      "grad_norm": 10.158563613891602,
      "learning_rate": 3.93374144760533e-05,
      "loss": 0.5524,
      "step": 730
    },
    {
      "epoch": 0.7716371220020855,
      "grad_norm": 4.220360279083252,
      "learning_rate": 3.9308606409794745e-05,
      "loss": 0.5036,
      "step": 740
    },
    {
      "epoch": 0.7820646506777894,
      "grad_norm": 9.825084686279297,
      "learning_rate": 3.92797983435362e-05,
      "loss": 0.6371,
      "step": 750
    },
    {
      "epoch": 0.7924921793534933,
      "grad_norm": 6.65028715133667,
      "learning_rate": 3.9250990277277645e-05,
      "loss": 0.6195,
      "step": 760
    },
    {
      "epoch": 0.8029197080291971,
      "grad_norm": 4.390841960906982,
      "learning_rate": 3.9222182211019085e-05,
      "loss": 0.5291,
      "step": 770
    },
    {
      "epoch": 0.8133472367049009,
      "grad_norm": 3.766507863998413,
      "learning_rate": 3.919337414476053e-05,
      "loss": 0.6066,
      "step": 780
    },
    {
      "epoch": 0.8237747653806048,
      "grad_norm": 4.022726058959961,
      "learning_rate": 3.9164566078501985e-05,
      "loss": 0.5581,
      "step": 790
    },
    {
      "epoch": 0.8342022940563086,
      "grad_norm": 6.824611663818359,
      "learning_rate": 3.913575801224343e-05,
      "loss": 0.5727,
      "step": 800
    },
    {
      "epoch": 0.8446298227320125,
      "grad_norm": 7.69049072265625,
      "learning_rate": 3.910694994598488e-05,
      "loss": 0.4925,
      "step": 810
    },
    {
      "epoch": 0.8550573514077163,
      "grad_norm": 3.8511757850646973,
      "learning_rate": 3.9078141879726325e-05,
      "loss": 0.6502,
      "step": 820
    },
    {
      "epoch": 0.8654848800834203,
      "grad_norm": 3.0265324115753174,
      "learning_rate": 3.904933381346777e-05,
      "loss": 0.6073,
      "step": 830
    },
    {
      "epoch": 0.8759124087591241,
      "grad_norm": 5.114975929260254,
      "learning_rate": 3.902052574720922e-05,
      "loss": 0.5153,
      "step": 840
    },
    {
      "epoch": 0.886339937434828,
      "grad_norm": 3.887894630432129,
      "learning_rate": 3.899171768095067e-05,
      "loss": 0.6219,
      "step": 850
    },
    {
      "epoch": 0.8967674661105318,
      "grad_norm": 5.1597185134887695,
      "learning_rate": 3.896290961469212e-05,
      "loss": 0.5637,
      "step": 860
    },
    {
      "epoch": 0.9071949947862357,
      "grad_norm": 2.691967248916626,
      "learning_rate": 3.8934101548433565e-05,
      "loss": 0.5563,
      "step": 870
    },
    {
      "epoch": 0.9176225234619395,
      "grad_norm": 9.767624855041504,
      "learning_rate": 3.890529348217501e-05,
      "loss": 0.5433,
      "step": 880
    },
    {
      "epoch": 0.9280500521376434,
      "grad_norm": 5.104187488555908,
      "learning_rate": 3.887648541591646e-05,
      "loss": 0.6368,
      "step": 890
    },
    {
      "epoch": 0.9384775808133472,
      "grad_norm": 4.493594646453857,
      "learning_rate": 3.8847677349657906e-05,
      "loss": 0.5408,
      "step": 900
    },
    {
      "epoch": 0.948905109489051,
      "grad_norm": 6.296830654144287,
      "learning_rate": 3.881886928339936e-05,
      "loss": 0.5824,
      "step": 910
    },
    {
      "epoch": 0.959332638164755,
      "grad_norm": 7.390388488769531,
      "learning_rate": 3.8790061217140806e-05,
      "loss": 0.5508,
      "step": 920
    },
    {
      "epoch": 0.9697601668404588,
      "grad_norm": 3.683417797088623,
      "learning_rate": 3.876125315088225e-05,
      "loss": 0.5279,
      "step": 930
    },
    {
      "epoch": 0.9801876955161627,
      "grad_norm": 4.5019450187683105,
      "learning_rate": 3.87324450846237e-05,
      "loss": 0.6172,
      "step": 940
    },
    {
      "epoch": 0.9906152241918665,
      "grad_norm": 8.357254981994629,
      "learning_rate": 3.8703637018365146e-05,
      "loss": 0.5192,
      "step": 950
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6619718309859155,
      "eval_f1": 0.6565977742448331,
      "eval_loss": 0.5662171840667725,
      "eval_precision": 0.5236686390532544,
      "eval_recall": 0.8799715909090909,
      "eval_roc_auc": 0.7077104450835645,
      "eval_runtime": 14.1483,
      "eval_samples_per_second": 270.986,
      "eval_steps_per_second": 16.963,
      "step": 959
    },
    {
      "epoch": 1.0010427528675705,
      "grad_norm": 4.304422378540039,
      "learning_rate": 3.867482895210659e-05,
      "loss": 0.6047,
      "step": 960
    },
    {
      "epoch": 1.0114702815432743,
      "grad_norm": 5.869869232177734,
      "learning_rate": 3.864602088584804e-05,
      "loss": 0.5181,
      "step": 970
    },
    {
      "epoch": 1.0218978102189782,
      "grad_norm": 6.329598903656006,
      "learning_rate": 3.8617212819589486e-05,
      "loss": 0.4369,
      "step": 980
    },
    {
      "epoch": 1.032325338894682,
      "grad_norm": 6.135312557220459,
      "learning_rate": 3.858840475333093e-05,
      "loss": 0.4928,
      "step": 990
    },
    {
      "epoch": 1.0427528675703859,
      "grad_norm": 10.788079261779785,
      "learning_rate": 3.855959668707238e-05,
      "loss": 0.5233,
      "step": 1000
    },
    {
      "epoch": 1.0531803962460897,
      "grad_norm": 5.386490345001221,
      "learning_rate": 3.853078862081383e-05,
      "loss": 0.4846,
      "step": 1010
    },
    {
      "epoch": 1.0636079249217936,
      "grad_norm": 11.162240028381348,
      "learning_rate": 3.850198055455528e-05,
      "loss": 0.4167,
      "step": 1020
    },
    {
      "epoch": 1.0740354535974974,
      "grad_norm": 5.86074161529541,
      "learning_rate": 3.8473172488296726e-05,
      "loss": 0.4748,
      "step": 1030
    },
    {
      "epoch": 1.0844629822732013,
      "grad_norm": 13.52506160736084,
      "learning_rate": 3.844436442203817e-05,
      "loss": 0.4179,
      "step": 1040
    },
    {
      "epoch": 1.094890510948905,
      "grad_norm": 7.220643043518066,
      "learning_rate": 3.841555635577962e-05,
      "loss": 0.4909,
      "step": 1050
    },
    {
      "epoch": 1.105318039624609,
      "grad_norm": 5.50223970413208,
      "learning_rate": 3.8386748289521066e-05,
      "loss": 0.5105,
      "step": 1060
    },
    {
      "epoch": 1.1157455683003128,
      "grad_norm": 5.999317646026611,
      "learning_rate": 3.835794022326252e-05,
      "loss": 0.4621,
      "step": 1070
    },
    {
      "epoch": 1.1261730969760166,
      "grad_norm": 14.704874992370605,
      "learning_rate": 3.832913215700397e-05,
      "loss": 0.3097,
      "step": 1080
    },
    {
      "epoch": 1.1366006256517205,
      "grad_norm": 10.32931900024414,
      "learning_rate": 3.830032409074541e-05,
      "loss": 0.7015,
      "step": 1090
    },
    {
      "epoch": 1.1470281543274243,
      "grad_norm": 7.726274490356445,
      "learning_rate": 3.827151602448686e-05,
      "loss": 0.5135,
      "step": 1100
    },
    {
      "epoch": 1.1574556830031282,
      "grad_norm": 14.224444389343262,
      "learning_rate": 3.824270795822831e-05,
      "loss": 0.4396,
      "step": 1110
    },
    {
      "epoch": 1.167883211678832,
      "grad_norm": 7.251230716705322,
      "learning_rate": 3.8213899891969753e-05,
      "loss": 0.4768,
      "step": 1120
    },
    {
      "epoch": 1.178310740354536,
      "grad_norm": 7.387293815612793,
      "learning_rate": 3.81850918257112e-05,
      "loss": 0.3754,
      "step": 1130
    },
    {
      "epoch": 1.1887382690302397,
      "grad_norm": 9.367391586303711,
      "learning_rate": 3.815628375945265e-05,
      "loss": 0.5129,
      "step": 1140
    },
    {
      "epoch": 1.1991657977059438,
      "grad_norm": 5.302196025848389,
      "learning_rate": 3.8127475693194094e-05,
      "loss": 0.4997,
      "step": 1150
    },
    {
      "epoch": 1.2095933263816476,
      "grad_norm": 4.858370304107666,
      "learning_rate": 3.809866762693555e-05,
      "loss": 0.4643,
      "step": 1160
    },
    {
      "epoch": 1.2200208550573515,
      "grad_norm": 8.486888885498047,
      "learning_rate": 3.8069859560676994e-05,
      "loss": 0.4103,
      "step": 1170
    },
    {
      "epoch": 1.2304483837330553,
      "grad_norm": 13.715707778930664,
      "learning_rate": 3.804105149441844e-05,
      "loss": 0.4477,
      "step": 1180
    },
    {
      "epoch": 1.2408759124087592,
      "grad_norm": 7.844603061676025,
      "learning_rate": 3.801224342815989e-05,
      "loss": 0.4482,
      "step": 1190
    },
    {
      "epoch": 1.251303441084463,
      "grad_norm": 4.176487922668457,
      "learning_rate": 3.7983435361901334e-05,
      "loss": 0.4589,
      "step": 1200
    },
    {
      "epoch": 1.2617309697601669,
      "grad_norm": 10.186575889587402,
      "learning_rate": 3.795462729564278e-05,
      "loss": 0.429,
      "step": 1210
    },
    {
      "epoch": 1.2721584984358707,
      "grad_norm": 3.879729986190796,
      "learning_rate": 3.7925819229384234e-05,
      "loss": 0.5054,
      "step": 1220
    },
    {
      "epoch": 1.2825860271115745,
      "grad_norm": 6.336765766143799,
      "learning_rate": 3.789701116312568e-05,
      "loss": 0.4315,
      "step": 1230
    },
    {
      "epoch": 1.2930135557872784,
      "grad_norm": 7.892068386077881,
      "learning_rate": 3.786820309686713e-05,
      "loss": 0.5866,
      "step": 1240
    },
    {
      "epoch": 1.3034410844629822,
      "grad_norm": 5.1417012214660645,
      "learning_rate": 3.7839395030608574e-05,
      "loss": 0.4676,
      "step": 1250
    },
    {
      "epoch": 1.313868613138686,
      "grad_norm": 6.775815010070801,
      "learning_rate": 3.781058696435002e-05,
      "loss": 0.4985,
      "step": 1260
    },
    {
      "epoch": 1.32429614181439,
      "grad_norm": 4.160303592681885,
      "learning_rate": 3.778177889809147e-05,
      "loss": 0.5066,
      "step": 1270
    },
    {
      "epoch": 1.3347236704900938,
      "grad_norm": 11.810855865478516,
      "learning_rate": 3.775297083183292e-05,
      "loss": 0.4998,
      "step": 1280
    },
    {
      "epoch": 1.3451511991657976,
      "grad_norm": 8.177823066711426,
      "learning_rate": 3.772416276557437e-05,
      "loss": 0.4169,
      "step": 1290
    },
    {
      "epoch": 1.3555787278415017,
      "grad_norm": 3.2616865634918213,
      "learning_rate": 3.7695354699315815e-05,
      "loss": 0.3715,
      "step": 1300
    },
    {
      "epoch": 1.3660062565172053,
      "grad_norm": 8.214564323425293,
      "learning_rate": 3.7666546633057255e-05,
      "loss": 0.4658,
      "step": 1310
    },
    {
      "epoch": 1.3764337851929094,
      "grad_norm": 7.6396331787109375,
      "learning_rate": 3.763773856679871e-05,
      "loss": 0.4732,
      "step": 1320
    },
    {
      "epoch": 1.3868613138686132,
      "grad_norm": 4.5531463623046875,
      "learning_rate": 3.7608930500540155e-05,
      "loss": 0.4322,
      "step": 1330
    },
    {
      "epoch": 1.397288842544317,
      "grad_norm": 7.17191219329834,
      "learning_rate": 3.75801224342816e-05,
      "loss": 0.4503,
      "step": 1340
    },
    {
      "epoch": 1.407716371220021,
      "grad_norm": 2.817460536956787,
      "learning_rate": 3.755131436802305e-05,
      "loss": 0.4204,
      "step": 1350
    },
    {
      "epoch": 1.4181438998957248,
      "grad_norm": 5.338399887084961,
      "learning_rate": 3.7522506301764495e-05,
      "loss": 0.5324,
      "step": 1360
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 3.412853240966797,
      "learning_rate": 3.749369823550594e-05,
      "loss": 0.5241,
      "step": 1370
    },
    {
      "epoch": 1.4389989572471324,
      "grad_norm": 3.8036937713623047,
      "learning_rate": 3.7464890169247395e-05,
      "loss": 0.5092,
      "step": 1380
    },
    {
      "epoch": 1.4494264859228363,
      "grad_norm": 13.917588233947754,
      "learning_rate": 3.743608210298884e-05,
      "loss": 0.355,
      "step": 1390
    },
    {
      "epoch": 1.4598540145985401,
      "grad_norm": 3.3150811195373535,
      "learning_rate": 3.740727403673029e-05,
      "loss": 0.5566,
      "step": 1400
    },
    {
      "epoch": 1.470281543274244,
      "grad_norm": 27.406532287597656,
      "learning_rate": 3.7378465970471735e-05,
      "loss": 0.4522,
      "step": 1410
    },
    {
      "epoch": 1.4807090719499478,
      "grad_norm": 11.92172622680664,
      "learning_rate": 3.734965790421318e-05,
      "loss": 0.5332,
      "step": 1420
    },
    {
      "epoch": 1.4911366006256517,
      "grad_norm": 12.11206340789795,
      "learning_rate": 3.732084983795463e-05,
      "loss": 0.5639,
      "step": 1430
    },
    {
      "epoch": 1.5015641293013555,
      "grad_norm": 4.123058795928955,
      "learning_rate": 3.729204177169608e-05,
      "loss": 0.4512,
      "step": 1440
    },
    {
      "epoch": 1.5119916579770596,
      "grad_norm": 6.91470193862915,
      "learning_rate": 3.726323370543753e-05,
      "loss": 0.4805,
      "step": 1450
    },
    {
      "epoch": 1.5224191866527632,
      "grad_norm": 14.47987174987793,
      "learning_rate": 3.7234425639178976e-05,
      "loss": 0.5772,
      "step": 1460
    },
    {
      "epoch": 1.5328467153284673,
      "grad_norm": 8.794233322143555,
      "learning_rate": 3.720561757292042e-05,
      "loss": 0.4979,
      "step": 1470
    },
    {
      "epoch": 1.543274244004171,
      "grad_norm": 7.760666847229004,
      "learning_rate": 3.717680950666187e-05,
      "loss": 0.415,
      "step": 1480
    },
    {
      "epoch": 1.553701772679875,
      "grad_norm": 7.079627990722656,
      "learning_rate": 3.7148001440403316e-05,
      "loss": 0.4894,
      "step": 1490
    },
    {
      "epoch": 1.5641293013555786,
      "grad_norm": 5.979849815368652,
      "learning_rate": 3.711919337414476e-05,
      "loss": 0.4546,
      "step": 1500
    },
    {
      "epoch": 1.5745568300312827,
      "grad_norm": 7.883499622344971,
      "learning_rate": 3.709038530788621e-05,
      "loss": 0.5157,
      "step": 1510
    },
    {
      "epoch": 1.5849843587069863,
      "grad_norm": 4.770682334899902,
      "learning_rate": 3.7061577241627656e-05,
      "loss": 0.503,
      "step": 1520
    },
    {
      "epoch": 1.5954118873826904,
      "grad_norm": 6.67912483215332,
      "learning_rate": 3.70327691753691e-05,
      "loss": 0.4453,
      "step": 1530
    },
    {
      "epoch": 1.6058394160583942,
      "grad_norm": 7.077139854431152,
      "learning_rate": 3.7003961109110556e-05,
      "loss": 0.4928,
      "step": 1540
    },
    {
      "epoch": 1.616266944734098,
      "grad_norm": 5.443018436431885,
      "learning_rate": 3.6975153042852e-05,
      "loss": 0.4081,
      "step": 1550
    },
    {
      "epoch": 1.6266944734098019,
      "grad_norm": 9.085107803344727,
      "learning_rate": 3.694634497659345e-05,
      "loss": 0.4013,
      "step": 1560
    },
    {
      "epoch": 1.6371220020855057,
      "grad_norm": 6.110729217529297,
      "learning_rate": 3.6917536910334896e-05,
      "loss": 0.4684,
      "step": 1570
    },
    {
      "epoch": 1.6475495307612096,
      "grad_norm": 9.866196632385254,
      "learning_rate": 3.688872884407634e-05,
      "loss": 0.4376,
      "step": 1580
    },
    {
      "epoch": 1.6579770594369134,
      "grad_norm": 10.744564056396484,
      "learning_rate": 3.685992077781779e-05,
      "loss": 0.4958,
      "step": 1590
    },
    {
      "epoch": 1.6684045881126173,
      "grad_norm": 12.412540435791016,
      "learning_rate": 3.683111271155924e-05,
      "loss": 0.4562,
      "step": 1600
    },
    {
      "epoch": 1.6788321167883211,
      "grad_norm": 8.789730072021484,
      "learning_rate": 3.680230464530069e-05,
      "loss": 0.4644,
      "step": 1610
    },
    {
      "epoch": 1.6892596454640252,
      "grad_norm": 6.356003284454346,
      "learning_rate": 3.6773496579042136e-05,
      "loss": 0.5043,
      "step": 1620
    },
    {
      "epoch": 1.6996871741397288,
      "grad_norm": 5.643204689025879,
      "learning_rate": 3.674468851278358e-05,
      "loss": 0.4704,
      "step": 1630
    },
    {
      "epoch": 1.7101147028154329,
      "grad_norm": 9.49537467956543,
      "learning_rate": 3.671588044652503e-05,
      "loss": 0.4404,
      "step": 1640
    },
    {
      "epoch": 1.7205422314911365,
      "grad_norm": 5.928094387054443,
      "learning_rate": 3.6687072380266477e-05,
      "loss": 0.5008,
      "step": 1650
    },
    {
      "epoch": 1.7309697601668406,
      "grad_norm": 4.038891315460205,
      "learning_rate": 3.665826431400792e-05,
      "loss": 0.4347,
      "step": 1660
    },
    {
      "epoch": 1.7413972888425442,
      "grad_norm": 7.981095314025879,
      "learning_rate": 3.662945624774937e-05,
      "loss": 0.4779,
      "step": 1670
    },
    {
      "epoch": 1.7518248175182483,
      "grad_norm": 7.367825984954834,
      "learning_rate": 3.660064818149082e-05,
      "loss": 0.4957,
      "step": 1680
    },
    {
      "epoch": 1.7622523461939519,
      "grad_norm": 5.934347629547119,
      "learning_rate": 3.6571840115232263e-05,
      "loss": 0.488,
      "step": 1690
    },
    {
      "epoch": 1.772679874869656,
      "grad_norm": 8.343771934509277,
      "learning_rate": 3.654303204897372e-05,
      "loss": 0.4513,
      "step": 1700
    },
    {
      "epoch": 1.7831074035453598,
      "grad_norm": 5.189497470855713,
      "learning_rate": 3.6514223982715164e-05,
      "loss": 0.4083,
      "step": 1710
    },
    {
      "epoch": 1.7935349322210636,
      "grad_norm": 7.437606334686279,
      "learning_rate": 3.648541591645661e-05,
      "loss": 0.5084,
      "step": 1720
    },
    {
      "epoch": 1.8039624608967675,
      "grad_norm": 4.990267276763916,
      "learning_rate": 3.645660785019806e-05,
      "loss": 0.393,
      "step": 1730
    },
    {
      "epoch": 1.8143899895724713,
      "grad_norm": 4.159974098205566,
      "learning_rate": 3.6427799783939504e-05,
      "loss": 0.4849,
      "step": 1740
    },
    {
      "epoch": 1.8248175182481752,
      "grad_norm": 26.053064346313477,
      "learning_rate": 3.639899171768095e-05,
      "loss": 0.4183,
      "step": 1750
    },
    {
      "epoch": 1.835245046923879,
      "grad_norm": 5.277994632720947,
      "learning_rate": 3.6370183651422404e-05,
      "loss": 0.4226,
      "step": 1760
    },
    {
      "epoch": 1.8456725755995829,
      "grad_norm": 6.874486446380615,
      "learning_rate": 3.634137558516385e-05,
      "loss": 0.4644,
      "step": 1770
    },
    {
      "epoch": 1.8561001042752867,
      "grad_norm": 7.116251468658447,
      "learning_rate": 3.63125675189053e-05,
      "loss": 0.4732,
      "step": 1780
    },
    {
      "epoch": 1.8665276329509908,
      "grad_norm": 5.999934673309326,
      "learning_rate": 3.6283759452646744e-05,
      "loss": 0.4702,
      "step": 1790
    },
    {
      "epoch": 1.8769551616266944,
      "grad_norm": 4.793787002563477,
      "learning_rate": 3.625495138638819e-05,
      "loss": 0.5986,
      "step": 1800
    },
    {
      "epoch": 1.8873826903023985,
      "grad_norm": 4.267024993896484,
      "learning_rate": 3.6226143320129644e-05,
      "loss": 0.4663,
      "step": 1810
    },
    {
      "epoch": 1.897810218978102,
      "grad_norm": 5.332070827484131,
      "learning_rate": 3.619733525387109e-05,
      "loss": 0.4685,
      "step": 1820
    },
    {
      "epoch": 1.9082377476538062,
      "grad_norm": 5.1317949295043945,
      "learning_rate": 3.616852718761254e-05,
      "loss": 0.4577,
      "step": 1830
    },
    {
      "epoch": 1.9186652763295098,
      "grad_norm": 4.711113452911377,
      "learning_rate": 3.613971912135398e-05,
      "loss": 0.5177,
      "step": 1840
    },
    {
      "epoch": 1.9290928050052139,
      "grad_norm": 4.488833904266357,
      "learning_rate": 3.611091105509543e-05,
      "loss": 0.479,
      "step": 1850
    },
    {
      "epoch": 1.9395203336809175,
      "grad_norm": 4.468386173248291,
      "learning_rate": 3.608210298883688e-05,
      "loss": 0.4951,
      "step": 1860
    },
    {
      "epoch": 1.9499478623566215,
      "grad_norm": 5.49347448348999,
      "learning_rate": 3.6053294922578324e-05,
      "loss": 0.497,
      "step": 1870
    },
    {
      "epoch": 1.9603753910323254,
      "grad_norm": 2.941460371017456,
      "learning_rate": 3.602448685631977e-05,
      "loss": 0.5352,
      "step": 1880
    },
    {
      "epoch": 1.9708029197080292,
      "grad_norm": 6.395269870758057,
      "learning_rate": 3.599567879006122e-05,
      "loss": 0.3936,
      "step": 1890
    },
    {
      "epoch": 1.981230448383733,
      "grad_norm": 6.966886520385742,
      "learning_rate": 3.5966870723802665e-05,
      "loss": 0.4573,
      "step": 1900
    },
    {
      "epoch": 1.991657977059437,
      "grad_norm": 10.03499698638916,
      "learning_rate": 3.593806265754412e-05,
      "loss": 0.4477,
      "step": 1910
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7866458007303078,
      "eval_f1": 0.7153792623521225,
      "eval_loss": 0.514565110206604,
      "eval_precision": 0.7012278308321964,
      "eval_recall": 0.7301136363636364,
      "eval_roc_auc": 0.7747847654200704,
      "eval_runtime": 13.898,
      "eval_samples_per_second": 275.866,
      "eval_steps_per_second": 17.269,
      "step": 1918
    },
    {
      "epoch": 2.002085505735141,
      "grad_norm": 3.388523578643799,
      "learning_rate": 3.5909254591285565e-05,
      "loss": 0.415,
      "step": 1920
    },
    {
      "epoch": 2.0125130344108446,
      "grad_norm": 9.007683753967285,
      "learning_rate": 3.588044652502701e-05,
      "loss": 0.3514,
      "step": 1930
    },
    {
      "epoch": 2.0229405630865487,
      "grad_norm": 5.189401149749756,
      "learning_rate": 3.585163845876846e-05,
      "loss": 0.4113,
      "step": 1940
    },
    {
      "epoch": 2.0333680917622523,
      "grad_norm": 2.764284610748291,
      "learning_rate": 3.5822830392509905e-05,
      "loss": 0.2858,
      "step": 1950
    },
    {
      "epoch": 2.0437956204379564,
      "grad_norm": 14.163046836853027,
      "learning_rate": 3.579402232625135e-05,
      "loss": 0.3287,
      "step": 1960
    },
    {
      "epoch": 2.05422314911366,
      "grad_norm": 12.867549896240234,
      "learning_rate": 3.5765214259992805e-05,
      "loss": 0.3618,
      "step": 1970
    },
    {
      "epoch": 2.064650677789364,
      "grad_norm": 5.737298011779785,
      "learning_rate": 3.573640619373425e-05,
      "loss": 0.3763,
      "step": 1980
    },
    {
      "epoch": 2.0750782064650677,
      "grad_norm": 3.8919029235839844,
      "learning_rate": 3.57075981274757e-05,
      "loss": 0.3069,
      "step": 1990
    },
    {
      "epoch": 2.0855057351407718,
      "grad_norm": 11.859637260437012,
      "learning_rate": 3.5678790061217145e-05,
      "loss": 0.2732,
      "step": 2000
    },
    {
      "epoch": 2.0959332638164754,
      "grad_norm": 9.760455131530762,
      "learning_rate": 3.564998199495859e-05,
      "loss": 0.3701,
      "step": 2010
    },
    {
      "epoch": 2.1063607924921794,
      "grad_norm": 1.851405382156372,
      "learning_rate": 3.562117392870004e-05,
      "loss": 0.3283,
      "step": 2020
    },
    {
      "epoch": 2.116788321167883,
      "grad_norm": 11.251277923583984,
      "learning_rate": 3.5592365862441485e-05,
      "loss": 0.3181,
      "step": 2030
    },
    {
      "epoch": 2.127215849843587,
      "grad_norm": 6.231003761291504,
      "learning_rate": 3.556355779618293e-05,
      "loss": 0.2795,
      "step": 2040
    },
    {
      "epoch": 2.1376433785192908,
      "grad_norm": 14.313791275024414,
      "learning_rate": 3.553474972992438e-05,
      "loss": 0.4182,
      "step": 2050
    },
    {
      "epoch": 2.148070907194995,
      "grad_norm": 8.423386573791504,
      "learning_rate": 3.5505941663665826e-05,
      "loss": 0.3302,
      "step": 2060
    },
    {
      "epoch": 2.1584984358706985,
      "grad_norm": 7.645117282867432,
      "learning_rate": 3.547713359740728e-05,
      "loss": 0.4107,
      "step": 2070
    },
    {
      "epoch": 2.1689259645464025,
      "grad_norm": 4.029754161834717,
      "learning_rate": 3.5448325531148726e-05,
      "loss": 0.3391,
      "step": 2080
    },
    {
      "epoch": 2.1793534932221066,
      "grad_norm": 7.201511859893799,
      "learning_rate": 3.541951746489017e-05,
      "loss": 0.3261,
      "step": 2090
    },
    {
      "epoch": 2.18978102189781,
      "grad_norm": 10.78359603881836,
      "learning_rate": 3.539070939863162e-05,
      "loss": 0.3397,
      "step": 2100
    },
    {
      "epoch": 2.2002085505735143,
      "grad_norm": 9.326581001281738,
      "learning_rate": 3.5361901332373066e-05,
      "loss": 0.4301,
      "step": 2110
    },
    {
      "epoch": 2.210636079249218,
      "grad_norm": 2.925612688064575,
      "learning_rate": 3.533309326611451e-05,
      "loss": 0.3312,
      "step": 2120
    },
    {
      "epoch": 2.221063607924922,
      "grad_norm": 8.498998641967773,
      "learning_rate": 3.5304285199855966e-05,
      "loss": 0.3941,
      "step": 2130
    },
    {
      "epoch": 2.2314911366006256,
      "grad_norm": 3.6802592277526855,
      "learning_rate": 3.527547713359741e-05,
      "loss": 0.3397,
      "step": 2140
    },
    {
      "epoch": 2.2419186652763297,
      "grad_norm": 8.68518352508545,
      "learning_rate": 3.524666906733886e-05,
      "loss": 0.2994,
      "step": 2150
    },
    {
      "epoch": 2.2523461939520333,
      "grad_norm": 9.353273391723633,
      "learning_rate": 3.5217861001080306e-05,
      "loss": 0.4607,
      "step": 2160
    },
    {
      "epoch": 2.2627737226277373,
      "grad_norm": 8.053099632263184,
      "learning_rate": 3.518905293482175e-05,
      "loss": 0.2941,
      "step": 2170
    },
    {
      "epoch": 2.273201251303441,
      "grad_norm": 3.2625248432159424,
      "learning_rate": 3.51602448685632e-05,
      "loss": 0.4024,
      "step": 2180
    },
    {
      "epoch": 2.283628779979145,
      "grad_norm": 10.930804252624512,
      "learning_rate": 3.513143680230465e-05,
      "loss": 0.2962,
      "step": 2190
    },
    {
      "epoch": 2.2940563086548487,
      "grad_norm": 9.015572547912598,
      "learning_rate": 3.510262873604609e-05,
      "loss": 0.4415,
      "step": 2200
    },
    {
      "epoch": 2.3044838373305527,
      "grad_norm": 10.212133407592773,
      "learning_rate": 3.507382066978754e-05,
      "loss": 0.308,
      "step": 2210
    },
    {
      "epoch": 2.3149113660062564,
      "grad_norm": 20.669979095458984,
      "learning_rate": 3.5045012603528986e-05,
      "loss": 0.3623,
      "step": 2220
    },
    {
      "epoch": 2.3253388946819604,
      "grad_norm": 3.8622992038726807,
      "learning_rate": 3.501620453727044e-05,
      "loss": 0.3174,
      "step": 2230
    },
    {
      "epoch": 2.335766423357664,
      "grad_norm": 5.392945766448975,
      "learning_rate": 3.498739647101189e-05,
      "loss": 0.304,
      "step": 2240
    },
    {
      "epoch": 2.346193952033368,
      "grad_norm": 13.505690574645996,
      "learning_rate": 3.495858840475333e-05,
      "loss": 0.2947,
      "step": 2250
    },
    {
      "epoch": 2.356621480709072,
      "grad_norm": 9.763505935668945,
      "learning_rate": 3.492978033849478e-05,
      "loss": 0.3839,
      "step": 2260
    },
    {
      "epoch": 2.367049009384776,
      "grad_norm": 10.14885139465332,
      "learning_rate": 3.490097227223623e-05,
      "loss": 0.36,
      "step": 2270
    },
    {
      "epoch": 2.3774765380604794,
      "grad_norm": 3.6735849380493164,
      "learning_rate": 3.4872164205977673e-05,
      "loss": 0.3352,
      "step": 2280
    },
    {
      "epoch": 2.3879040667361835,
      "grad_norm": 5.985787868499756,
      "learning_rate": 3.484335613971913e-05,
      "loss": 0.2638,
      "step": 2290
    },
    {
      "epoch": 2.3983315954118876,
      "grad_norm": 5.604104995727539,
      "learning_rate": 3.4814548073460574e-05,
      "loss": 0.3639,
      "step": 2300
    },
    {
      "epoch": 2.408759124087591,
      "grad_norm": 6.023534297943115,
      "learning_rate": 3.478574000720202e-05,
      "loss": 0.4046,
      "step": 2310
    },
    {
      "epoch": 2.4191866527632953,
      "grad_norm": 7.370450019836426,
      "learning_rate": 3.475693194094347e-05,
      "loss": 0.2228,
      "step": 2320
    },
    {
      "epoch": 2.429614181438999,
      "grad_norm": 33.28805160522461,
      "learning_rate": 3.4728123874684914e-05,
      "loss": 0.3596,
      "step": 2330
    },
    {
      "epoch": 2.440041710114703,
      "grad_norm": 9.5804443359375,
      "learning_rate": 3.469931580842636e-05,
      "loss": 0.5001,
      "step": 2340
    },
    {
      "epoch": 2.4504692387904066,
      "grad_norm": 13.576166152954102,
      "learning_rate": 3.4670507742167814e-05,
      "loss": 0.4532,
      "step": 2350
    },
    {
      "epoch": 2.4608967674661106,
      "grad_norm": 6.0205230712890625,
      "learning_rate": 3.464169967590926e-05,
      "loss": 0.2936,
      "step": 2360
    },
    {
      "epoch": 2.4713242961418143,
      "grad_norm": 7.011155605316162,
      "learning_rate": 3.46128916096507e-05,
      "loss": 0.3541,
      "step": 2370
    },
    {
      "epoch": 2.4817518248175183,
      "grad_norm": 3.337550163269043,
      "learning_rate": 3.458408354339215e-05,
      "loss": 0.314,
      "step": 2380
    },
    {
      "epoch": 2.492179353493222,
      "grad_norm": 8.668181419372559,
      "learning_rate": 3.45552754771336e-05,
      "loss": 0.3268,
      "step": 2390
    },
    {
      "epoch": 2.502606882168926,
      "grad_norm": 7.824032306671143,
      "learning_rate": 3.452646741087505e-05,
      "loss": 0.4064,
      "step": 2400
    },
    {
      "epoch": 2.5130344108446296,
      "grad_norm": 8.133481979370117,
      "learning_rate": 3.4497659344616494e-05,
      "loss": 0.3662,
      "step": 2410
    },
    {
      "epoch": 2.5234619395203337,
      "grad_norm": 11.585042953491211,
      "learning_rate": 3.446885127835794e-05,
      "loss": 0.3708,
      "step": 2420
    },
    {
      "epoch": 2.5338894681960378,
      "grad_norm": 20.483476638793945,
      "learning_rate": 3.444004321209939e-05,
      "loss": 0.3125,
      "step": 2430
    },
    {
      "epoch": 2.5443169968717414,
      "grad_norm": 6.320762634277344,
      "learning_rate": 3.441123514584084e-05,
      "loss": 0.3793,
      "step": 2440
    },
    {
      "epoch": 2.554744525547445,
      "grad_norm": 6.833190441131592,
      "learning_rate": 3.438242707958229e-05,
      "loss": 0.2787,
      "step": 2450
    },
    {
      "epoch": 2.565172054223149,
      "grad_norm": 7.400945663452148,
      "learning_rate": 3.4353619013323735e-05,
      "loss": 0.4103,
      "step": 2460
    },
    {
      "epoch": 2.575599582898853,
      "grad_norm": 9.062917709350586,
      "learning_rate": 3.432481094706518e-05,
      "loss": 0.3571,
      "step": 2470
    },
    {
      "epoch": 2.586027111574557,
      "grad_norm": 5.726953029632568,
      "learning_rate": 3.429600288080663e-05,
      "loss": 0.4049,
      "step": 2480
    },
    {
      "epoch": 2.596454640250261,
      "grad_norm": 27.337072372436523,
      "learning_rate": 3.4267194814548075e-05,
      "loss": 0.4423,
      "step": 2490
    },
    {
      "epoch": 2.6068821689259645,
      "grad_norm": 21.869308471679688,
      "learning_rate": 3.423838674828953e-05,
      "loss": 0.2968,
      "step": 2500
    },
    {
      "epoch": 2.6173096976016685,
      "grad_norm": 17.45606231689453,
      "learning_rate": 3.4209578682030975e-05,
      "loss": 0.4305,
      "step": 2510
    },
    {
      "epoch": 2.627737226277372,
      "grad_norm": 11.22848129272461,
      "learning_rate": 3.418077061577242e-05,
      "loss": 0.3471,
      "step": 2520
    },
    {
      "epoch": 2.6381647549530762,
      "grad_norm": 3.6129462718963623,
      "learning_rate": 3.415196254951387e-05,
      "loss": 0.2994,
      "step": 2530
    },
    {
      "epoch": 2.64859228362878,
      "grad_norm": 5.641872406005859,
      "learning_rate": 3.4123154483255315e-05,
      "loss": 0.3411,
      "step": 2540
    },
    {
      "epoch": 2.659019812304484,
      "grad_norm": 2.144303321838379,
      "learning_rate": 3.409434641699676e-05,
      "loss": 0.3546,
      "step": 2550
    },
    {
      "epoch": 2.6694473409801875,
      "grad_norm": 8.812528610229492,
      "learning_rate": 3.406553835073821e-05,
      "loss": 0.3018,
      "step": 2560
    },
    {
      "epoch": 2.6798748696558916,
      "grad_norm": 11.133988380432129,
      "learning_rate": 3.4036730284479655e-05,
      "loss": 0.5415,
      "step": 2570
    },
    {
      "epoch": 2.6903023983315952,
      "grad_norm": 2.7200896739959717,
      "learning_rate": 3.40079222182211e-05,
      "loss": 0.357,
      "step": 2580
    },
    {
      "epoch": 2.7007299270072993,
      "grad_norm": 12.458438873291016,
      "learning_rate": 3.397911415196255e-05,
      "loss": 0.4641,
      "step": 2590
    },
    {
      "epoch": 2.7111574556830034,
      "grad_norm": 10.88901424407959,
      "learning_rate": 3.3950306085704e-05,
      "loss": 0.5003,
      "step": 2600
    },
    {
      "epoch": 2.721584984358707,
      "grad_norm": 7.780651092529297,
      "learning_rate": 3.392149801944545e-05,
      "loss": 0.4048,
      "step": 2610
    },
    {
      "epoch": 2.7320125130344106,
      "grad_norm": 5.51660680770874,
      "learning_rate": 3.3892689953186896e-05,
      "loss": 0.4646,
      "step": 2620
    },
    {
      "epoch": 2.7424400417101147,
      "grad_norm": 6.606871128082275,
      "learning_rate": 3.386388188692834e-05,
      "loss": 0.4266,
      "step": 2630
    },
    {
      "epoch": 2.7528675703858188,
      "grad_norm": 3.9239628314971924,
      "learning_rate": 3.383507382066979e-05,
      "loss": 0.2637,
      "step": 2640
    },
    {
      "epoch": 2.7632950990615224,
      "grad_norm": 16.080486297607422,
      "learning_rate": 3.3806265754411236e-05,
      "loss": 0.3224,
      "step": 2650
    },
    {
      "epoch": 2.7737226277372264,
      "grad_norm": 11.628478050231934,
      "learning_rate": 3.377745768815269e-05,
      "loss": 0.4254,
      "step": 2660
    },
    {
      "epoch": 2.78415015641293,
      "grad_norm": 16.207069396972656,
      "learning_rate": 3.3748649621894136e-05,
      "loss": 0.3621,
      "step": 2670
    },
    {
      "epoch": 2.794577685088634,
      "grad_norm": 15.338518142700195,
      "learning_rate": 3.371984155563558e-05,
      "loss": 0.4071,
      "step": 2680
    },
    {
      "epoch": 2.8050052137643378,
      "grad_norm": 17.92275619506836,
      "learning_rate": 3.369103348937703e-05,
      "loss": 0.2963,
      "step": 2690
    },
    {
      "epoch": 2.815432742440042,
      "grad_norm": 10.520147323608398,
      "learning_rate": 3.3662225423118476e-05,
      "loss": 0.3351,
      "step": 2700
    },
    {
      "epoch": 2.8258602711157454,
      "grad_norm": 8.593851089477539,
      "learning_rate": 3.363341735685992e-05,
      "loss": 0.4134,
      "step": 2710
    },
    {
      "epoch": 2.8362877997914495,
      "grad_norm": 4.34782600402832,
      "learning_rate": 3.3604609290601376e-05,
      "loss": 0.273,
      "step": 2720
    },
    {
      "epoch": 2.846715328467153,
      "grad_norm": 12.685188293457031,
      "learning_rate": 3.3575801224342816e-05,
      "loss": 0.2766,
      "step": 2730
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 24.901201248168945,
      "learning_rate": 3.354699315808426e-05,
      "loss": 0.389,
      "step": 2740
    },
    {
      "epoch": 2.867570385818561,
      "grad_norm": 13.616683959960938,
      "learning_rate": 3.351818509182571e-05,
      "loss": 0.3267,
      "step": 2750
    },
    {
      "epoch": 2.877997914494265,
      "grad_norm": 3.5650267601013184,
      "learning_rate": 3.348937702556716e-05,
      "loss": 0.2487,
      "step": 2760
    },
    {
      "epoch": 2.888425443169969,
      "grad_norm": 5.500885963439941,
      "learning_rate": 3.346056895930861e-05,
      "loss": 0.3628,
      "step": 2770
    },
    {
      "epoch": 2.8988529718456726,
      "grad_norm": 11.151430130004883,
      "learning_rate": 3.3431760893050056e-05,
      "loss": 0.2865,
      "step": 2780
    },
    {
      "epoch": 2.909280500521376,
      "grad_norm": 14.0159273147583,
      "learning_rate": 3.34029528267915e-05,
      "loss": 0.3717,
      "step": 2790
    },
    {
      "epoch": 2.9197080291970803,
      "grad_norm": 3.6924524307250977,
      "learning_rate": 3.337414476053295e-05,
      "loss": 0.4439,
      "step": 2800
    },
    {
      "epoch": 2.9301355578727843,
      "grad_norm": 3.603386163711548,
      "learning_rate": 3.3345336694274397e-05,
      "loss": 0.3666,
      "step": 2810
    },
    {
      "epoch": 2.940563086548488,
      "grad_norm": 19.329158782958984,
      "learning_rate": 3.331652862801585e-05,
      "loss": 0.2819,
      "step": 2820
    },
    {
      "epoch": 2.9509906152241916,
      "grad_norm": 11.050041198730469,
      "learning_rate": 3.32877205617573e-05,
      "loss": 0.4928,
      "step": 2830
    },
    {
      "epoch": 2.9614181438998957,
      "grad_norm": 18.149974822998047,
      "learning_rate": 3.3258912495498743e-05,
      "loss": 0.3603,
      "step": 2840
    },
    {
      "epoch": 2.9718456725755997,
      "grad_norm": 5.612584114074707,
      "learning_rate": 3.323010442924019e-05,
      "loss": 0.4506,
      "step": 2850
    },
    {
      "epoch": 2.9822732012513034,
      "grad_norm": 9.6879301071167,
      "learning_rate": 3.320129636298164e-05,
      "loss": 0.4414,
      "step": 2860
    },
    {
      "epoch": 2.9927007299270074,
      "grad_norm": 5.632885456085205,
      "learning_rate": 3.3172488296723084e-05,
      "loss": 0.4959,
      "step": 2870
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7952529994783516,
      "eval_f1": 0.7279029462738301,
      "eval_loss": 0.4892035722732544,
      "eval_precision": 0.7109004739336493,
      "eval_recall": 0.7457386363636364,
      "eval_roc_auc": 0.7848643717679682,
      "eval_runtime": 14.0885,
      "eval_samples_per_second": 272.136,
      "eval_steps_per_second": 17.035,
      "step": 2877
    },
    {
      "epoch": 3.003128258602711,
      "grad_norm": 12.326298713684082,
      "learning_rate": 3.314368023046454e-05,
      "loss": 0.3923,
      "step": 2880
    },
    {
      "epoch": 3.013555787278415,
      "grad_norm": 4.4896063804626465,
      "learning_rate": 3.3114872164205984e-05,
      "loss": 0.213,
      "step": 2890
    },
    {
      "epoch": 3.0239833159541187,
      "grad_norm": 0.2571183145046234,
      "learning_rate": 3.308606409794743e-05,
      "loss": 0.1187,
      "step": 2900
    },
    {
      "epoch": 3.034410844629823,
      "grad_norm": 22.850557327270508,
      "learning_rate": 3.305725603168887e-05,
      "loss": 0.2542,
      "step": 2910
    },
    {
      "epoch": 3.0448383733055264,
      "grad_norm": 23.935773849487305,
      "learning_rate": 3.3028447965430324e-05,
      "loss": 0.3142,
      "step": 2920
    },
    {
      "epoch": 3.0552659019812305,
      "grad_norm": 10.200531005859375,
      "learning_rate": 3.299963989917177e-05,
      "loss": 0.1948,
      "step": 2930
    },
    {
      "epoch": 3.065693430656934,
      "grad_norm": 43.12325668334961,
      "learning_rate": 3.297083183291322e-05,
      "loss": 0.1832,
      "step": 2940
    },
    {
      "epoch": 3.076120959332638,
      "grad_norm": 12.885051727294922,
      "learning_rate": 3.2942023766654664e-05,
      "loss": 0.171,
      "step": 2950
    },
    {
      "epoch": 3.086548488008342,
      "grad_norm": 7.396296977996826,
      "learning_rate": 3.291321570039611e-05,
      "loss": 0.3521,
      "step": 2960
    },
    {
      "epoch": 3.096976016684046,
      "grad_norm": 3.1175129413604736,
      "learning_rate": 3.288440763413756e-05,
      "loss": 0.365,
      "step": 2970
    },
    {
      "epoch": 3.10740354535975,
      "grad_norm": 22.91254997253418,
      "learning_rate": 3.285559956787901e-05,
      "loss": 0.3057,
      "step": 2980
    },
    {
      "epoch": 3.1178310740354536,
      "grad_norm": 6.786282062530518,
      "learning_rate": 3.282679150162046e-05,
      "loss": 0.3736,
      "step": 2990
    },
    {
      "epoch": 3.1282586027111576,
      "grad_norm": 6.745983600616455,
      "learning_rate": 3.2797983435361904e-05,
      "loss": 0.3082,
      "step": 3000
    },
    {
      "epoch": 3.1386861313868613,
      "grad_norm": 6.654139518737793,
      "learning_rate": 3.276917536910335e-05,
      "loss": 0.2347,
      "step": 3010
    },
    {
      "epoch": 3.1491136600625653,
      "grad_norm": 13.29301929473877,
      "learning_rate": 3.27403673028448e-05,
      "loss": 0.336,
      "step": 3020
    },
    {
      "epoch": 3.159541188738269,
      "grad_norm": 34.7248649597168,
      "learning_rate": 3.2711559236586244e-05,
      "loss": 0.237,
      "step": 3030
    },
    {
      "epoch": 3.169968717413973,
      "grad_norm": 16.730133056640625,
      "learning_rate": 3.26827511703277e-05,
      "loss": 0.2077,
      "step": 3040
    },
    {
      "epoch": 3.1803962460896766,
      "grad_norm": 0.9222655892372131,
      "learning_rate": 3.2653943104069145e-05,
      "loss": 0.297,
      "step": 3050
    },
    {
      "epoch": 3.1908237747653807,
      "grad_norm": 5.240866184234619,
      "learning_rate": 3.262513503781059e-05,
      "loss": 0.2525,
      "step": 3060
    },
    {
      "epoch": 3.2012513034410843,
      "grad_norm": 14.798677444458008,
      "learning_rate": 3.259632697155204e-05,
      "loss": 0.1512,
      "step": 3070
    },
    {
      "epoch": 3.2116788321167884,
      "grad_norm": 12.230301856994629,
      "learning_rate": 3.2567518905293485e-05,
      "loss": 0.3421,
      "step": 3080
    },
    {
      "epoch": 3.222106360792492,
      "grad_norm": 7.753597736358643,
      "learning_rate": 3.253871083903493e-05,
      "loss": 0.2829,
      "step": 3090
    },
    {
      "epoch": 3.232533889468196,
      "grad_norm": 46.70945358276367,
      "learning_rate": 3.250990277277638e-05,
      "loss": 0.4431,
      "step": 3100
    },
    {
      "epoch": 3.2429614181438997,
      "grad_norm": 2.9403417110443115,
      "learning_rate": 3.2481094706517825e-05,
      "loss": 0.2116,
      "step": 3110
    },
    {
      "epoch": 3.2533889468196038,
      "grad_norm": 12.387081146240234,
      "learning_rate": 3.245228664025927e-05,
      "loss": 0.2156,
      "step": 3120
    },
    {
      "epoch": 3.2638164754953074,
      "grad_norm": 7.196552753448486,
      "learning_rate": 3.2423478574000725e-05,
      "loss": 0.2482,
      "step": 3130
    },
    {
      "epoch": 3.2742440041710115,
      "grad_norm": 13.2423095703125,
      "learning_rate": 3.239467050774217e-05,
      "loss": 0.3397,
      "step": 3140
    },
    {
      "epoch": 3.2846715328467155,
      "grad_norm": 73.76554107666016,
      "learning_rate": 3.236586244148362e-05,
      "loss": 0.3303,
      "step": 3150
    },
    {
      "epoch": 3.295099061522419,
      "grad_norm": 0.9448621273040771,
      "learning_rate": 3.2337054375225065e-05,
      "loss": 0.3221,
      "step": 3160
    },
    {
      "epoch": 3.3055265901981232,
      "grad_norm": 7.627236366271973,
      "learning_rate": 3.230824630896651e-05,
      "loss": 0.1828,
      "step": 3170
    },
    {
      "epoch": 3.315954118873827,
      "grad_norm": 59.909427642822266,
      "learning_rate": 3.227943824270796e-05,
      "loss": 0.257,
      "step": 3180
    },
    {
      "epoch": 3.326381647549531,
      "grad_norm": 1.7277281284332275,
      "learning_rate": 3.225063017644941e-05,
      "loss": 0.2945,
      "step": 3190
    },
    {
      "epoch": 3.3368091762252345,
      "grad_norm": 9.259799003601074,
      "learning_rate": 3.222182211019086e-05,
      "loss": 0.2023,
      "step": 3200
    },
    {
      "epoch": 3.3472367049009386,
      "grad_norm": 19.0358829498291,
      "learning_rate": 3.2193014043932306e-05,
      "loss": 0.316,
      "step": 3210
    },
    {
      "epoch": 3.3576642335766422,
      "grad_norm": 9.213162422180176,
      "learning_rate": 3.216420597767375e-05,
      "loss": 0.429,
      "step": 3220
    },
    {
      "epoch": 3.3680917622523463,
      "grad_norm": 13.245641708374023,
      "learning_rate": 3.21353979114152e-05,
      "loss": 0.2962,
      "step": 3230
    },
    {
      "epoch": 3.37851929092805,
      "grad_norm": 3.131756067276001,
      "learning_rate": 3.2106589845156646e-05,
      "loss": 0.2579,
      "step": 3240
    },
    {
      "epoch": 3.388946819603754,
      "grad_norm": 2.716609001159668,
      "learning_rate": 3.20777817788981e-05,
      "loss": 0.2632,
      "step": 3250
    },
    {
      "epoch": 3.3993743482794576,
      "grad_norm": 2.0375094413757324,
      "learning_rate": 3.204897371263954e-05,
      "loss": 0.3102,
      "step": 3260
    },
    {
      "epoch": 3.4098018769551617,
      "grad_norm": 1.9947506189346313,
      "learning_rate": 3.2020165646380986e-05,
      "loss": 0.2821,
      "step": 3270
    },
    {
      "epoch": 3.4202294056308653,
      "grad_norm": 17.75077247619629,
      "learning_rate": 3.199135758012243e-05,
      "loss": 0.3332,
      "step": 3280
    },
    {
      "epoch": 3.4306569343065694,
      "grad_norm": 3.9213438034057617,
      "learning_rate": 3.1962549513863886e-05,
      "loss": 0.2442,
      "step": 3290
    },
    {
      "epoch": 3.441084462982273,
      "grad_norm": 2.099079132080078,
      "learning_rate": 3.193374144760533e-05,
      "loss": 0.255,
      "step": 3300
    },
    {
      "epoch": 3.451511991657977,
      "grad_norm": 3.6024162769317627,
      "learning_rate": 3.190493338134678e-05,
      "loss": 0.282,
      "step": 3310
    },
    {
      "epoch": 3.461939520333681,
      "grad_norm": 1.645363450050354,
      "learning_rate": 3.1876125315088226e-05,
      "loss": 0.1905,
      "step": 3320
    },
    {
      "epoch": 3.4723670490093848,
      "grad_norm": 9.334054946899414,
      "learning_rate": 3.184731724882967e-05,
      "loss": 0.3756,
      "step": 3330
    },
    {
      "epoch": 3.482794577685089,
      "grad_norm": 5.010570049285889,
      "learning_rate": 3.181850918257112e-05,
      "loss": 0.2728,
      "step": 3340
    },
    {
      "epoch": 3.4932221063607924,
      "grad_norm": 16.68804168701172,
      "learning_rate": 3.178970111631257e-05,
      "loss": 0.2638,
      "step": 3350
    },
    {
      "epoch": 3.5036496350364965,
      "grad_norm": 6.28884220123291,
      "learning_rate": 3.176089305005402e-05,
      "loss": 0.3372,
      "step": 3360
    },
    {
      "epoch": 3.5140771637122,
      "grad_norm": 61.13075256347656,
      "learning_rate": 3.1732084983795467e-05,
      "loss": 0.3244,
      "step": 3370
    },
    {
      "epoch": 3.524504692387904,
      "grad_norm": 33.0354118347168,
      "learning_rate": 3.170327691753691e-05,
      "loss": 0.3644,
      "step": 3380
    },
    {
      "epoch": 3.534932221063608,
      "grad_norm": 4.6284637451171875,
      "learning_rate": 3.167446885127836e-05,
      "loss": 0.2662,
      "step": 3390
    },
    {
      "epoch": 3.545359749739312,
      "grad_norm": 10.739446640014648,
      "learning_rate": 3.164566078501981e-05,
      "loss": 0.2928,
      "step": 3400
    },
    {
      "epoch": 3.5557872784150155,
      "grad_norm": 4.530100345611572,
      "learning_rate": 3.161685271876126e-05,
      "loss": 0.2461,
      "step": 3410
    },
    {
      "epoch": 3.5662148070907196,
      "grad_norm": 2.0369348526000977,
      "learning_rate": 3.158804465250271e-05,
      "loss": 0.3163,
      "step": 3420
    },
    {
      "epoch": 3.576642335766423,
      "grad_norm": 0.7133777141571045,
      "learning_rate": 3.1559236586244154e-05,
      "loss": 0.1694,
      "step": 3430
    },
    {
      "epoch": 3.5870698644421273,
      "grad_norm": 32.2490119934082,
      "learning_rate": 3.1530428519985593e-05,
      "loss": 0.297,
      "step": 3440
    },
    {
      "epoch": 3.5974973931178313,
      "grad_norm": 24.96019172668457,
      "learning_rate": 3.150162045372705e-05,
      "loss": 0.3739,
      "step": 3450
    },
    {
      "epoch": 3.607924921793535,
      "grad_norm": 11.635637283325195,
      "learning_rate": 3.1472812387468494e-05,
      "loss": 0.2289,
      "step": 3460
    },
    {
      "epoch": 3.6183524504692386,
      "grad_norm": 19.004959106445312,
      "learning_rate": 3.144400432120994e-05,
      "loss": 0.2093,
      "step": 3470
    },
    {
      "epoch": 3.6287799791449427,
      "grad_norm": 20.527070999145508,
      "learning_rate": 3.141519625495139e-05,
      "loss": 0.3428,
      "step": 3480
    },
    {
      "epoch": 3.6392075078206467,
      "grad_norm": 2.601872682571411,
      "learning_rate": 3.1386388188692834e-05,
      "loss": 0.3589,
      "step": 3490
    },
    {
      "epoch": 3.6496350364963503,
      "grad_norm": 0.9409006237983704,
      "learning_rate": 3.135758012243428e-05,
      "loss": 0.2732,
      "step": 3500
    },
    {
      "epoch": 3.660062565172054,
      "grad_norm": 2.575716495513916,
      "learning_rate": 3.1328772056175734e-05,
      "loss": 0.0999,
      "step": 3510
    },
    {
      "epoch": 3.670490093847758,
      "grad_norm": 11.323345184326172,
      "learning_rate": 3.129996398991718e-05,
      "loss": 0.3924,
      "step": 3520
    },
    {
      "epoch": 3.680917622523462,
      "grad_norm": 25.35553550720215,
      "learning_rate": 3.127115592365863e-05,
      "loss": 0.2471,
      "step": 3530
    },
    {
      "epoch": 3.6913451511991657,
      "grad_norm": 9.834919929504395,
      "learning_rate": 3.1242347857400074e-05,
      "loss": 0.3194,
      "step": 3540
    },
    {
      "epoch": 3.70177267987487,
      "grad_norm": 6.509308815002441,
      "learning_rate": 3.121353979114152e-05,
      "loss": 0.2909,
      "step": 3550
    },
    {
      "epoch": 3.7122002085505734,
      "grad_norm": 4.109285831451416,
      "learning_rate": 3.118473172488297e-05,
      "loss": 0.2406,
      "step": 3560
    },
    {
      "epoch": 3.7226277372262775,
      "grad_norm": 40.910888671875,
      "learning_rate": 3.115592365862442e-05,
      "loss": 0.282,
      "step": 3570
    },
    {
      "epoch": 3.733055265901981,
      "grad_norm": 8.195725440979004,
      "learning_rate": 3.112711559236587e-05,
      "loss": 0.3097,
      "step": 3580
    },
    {
      "epoch": 3.743482794577685,
      "grad_norm": 22.58370018005371,
      "learning_rate": 3.1098307526107314e-05,
      "loss": 0.2847,
      "step": 3590
    },
    {
      "epoch": 3.753910323253389,
      "grad_norm": 2.517270565032959,
      "learning_rate": 3.106949945984876e-05,
      "loss": 0.2962,
      "step": 3600
    },
    {
      "epoch": 3.764337851929093,
      "grad_norm": 3.220205545425415,
      "learning_rate": 3.104069139359021e-05,
      "loss": 0.3435,
      "step": 3610
    },
    {
      "epoch": 3.774765380604797,
      "grad_norm": 6.6944451332092285,
      "learning_rate": 3.1011883327331655e-05,
      "loss": 0.429,
      "step": 3620
    },
    {
      "epoch": 3.7851929092805006,
      "grad_norm": 5.544528484344482,
      "learning_rate": 3.09830752610731e-05,
      "loss": 0.247,
      "step": 3630
    },
    {
      "epoch": 3.795620437956204,
      "grad_norm": 6.778593063354492,
      "learning_rate": 3.095426719481455e-05,
      "loss": 0.265,
      "step": 3640
    },
    {
      "epoch": 3.8060479666319083,
      "grad_norm": 11.679971694946289,
      "learning_rate": 3.0925459128555995e-05,
      "loss": 0.2022,
      "step": 3650
    },
    {
      "epoch": 3.8164754953076123,
      "grad_norm": 8.14188003540039,
      "learning_rate": 3.089665106229744e-05,
      "loss": 0.2569,
      "step": 3660
    },
    {
      "epoch": 3.826903023983316,
      "grad_norm": 26.455785751342773,
      "learning_rate": 3.0867842996038895e-05,
      "loss": 0.3825,
      "step": 3670
    },
    {
      "epoch": 3.8373305526590196,
      "grad_norm": 7.652565002441406,
      "learning_rate": 3.083903492978034e-05,
      "loss": 0.2893,
      "step": 3680
    },
    {
      "epoch": 3.8477580813347236,
      "grad_norm": 6.484791278839111,
      "learning_rate": 3.081022686352179e-05,
      "loss": 0.3232,
      "step": 3690
    },
    {
      "epoch": 3.8581856100104277,
      "grad_norm": 4.098718643188477,
      "learning_rate": 3.0781418797263235e-05,
      "loss": 0.3041,
      "step": 3700
    },
    {
      "epoch": 3.8686131386861313,
      "grad_norm": 0.8860408663749695,
      "learning_rate": 3.075261073100468e-05,
      "loss": 0.3027,
      "step": 3710
    },
    {
      "epoch": 3.8790406673618354,
      "grad_norm": 37.203582763671875,
      "learning_rate": 3.072380266474613e-05,
      "loss": 0.221,
      "step": 3720
    },
    {
      "epoch": 3.889468196037539,
      "grad_norm": 52.963653564453125,
      "learning_rate": 3.069499459848758e-05,
      "loss": 0.1998,
      "step": 3730
    },
    {
      "epoch": 3.899895724713243,
      "grad_norm": 17.502246856689453,
      "learning_rate": 3.066618653222903e-05,
      "loss": 0.4004,
      "step": 3740
    },
    {
      "epoch": 3.9103232533889467,
      "grad_norm": 43.73429489135742,
      "learning_rate": 3.0637378465970475e-05,
      "loss": 0.3381,
      "step": 3750
    },
    {
      "epoch": 3.9207507820646508,
      "grad_norm": 14.547479629516602,
      "learning_rate": 3.060857039971192e-05,
      "loss": 0.3902,
      "step": 3760
    },
    {
      "epoch": 3.9311783107403544,
      "grad_norm": 9.548921585083008,
      "learning_rate": 3.057976233345337e-05,
      "loss": 0.2993,
      "step": 3770
    },
    {
      "epoch": 3.9416058394160585,
      "grad_norm": 3.513996124267578,
      "learning_rate": 3.055095426719482e-05,
      "loss": 0.2174,
      "step": 3780
    },
    {
      "epoch": 3.952033368091762,
      "grad_norm": 20.013519287109375,
      "learning_rate": 3.052214620093627e-05,
      "loss": 0.3242,
      "step": 3790
    },
    {
      "epoch": 3.962460896767466,
      "grad_norm": 37.38252639770508,
      "learning_rate": 3.049333813467771e-05,
      "loss": 0.2468,
      "step": 3800
    },
    {
      "epoch": 3.97288842544317,
      "grad_norm": 58.423301696777344,
      "learning_rate": 3.046453006841916e-05,
      "loss": 0.2982,
      "step": 3810
    },
    {
      "epoch": 3.983315954118874,
      "grad_norm": 39.71326446533203,
      "learning_rate": 3.0435722002160606e-05,
      "loss": 0.2557,
      "step": 3820
    },
    {
      "epoch": 3.993743482794578,
      "grad_norm": 5.994832515716553,
      "learning_rate": 3.0406913935902052e-05,
      "loss": 0.3399,
      "step": 3830
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.7942097026604069,
      "eval_f1": 0.7152652472031757,
      "eval_loss": 0.7173379063606262,
      "eval_precision": 0.727072633895818,
      "eval_recall": 0.7038352272727273,
      "eval_roc_auc": 0.7752481989620026,
      "eval_runtime": 14.2034,
      "eval_samples_per_second": 269.935,
      "eval_steps_per_second": 16.897,
      "step": 3836
    },
    {
      "epoch": 4.004171011470282,
      "grad_norm": 24.740089416503906,
      "learning_rate": 3.0378105869643503e-05,
      "loss": 0.2489,
      "step": 3840
    },
    {
      "epoch": 4.014598540145985,
      "grad_norm": 6.382378101348877,
      "learning_rate": 3.034929780338495e-05,
      "loss": 0.1471,
      "step": 3850
    },
    {
      "epoch": 4.025026068821689,
      "grad_norm": 3.90511155128479,
      "learning_rate": 3.0320489737126396e-05,
      "loss": 0.2075,
      "step": 3860
    },
    {
      "epoch": 4.035453597497393,
      "grad_norm": 4.762904644012451,
      "learning_rate": 3.0291681670867846e-05,
      "loss": 0.2042,
      "step": 3870
    },
    {
      "epoch": 4.045881126173097,
      "grad_norm": 4.472313404083252,
      "learning_rate": 3.0262873604609293e-05,
      "loss": 0.2184,
      "step": 3880
    },
    {
      "epoch": 4.0563086548488005,
      "grad_norm": 8.381674766540527,
      "learning_rate": 3.023406553835074e-05,
      "loss": 0.2886,
      "step": 3890
    },
    {
      "epoch": 4.066736183524505,
      "grad_norm": 58.82917404174805,
      "learning_rate": 3.020525747209219e-05,
      "loss": 0.2538,
      "step": 3900
    },
    {
      "epoch": 4.077163712200209,
      "grad_norm": 17.23885154724121,
      "learning_rate": 3.0176449405833636e-05,
      "loss": 0.2524,
      "step": 3910
    },
    {
      "epoch": 4.087591240875913,
      "grad_norm": 8.558951377868652,
      "learning_rate": 3.0147641339575083e-05,
      "loss": 0.1957,
      "step": 3920
    },
    {
      "epoch": 4.098018769551616,
      "grad_norm": 8.329937934875488,
      "learning_rate": 3.0118833273316533e-05,
      "loss": 0.2572,
      "step": 3930
    },
    {
      "epoch": 4.10844629822732,
      "grad_norm": 1.4936611652374268,
      "learning_rate": 3.009002520705798e-05,
      "loss": 0.1733,
      "step": 3940
    },
    {
      "epoch": 4.118873826903024,
      "grad_norm": 28.461557388305664,
      "learning_rate": 3.0061217140799427e-05,
      "loss": 0.1488,
      "step": 3950
    },
    {
      "epoch": 4.129301355578728,
      "grad_norm": 2.568798065185547,
      "learning_rate": 3.0032409074540877e-05,
      "loss": 0.2892,
      "step": 3960
    },
    {
      "epoch": 4.139728884254431,
      "grad_norm": 0.24823540449142456,
      "learning_rate": 3.0003601008282323e-05,
      "loss": 0.2466,
      "step": 3970
    },
    {
      "epoch": 4.150156412930135,
      "grad_norm": 7.28899621963501,
      "learning_rate": 2.9974792942023767e-05,
      "loss": 0.3268,
      "step": 3980
    },
    {
      "epoch": 4.160583941605839,
      "grad_norm": 0.5394171476364136,
      "learning_rate": 2.9945984875765213e-05,
      "loss": 0.1996,
      "step": 3990
    },
    {
      "epoch": 4.1710114702815435,
      "grad_norm": 44.92596435546875,
      "learning_rate": 2.9917176809506663e-05,
      "loss": 0.1918,
      "step": 4000
    },
    {
      "epoch": 4.181438998957248,
      "grad_norm": 0.418828547000885,
      "learning_rate": 2.988836874324811e-05,
      "loss": 0.2923,
      "step": 4010
    },
    {
      "epoch": 4.191866527632951,
      "grad_norm": 1.0111480951309204,
      "learning_rate": 2.9859560676989557e-05,
      "loss": 0.2642,
      "step": 4020
    },
    {
      "epoch": 4.202294056308655,
      "grad_norm": 1.0822902917861938,
      "learning_rate": 2.9830752610731007e-05,
      "loss": 0.2701,
      "step": 4030
    },
    {
      "epoch": 4.212721584984359,
      "grad_norm": 8.78250789642334,
      "learning_rate": 2.9801944544472454e-05,
      "loss": 0.2191,
      "step": 4040
    },
    {
      "epoch": 4.223149113660063,
      "grad_norm": 5.469165325164795,
      "learning_rate": 2.9773136478213904e-05,
      "loss": 0.1953,
      "step": 4050
    },
    {
      "epoch": 4.233576642335766,
      "grad_norm": 2.2825052738189697,
      "learning_rate": 2.974432841195535e-05,
      "loss": 0.2901,
      "step": 4060
    },
    {
      "epoch": 4.24400417101147,
      "grad_norm": 2.0794155597686768,
      "learning_rate": 2.9715520345696797e-05,
      "loss": 0.1208,
      "step": 4070
    },
    {
      "epoch": 4.254431699687174,
      "grad_norm": 15.20541763305664,
      "learning_rate": 2.9686712279438247e-05,
      "loss": 0.1949,
      "step": 4080
    },
    {
      "epoch": 4.264859228362878,
      "grad_norm": 0.30133605003356934,
      "learning_rate": 2.9657904213179694e-05,
      "loss": 0.1784,
      "step": 4090
    },
    {
      "epoch": 4.2752867570385815,
      "grad_norm": 1.3427464962005615,
      "learning_rate": 2.962909614692114e-05,
      "loss": 0.2722,
      "step": 4100
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 6.340129852294922,
      "learning_rate": 2.960028808066259e-05,
      "loss": 0.1275,
      "step": 4110
    },
    {
      "epoch": 4.29614181438999,
      "grad_norm": 0.4006660282611847,
      "learning_rate": 2.9571480014404038e-05,
      "loss": 0.3305,
      "step": 4120
    },
    {
      "epoch": 4.306569343065694,
      "grad_norm": 35.42631912231445,
      "learning_rate": 2.9542671948145484e-05,
      "loss": 0.329,
      "step": 4130
    },
    {
      "epoch": 4.316996871741397,
      "grad_norm": 30.985435485839844,
      "learning_rate": 2.9513863881886934e-05,
      "loss": 0.2115,
      "step": 4140
    },
    {
      "epoch": 4.327424400417101,
      "grad_norm": 0.9515320062637329,
      "learning_rate": 2.9485055815628378e-05,
      "loss": 0.264,
      "step": 4150
    },
    {
      "epoch": 4.337851929092805,
      "grad_norm": 16.691316604614258,
      "learning_rate": 2.9456247749369824e-05,
      "loss": 0.3429,
      "step": 4160
    },
    {
      "epoch": 4.348279457768509,
      "grad_norm": 15.865633010864258,
      "learning_rate": 2.942743968311127e-05,
      "loss": 0.3369,
      "step": 4170
    },
    {
      "epoch": 4.358706986444213,
      "grad_norm": 16.17766571044922,
      "learning_rate": 2.939863161685272e-05,
      "loss": 0.2384,
      "step": 4180
    },
    {
      "epoch": 4.369134515119916,
      "grad_norm": 1.4749655723571777,
      "learning_rate": 2.9369823550594168e-05,
      "loss": 0.1329,
      "step": 4190
    },
    {
      "epoch": 4.37956204379562,
      "grad_norm": 32.86528778076172,
      "learning_rate": 2.9341015484335615e-05,
      "loss": 0.2736,
      "step": 4200
    },
    {
      "epoch": 4.3899895724713245,
      "grad_norm": 20.916006088256836,
      "learning_rate": 2.9312207418077065e-05,
      "loss": 0.166,
      "step": 4210
    },
    {
      "epoch": 4.4004171011470286,
      "grad_norm": 12.7954740524292,
      "learning_rate": 2.928339935181851e-05,
      "loss": 0.1934,
      "step": 4220
    },
    {
      "epoch": 4.410844629822732,
      "grad_norm": 1.9297823905944824,
      "learning_rate": 2.9254591285559958e-05,
      "loss": 0.1577,
      "step": 4230
    },
    {
      "epoch": 4.421272158498436,
      "grad_norm": 12.296795845031738,
      "learning_rate": 2.9225783219301408e-05,
      "loss": 0.2426,
      "step": 4240
    },
    {
      "epoch": 4.43169968717414,
      "grad_norm": 0.5098189115524292,
      "learning_rate": 2.9196975153042855e-05,
      "loss": 0.2257,
      "step": 4250
    },
    {
      "epoch": 4.442127215849844,
      "grad_norm": 5.662662029266357,
      "learning_rate": 2.91681670867843e-05,
      "loss": 0.2156,
      "step": 4260
    },
    {
      "epoch": 4.452554744525547,
      "grad_norm": 0.3907850384712219,
      "learning_rate": 2.9139359020525752e-05,
      "loss": 0.1738,
      "step": 4270
    },
    {
      "epoch": 4.462982273201251,
      "grad_norm": 10.304377555847168,
      "learning_rate": 2.91105509542672e-05,
      "loss": 0.2016,
      "step": 4280
    },
    {
      "epoch": 4.473409801876955,
      "grad_norm": 41.34203338623047,
      "learning_rate": 2.9081742888008645e-05,
      "loss": 0.3698,
      "step": 4290
    },
    {
      "epoch": 4.483837330552659,
      "grad_norm": 47.52161407470703,
      "learning_rate": 2.9052934821750095e-05,
      "loss": 0.1752,
      "step": 4300
    },
    {
      "epoch": 4.4942648592283625,
      "grad_norm": 6.774770736694336,
      "learning_rate": 2.9024126755491542e-05,
      "loss": 0.2208,
      "step": 4310
    },
    {
      "epoch": 4.504692387904067,
      "grad_norm": 15.974421501159668,
      "learning_rate": 2.899531868923299e-05,
      "loss": 0.1293,
      "step": 4320
    },
    {
      "epoch": 4.515119916579771,
      "grad_norm": 10.38388442993164,
      "learning_rate": 2.8966510622974432e-05,
      "loss": 0.3266,
      "step": 4330
    },
    {
      "epoch": 4.525547445255475,
      "grad_norm": 30.232519149780273,
      "learning_rate": 2.8937702556715882e-05,
      "loss": 0.2184,
      "step": 4340
    },
    {
      "epoch": 4.535974973931179,
      "grad_norm": 88.00483703613281,
      "learning_rate": 2.890889449045733e-05,
      "loss": 0.1455,
      "step": 4350
    },
    {
      "epoch": 4.546402502606882,
      "grad_norm": 26.110614776611328,
      "learning_rate": 2.8880086424198775e-05,
      "loss": 0.24,
      "step": 4360
    },
    {
      "epoch": 4.556830031282586,
      "grad_norm": 6.795956611633301,
      "learning_rate": 2.8851278357940226e-05,
      "loss": 0.2166,
      "step": 4370
    },
    {
      "epoch": 4.56725755995829,
      "grad_norm": 17.687002182006836,
      "learning_rate": 2.8822470291681672e-05,
      "loss": 0.2784,
      "step": 4380
    },
    {
      "epoch": 4.577685088633993,
      "grad_norm": 0.5896517038345337,
      "learning_rate": 2.879366222542312e-05,
      "loss": 0.2082,
      "step": 4390
    },
    {
      "epoch": 4.588112617309697,
      "grad_norm": 11.912579536437988,
      "learning_rate": 2.876485415916457e-05,
      "loss": 0.2333,
      "step": 4400
    },
    {
      "epoch": 4.598540145985401,
      "grad_norm": 1.9673535823822021,
      "learning_rate": 2.8736046092906016e-05,
      "loss": 0.1379,
      "step": 4410
    },
    {
      "epoch": 4.6089676746611055,
      "grad_norm": 59.087066650390625,
      "learning_rate": 2.8707238026647463e-05,
      "loss": 0.2631,
      "step": 4420
    },
    {
      "epoch": 4.6193952033368095,
      "grad_norm": 0.8274736404418945,
      "learning_rate": 2.8678429960388913e-05,
      "loss": 0.2261,
      "step": 4430
    },
    {
      "epoch": 4.629822732012513,
      "grad_norm": 11.040510177612305,
      "learning_rate": 2.864962189413036e-05,
      "loss": 0.3206,
      "step": 4440
    },
    {
      "epoch": 4.640250260688217,
      "grad_norm": 0.5455137491226196,
      "learning_rate": 2.8620813827871806e-05,
      "loss": 0.1869,
      "step": 4450
    },
    {
      "epoch": 4.650677789363921,
      "grad_norm": 9.337225914001465,
      "learning_rate": 2.8592005761613256e-05,
      "loss": 0.288,
      "step": 4460
    },
    {
      "epoch": 4.661105318039625,
      "grad_norm": 90.83507537841797,
      "learning_rate": 2.8563197695354703e-05,
      "loss": 0.1794,
      "step": 4470
    },
    {
      "epoch": 4.671532846715328,
      "grad_norm": 1.6522821187973022,
      "learning_rate": 2.853438962909615e-05,
      "loss": 0.185,
      "step": 4480
    },
    {
      "epoch": 4.681960375391032,
      "grad_norm": 26.31731414794922,
      "learning_rate": 2.85055815628376e-05,
      "loss": 0.2925,
      "step": 4490
    },
    {
      "epoch": 4.692387904066736,
      "grad_norm": 5.975254058837891,
      "learning_rate": 2.8476773496579046e-05,
      "loss": 0.2878,
      "step": 4500
    },
    {
      "epoch": 4.70281543274244,
      "grad_norm": 1.3545705080032349,
      "learning_rate": 2.844796543032049e-05,
      "loss": 0.225,
      "step": 4510
    },
    {
      "epoch": 4.713242961418144,
      "grad_norm": 14.641027450561523,
      "learning_rate": 2.8419157364061936e-05,
      "loss": 0.2422,
      "step": 4520
    },
    {
      "epoch": 4.7236704900938475,
      "grad_norm": 2.617581844329834,
      "learning_rate": 2.8390349297803386e-05,
      "loss": 0.172,
      "step": 4530
    },
    {
      "epoch": 4.734098018769552,
      "grad_norm": 0.6765211224555969,
      "learning_rate": 2.8361541231544833e-05,
      "loss": 0.2334,
      "step": 4540
    },
    {
      "epoch": 4.744525547445256,
      "grad_norm": 4.318596363067627,
      "learning_rate": 2.833273316528628e-05,
      "loss": 0.1966,
      "step": 4550
    },
    {
      "epoch": 4.754953076120959,
      "grad_norm": 5.5233001708984375,
      "learning_rate": 2.830392509902773e-05,
      "loss": 0.2982,
      "step": 4560
    },
    {
      "epoch": 4.765380604796663,
      "grad_norm": 0.3598990738391876,
      "learning_rate": 2.8275117032769177e-05,
      "loss": 0.3307,
      "step": 4570
    },
    {
      "epoch": 4.775808133472367,
      "grad_norm": 0.9274095892906189,
      "learning_rate": 2.8246308966510623e-05,
      "loss": 0.2258,
      "step": 4580
    },
    {
      "epoch": 4.786235662148071,
      "grad_norm": 10.399177551269531,
      "learning_rate": 2.8217500900252074e-05,
      "loss": 0.2655,
      "step": 4590
    },
    {
      "epoch": 4.796663190823775,
      "grad_norm": 39.5786247253418,
      "learning_rate": 2.818869283399352e-05,
      "loss": 0.1564,
      "step": 4600
    },
    {
      "epoch": 4.807090719499478,
      "grad_norm": 45.01776123046875,
      "learning_rate": 2.8159884767734967e-05,
      "loss": 0.1765,
      "step": 4610
    },
    {
      "epoch": 4.817518248175182,
      "grad_norm": 0.7207100987434387,
      "learning_rate": 2.8131076701476417e-05,
      "loss": 0.3166,
      "step": 4620
    },
    {
      "epoch": 4.827945776850886,
      "grad_norm": 0.9582153558731079,
      "learning_rate": 2.8102268635217864e-05,
      "loss": 0.2539,
      "step": 4630
    },
    {
      "epoch": 4.8383733055265905,
      "grad_norm": 0.5235048532485962,
      "learning_rate": 2.807346056895931e-05,
      "loss": 0.1603,
      "step": 4640
    },
    {
      "epoch": 4.848800834202294,
      "grad_norm": 5.347183704376221,
      "learning_rate": 2.804465250270076e-05,
      "loss": 0.232,
      "step": 4650
    },
    {
      "epoch": 4.859228362877998,
      "grad_norm": 9.989115715026855,
      "learning_rate": 2.8015844436442207e-05,
      "loss": 0.1819,
      "step": 4660
    },
    {
      "epoch": 4.869655891553702,
      "grad_norm": 0.37536996603012085,
      "learning_rate": 2.7987036370183654e-05,
      "loss": 0.2284,
      "step": 4670
    },
    {
      "epoch": 4.880083420229406,
      "grad_norm": 0.39842161536216736,
      "learning_rate": 2.7958228303925104e-05,
      "loss": 0.3083,
      "step": 4680
    },
    {
      "epoch": 4.89051094890511,
      "grad_norm": 1.0918790102005005,
      "learning_rate": 2.7929420237666547e-05,
      "loss": 0.2432,
      "step": 4690
    },
    {
      "epoch": 4.900938477580813,
      "grad_norm": 7.329502105712891,
      "learning_rate": 2.7900612171407994e-05,
      "loss": 0.3452,
      "step": 4700
    },
    {
      "epoch": 4.911366006256517,
      "grad_norm": 6.034932613372803,
      "learning_rate": 2.7871804105149444e-05,
      "loss": 0.259,
      "step": 4710
    },
    {
      "epoch": 4.921793534932221,
      "grad_norm": 17.249494552612305,
      "learning_rate": 2.784299603889089e-05,
      "loss": 0.2632,
      "step": 4720
    },
    {
      "epoch": 4.9322210636079244,
      "grad_norm": 0.7455590963363647,
      "learning_rate": 2.7814187972632338e-05,
      "loss": 0.1966,
      "step": 4730
    },
    {
      "epoch": 4.9426485922836285,
      "grad_norm": 0.6725414991378784,
      "learning_rate": 2.7785379906373788e-05,
      "loss": 0.2329,
      "step": 4740
    },
    {
      "epoch": 4.953076120959333,
      "grad_norm": 56.867286682128906,
      "learning_rate": 2.7756571840115234e-05,
      "loss": 0.2599,
      "step": 4750
    },
    {
      "epoch": 4.963503649635037,
      "grad_norm": 32.71897506713867,
      "learning_rate": 2.772776377385668e-05,
      "loss": 0.1666,
      "step": 4760
    },
    {
      "epoch": 4.973931178310741,
      "grad_norm": 0.38847124576568604,
      "learning_rate": 2.769895570759813e-05,
      "loss": 0.192,
      "step": 4770
    },
    {
      "epoch": 4.984358706986444,
      "grad_norm": 1.167845606803894,
      "learning_rate": 2.7670147641339578e-05,
      "loss": 0.1637,
      "step": 4780
    },
    {
      "epoch": 4.994786235662148,
      "grad_norm": 0.9963991045951843,
      "learning_rate": 2.7641339575081025e-05,
      "loss": 0.254,
      "step": 4790
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.7876890975482524,
      "eval_f1": 0.7143859649122807,
      "eval_loss": 0.8095299005508423,
      "eval_precision": 0.7059639389736477,
      "eval_recall": 0.7230113636363636,
      "eval_roc_auc": 0.7741190371355768,
      "eval_runtime": 14.0393,
      "eval_samples_per_second": 273.09,
      "eval_steps_per_second": 17.095,
      "step": 4795
    },
    {
      "epoch": 5.005213764337852,
      "grad_norm": 4.143205642700195,
      "learning_rate": 2.7612531508822475e-05,
      "loss": 0.1189,
      "step": 4800
    },
    {
      "epoch": 5.015641293013556,
      "grad_norm": 12.631683349609375,
      "learning_rate": 2.758372344256392e-05,
      "loss": 0.1593,
      "step": 4810
    },
    {
      "epoch": 5.026068821689259,
      "grad_norm": 3.2949211597442627,
      "learning_rate": 2.7554915376305368e-05,
      "loss": 0.2357,
      "step": 4820
    },
    {
      "epoch": 5.036496350364963,
      "grad_norm": 0.31082209944725037,
      "learning_rate": 2.7526107310046818e-05,
      "loss": 0.1167,
      "step": 4830
    },
    {
      "epoch": 5.046923879040667,
      "grad_norm": 18.22406005859375,
      "learning_rate": 2.7497299243788265e-05,
      "loss": 0.2258,
      "step": 4840
    },
    {
      "epoch": 5.0573514077163715,
      "grad_norm": 45.6154670715332,
      "learning_rate": 2.7468491177529712e-05,
      "loss": 0.1818,
      "step": 4850
    },
    {
      "epoch": 5.067778936392075,
      "grad_norm": 155.298828125,
      "learning_rate": 2.7439683111271162e-05,
      "loss": 0.1955,
      "step": 4860
    },
    {
      "epoch": 5.078206465067779,
      "grad_norm": 0.9715266823768616,
      "learning_rate": 2.7410875045012605e-05,
      "loss": 0.1495,
      "step": 4870
    },
    {
      "epoch": 5.088633993743483,
      "grad_norm": 25.67784881591797,
      "learning_rate": 2.7382066978754052e-05,
      "loss": 0.2251,
      "step": 4880
    },
    {
      "epoch": 5.099061522419187,
      "grad_norm": 11.023050308227539,
      "learning_rate": 2.73532589124955e-05,
      "loss": 0.2137,
      "step": 4890
    },
    {
      "epoch": 5.109489051094891,
      "grad_norm": 12.48507022857666,
      "learning_rate": 2.732445084623695e-05,
      "loss": 0.143,
      "step": 4900
    },
    {
      "epoch": 5.119916579770594,
      "grad_norm": 2.5780692100524902,
      "learning_rate": 2.7295642779978395e-05,
      "loss": 0.2117,
      "step": 4910
    },
    {
      "epoch": 5.130344108446298,
      "grad_norm": 0.561305046081543,
      "learning_rate": 2.7266834713719842e-05,
      "loss": 0.1646,
      "step": 4920
    },
    {
      "epoch": 5.140771637122002,
      "grad_norm": 14.973142623901367,
      "learning_rate": 2.7238026647461292e-05,
      "loss": 0.1051,
      "step": 4930
    },
    {
      "epoch": 5.151199165797706,
      "grad_norm": 0.317782461643219,
      "learning_rate": 2.720921858120274e-05,
      "loss": 0.2243,
      "step": 4940
    },
    {
      "epoch": 5.1616266944734095,
      "grad_norm": 2.131788969039917,
      "learning_rate": 2.7180410514944186e-05,
      "loss": 0.2209,
      "step": 4950
    },
    {
      "epoch": 5.172054223149114,
      "grad_norm": 0.41758421063423157,
      "learning_rate": 2.7151602448685636e-05,
      "loss": 0.1471,
      "step": 4960
    },
    {
      "epoch": 5.182481751824818,
      "grad_norm": 13.343893051147461,
      "learning_rate": 2.7122794382427082e-05,
      "loss": 0.161,
      "step": 4970
    },
    {
      "epoch": 5.192909280500522,
      "grad_norm": 1.0577161312103271,
      "learning_rate": 2.709398631616853e-05,
      "loss": 0.2204,
      "step": 4980
    },
    {
      "epoch": 5.203336809176225,
      "grad_norm": 0.6344671249389648,
      "learning_rate": 2.706517824990998e-05,
      "loss": 0.222,
      "step": 4990
    },
    {
      "epoch": 5.213764337851929,
      "grad_norm": 1.5885822772979736,
      "learning_rate": 2.7036370183651426e-05,
      "loss": 0.1354,
      "step": 5000
    },
    {
      "epoch": 5.224191866527633,
      "grad_norm": 0.7503511905670166,
      "learning_rate": 2.7007562117392873e-05,
      "loss": 0.1615,
      "step": 5010
    },
    {
      "epoch": 5.234619395203337,
      "grad_norm": 0.30139774084091187,
      "learning_rate": 2.6978754051134323e-05,
      "loss": 0.1655,
      "step": 5020
    },
    {
      "epoch": 5.24504692387904,
      "grad_norm": 0.5514507293701172,
      "learning_rate": 2.694994598487577e-05,
      "loss": 0.2023,
      "step": 5030
    },
    {
      "epoch": 5.255474452554744,
      "grad_norm": 1.105347752571106,
      "learning_rate": 2.6921137918617213e-05,
      "loss": 0.1556,
      "step": 5040
    },
    {
      "epoch": 5.265901981230448,
      "grad_norm": 0.3497958481311798,
      "learning_rate": 2.689232985235866e-05,
      "loss": 0.2156,
      "step": 5050
    },
    {
      "epoch": 5.2763295099061525,
      "grad_norm": 0.4260844886302948,
      "learning_rate": 2.686352178610011e-05,
      "loss": 0.2161,
      "step": 5060
    },
    {
      "epoch": 5.286757038581856,
      "grad_norm": 1.2118068933486938,
      "learning_rate": 2.6834713719841556e-05,
      "loss": 0.1323,
      "step": 5070
    },
    {
      "epoch": 5.29718456725756,
      "grad_norm": 10.881839752197266,
      "learning_rate": 2.6805905653583003e-05,
      "loss": 0.2422,
      "step": 5080
    },
    {
      "epoch": 5.307612095933264,
      "grad_norm": 0.6294515132904053,
      "learning_rate": 2.6777097587324453e-05,
      "loss": 0.2278,
      "step": 5090
    },
    {
      "epoch": 5.318039624608968,
      "grad_norm": 3.7452714443206787,
      "learning_rate": 2.67482895210659e-05,
      "loss": 0.1781,
      "step": 5100
    },
    {
      "epoch": 5.328467153284672,
      "grad_norm": 1.9439183473587036,
      "learning_rate": 2.6719481454807346e-05,
      "loss": 0.1883,
      "step": 5110
    },
    {
      "epoch": 5.338894681960375,
      "grad_norm": 16.676774978637695,
      "learning_rate": 2.6690673388548797e-05,
      "loss": 0.1225,
      "step": 5120
    },
    {
      "epoch": 5.349322210636079,
      "grad_norm": 0.36441299319267273,
      "learning_rate": 2.6661865322290243e-05,
      "loss": 0.2719,
      "step": 5130
    },
    {
      "epoch": 5.359749739311783,
      "grad_norm": 0.38819313049316406,
      "learning_rate": 2.663305725603169e-05,
      "loss": 0.186,
      "step": 5140
    },
    {
      "epoch": 5.370177267987487,
      "grad_norm": 2.218134880065918,
      "learning_rate": 2.660424918977314e-05,
      "loss": 0.286,
      "step": 5150
    },
    {
      "epoch": 5.3806047966631905,
      "grad_norm": 0.7078661918640137,
      "learning_rate": 2.6575441123514587e-05,
      "loss": 0.1636,
      "step": 5160
    },
    {
      "epoch": 5.3910323253388945,
      "grad_norm": 0.667805552482605,
      "learning_rate": 2.6546633057256034e-05,
      "loss": 0.0769,
      "step": 5170
    },
    {
      "epoch": 5.401459854014599,
      "grad_norm": 27.635417938232422,
      "learning_rate": 2.6517824990997484e-05,
      "loss": 0.2413,
      "step": 5180
    },
    {
      "epoch": 5.411887382690303,
      "grad_norm": 0.48511260747909546,
      "learning_rate": 2.648901692473893e-05,
      "loss": 0.1954,
      "step": 5190
    },
    {
      "epoch": 5.422314911366006,
      "grad_norm": 0.37777936458587646,
      "learning_rate": 2.6460208858480377e-05,
      "loss": 0.188,
      "step": 5200
    },
    {
      "epoch": 5.43274244004171,
      "grad_norm": 0.3323783278465271,
      "learning_rate": 2.6431400792221827e-05,
      "loss": 0.1729,
      "step": 5210
    },
    {
      "epoch": 5.443169968717414,
      "grad_norm": 35.550777435302734,
      "learning_rate": 2.640259272596327e-05,
      "loss": 0.2002,
      "step": 5220
    },
    {
      "epoch": 5.453597497393118,
      "grad_norm": 71.0313491821289,
      "learning_rate": 2.6373784659704717e-05,
      "loss": 0.2943,
      "step": 5230
    },
    {
      "epoch": 5.464025026068821,
      "grad_norm": 0.5656740665435791,
      "learning_rate": 2.6344976593446164e-05,
      "loss": 0.1114,
      "step": 5240
    },
    {
      "epoch": 5.474452554744525,
      "grad_norm": 0.32465875148773193,
      "learning_rate": 2.6316168527187614e-05,
      "loss": 0.1647,
      "step": 5250
    },
    {
      "epoch": 5.484880083420229,
      "grad_norm": 17.46148109436035,
      "learning_rate": 2.628736046092906e-05,
      "loss": 0.1318,
      "step": 5260
    },
    {
      "epoch": 5.495307612095933,
      "grad_norm": 2.039984703063965,
      "learning_rate": 2.6258552394670507e-05,
      "loss": 0.1499,
      "step": 5270
    },
    {
      "epoch": 5.5057351407716375,
      "grad_norm": 57.30299758911133,
      "learning_rate": 2.6229744328411958e-05,
      "loss": 0.2303,
      "step": 5280
    },
    {
      "epoch": 5.516162669447341,
      "grad_norm": 3.6436641216278076,
      "learning_rate": 2.6200936262153404e-05,
      "loss": 0.2147,
      "step": 5290
    },
    {
      "epoch": 5.526590198123045,
      "grad_norm": 49.688655853271484,
      "learning_rate": 2.617212819589485e-05,
      "loss": 0.1785,
      "step": 5300
    },
    {
      "epoch": 5.537017726798749,
      "grad_norm": 19.26447105407715,
      "learning_rate": 2.61433201296363e-05,
      "loss": 0.1018,
      "step": 5310
    },
    {
      "epoch": 5.547445255474453,
      "grad_norm": 10.555392265319824,
      "learning_rate": 2.6114512063377748e-05,
      "loss": 0.2146,
      "step": 5320
    },
    {
      "epoch": 5.557872784150156,
      "grad_norm": 46.33504104614258,
      "learning_rate": 2.6085703997119194e-05,
      "loss": 0.2483,
      "step": 5330
    },
    {
      "epoch": 5.56830031282586,
      "grad_norm": 0.16036760807037354,
      "learning_rate": 2.6056895930860645e-05,
      "loss": 0.1696,
      "step": 5340
    },
    {
      "epoch": 5.578727841501564,
      "grad_norm": 12.048713684082031,
      "learning_rate": 2.602808786460209e-05,
      "loss": 0.129,
      "step": 5350
    },
    {
      "epoch": 5.589155370177268,
      "grad_norm": 0.3420673906803131,
      "learning_rate": 2.599927979834354e-05,
      "loss": 0.2306,
      "step": 5360
    },
    {
      "epoch": 5.599582898852972,
      "grad_norm": 0.2604331076145172,
      "learning_rate": 2.5970471732084988e-05,
      "loss": 0.0416,
      "step": 5370
    },
    {
      "epoch": 5.6100104275286755,
      "grad_norm": 40.53423309326172,
      "learning_rate": 2.5941663665826435e-05,
      "loss": 0.3133,
      "step": 5380
    },
    {
      "epoch": 5.62043795620438,
      "grad_norm": 0.566945493221283,
      "learning_rate": 2.5912855599567885e-05,
      "loss": 0.2836,
      "step": 5390
    },
    {
      "epoch": 5.630865484880084,
      "grad_norm": 25.427141189575195,
      "learning_rate": 2.5884047533309328e-05,
      "loss": 0.1148,
      "step": 5400
    },
    {
      "epoch": 5.641293013555787,
      "grad_norm": 0.9673824310302734,
      "learning_rate": 2.5855239467050775e-05,
      "loss": 0.1115,
      "step": 5410
    },
    {
      "epoch": 5.651720542231491,
      "grad_norm": 53.3591194152832,
      "learning_rate": 2.582643140079222e-05,
      "loss": 0.3473,
      "step": 5420
    },
    {
      "epoch": 5.662148070907195,
      "grad_norm": 21.44313621520996,
      "learning_rate": 2.5797623334533672e-05,
      "loss": 0.2846,
      "step": 5430
    },
    {
      "epoch": 5.672575599582899,
      "grad_norm": 27.512300491333008,
      "learning_rate": 2.576881526827512e-05,
      "loss": 0.2727,
      "step": 5440
    },
    {
      "epoch": 5.683003128258603,
      "grad_norm": 10.862421035766602,
      "learning_rate": 2.5740007202016565e-05,
      "loss": 0.2444,
      "step": 5450
    },
    {
      "epoch": 5.693430656934306,
      "grad_norm": 26.843645095825195,
      "learning_rate": 2.5711199135758015e-05,
      "loss": 0.2286,
      "step": 5460
    },
    {
      "epoch": 5.70385818561001,
      "grad_norm": 0.43506428599357605,
      "learning_rate": 2.5682391069499462e-05,
      "loss": 0.0991,
      "step": 5470
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 23.63456916809082,
      "learning_rate": 2.565358300324091e-05,
      "loss": 0.238,
      "step": 5480
    },
    {
      "epoch": 5.7247132429614185,
      "grad_norm": 1.8885488510131836,
      "learning_rate": 2.562477493698236e-05,
      "loss": 0.2124,
      "step": 5490
    },
    {
      "epoch": 5.735140771637122,
      "grad_norm": 0.5495491623878479,
      "learning_rate": 2.5595966870723805e-05,
      "loss": 0.1725,
      "step": 5500
    },
    {
      "epoch": 5.745568300312826,
      "grad_norm": 2.0076329708099365,
      "learning_rate": 2.5567158804465252e-05,
      "loss": 0.2118,
      "step": 5510
    },
    {
      "epoch": 5.75599582898853,
      "grad_norm": 0.3799365758895874,
      "learning_rate": 2.5538350738206702e-05,
      "loss": 0.0682,
      "step": 5520
    },
    {
      "epoch": 5.766423357664234,
      "grad_norm": 25.68350601196289,
      "learning_rate": 2.550954267194815e-05,
      "loss": 0.1454,
      "step": 5530
    },
    {
      "epoch": 5.776850886339938,
      "grad_norm": 3.657382011413574,
      "learning_rate": 2.5480734605689596e-05,
      "loss": 0.1654,
      "step": 5540
    },
    {
      "epoch": 5.787278415015641,
      "grad_norm": 0.6042474508285522,
      "learning_rate": 2.5451926539431046e-05,
      "loss": 0.2037,
      "step": 5550
    },
    {
      "epoch": 5.797705943691345,
      "grad_norm": 10.089129447937012,
      "learning_rate": 2.5423118473172492e-05,
      "loss": 0.246,
      "step": 5560
    },
    {
      "epoch": 5.808133472367049,
      "grad_norm": 7.92703914642334,
      "learning_rate": 2.539431040691394e-05,
      "loss": 0.1743,
      "step": 5570
    },
    {
      "epoch": 5.818561001042752,
      "grad_norm": 0.6204603314399719,
      "learning_rate": 2.5365502340655383e-05,
      "loss": 0.1233,
      "step": 5580
    },
    {
      "epoch": 5.8289885297184565,
      "grad_norm": 31.969087600708008,
      "learning_rate": 2.5336694274396833e-05,
      "loss": 0.174,
      "step": 5590
    },
    {
      "epoch": 5.839416058394161,
      "grad_norm": 0.51798415184021,
      "learning_rate": 2.530788620813828e-05,
      "loss": 0.0761,
      "step": 5600
    },
    {
      "epoch": 5.849843587069865,
      "grad_norm": 0.9696345925331116,
      "learning_rate": 2.5279078141879726e-05,
      "loss": 0.2078,
      "step": 5610
    },
    {
      "epoch": 5.860271115745569,
      "grad_norm": 0.5395927429199219,
      "learning_rate": 2.5250270075621176e-05,
      "loss": 0.309,
      "step": 5620
    },
    {
      "epoch": 5.870698644421272,
      "grad_norm": 2.1237077713012695,
      "learning_rate": 2.5221462009362623e-05,
      "loss": 0.1542,
      "step": 5630
    },
    {
      "epoch": 5.881126173096976,
      "grad_norm": 129.67881774902344,
      "learning_rate": 2.519265394310407e-05,
      "loss": 0.2886,
      "step": 5640
    },
    {
      "epoch": 5.89155370177268,
      "grad_norm": 0.4612203538417816,
      "learning_rate": 2.516384587684552e-05,
      "loss": 0.0363,
      "step": 5650
    },
    {
      "epoch": 5.901981230448384,
      "grad_norm": 3.374323844909668,
      "learning_rate": 2.5135037810586966e-05,
      "loss": 0.1375,
      "step": 5660
    },
    {
      "epoch": 5.912408759124087,
      "grad_norm": 46.686256408691406,
      "learning_rate": 2.5106229744328413e-05,
      "loss": 0.2275,
      "step": 5670
    },
    {
      "epoch": 5.922836287799791,
      "grad_norm": 12.299386024475098,
      "learning_rate": 2.5077421678069863e-05,
      "loss": 0.2447,
      "step": 5680
    },
    {
      "epoch": 5.933263816475495,
      "grad_norm": 17.956985473632812,
      "learning_rate": 2.504861361181131e-05,
      "loss": 0.2085,
      "step": 5690
    },
    {
      "epoch": 5.9436913451511995,
      "grad_norm": 0.6067669987678528,
      "learning_rate": 2.5019805545552757e-05,
      "loss": 0.2688,
      "step": 5700
    },
    {
      "epoch": 5.954118873826903,
      "grad_norm": 4.392250061035156,
      "learning_rate": 2.4990997479294207e-05,
      "loss": 0.1778,
      "step": 5710
    },
    {
      "epoch": 5.964546402502607,
      "grad_norm": 32.090763092041016,
      "learning_rate": 2.4962189413035653e-05,
      "loss": 0.1388,
      "step": 5720
    },
    {
      "epoch": 5.974973931178311,
      "grad_norm": 45.63414001464844,
      "learning_rate": 2.49333813467771e-05,
      "loss": 0.1813,
      "step": 5730
    },
    {
      "epoch": 5.985401459854015,
      "grad_norm": 38.54139709472656,
      "learning_rate": 2.490457328051855e-05,
      "loss": 0.1822,
      "step": 5740
    },
    {
      "epoch": 5.995828988529718,
      "grad_norm": 77.81455993652344,
      "learning_rate": 2.4875765214259997e-05,
      "loss": 0.142,
      "step": 5750
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.7874282733437663,
      "eval_f1": 0.7147357367868393,
      "eval_loss": 0.9028527736663818,
      "eval_precision": 0.704623878536922,
      "eval_recall": 0.7251420454545454,
      "eval_roc_auc": 0.7743599757363411,
      "eval_runtime": 14.0573,
      "eval_samples_per_second": 272.741,
      "eval_steps_per_second": 17.073,
      "step": 5754
    },
    {
      "epoch": 6.006256517205422,
      "grad_norm": 0.49981066584587097,
      "learning_rate": 2.484695714800144e-05,
      "loss": 0.1568,
      "step": 5760
    },
    {
      "epoch": 6.016684045881126,
      "grad_norm": 12.153556823730469,
      "learning_rate": 2.4818149081742887e-05,
      "loss": 0.1538,
      "step": 5770
    },
    {
      "epoch": 6.02711157455683,
      "grad_norm": 0.646634578704834,
      "learning_rate": 2.4789341015484337e-05,
      "loss": 0.148,
      "step": 5780
    },
    {
      "epoch": 6.037539103232534,
      "grad_norm": 0.4948994517326355,
      "learning_rate": 2.4760532949225784e-05,
      "loss": 0.0677,
      "step": 5790
    },
    {
      "epoch": 6.0479666319082375,
      "grad_norm": 0.45138004422187805,
      "learning_rate": 2.473172488296723e-05,
      "loss": 0.1419,
      "step": 5800
    },
    {
      "epoch": 6.0583941605839415,
      "grad_norm": 1.7057483196258545,
      "learning_rate": 2.470291681670868e-05,
      "loss": 0.0777,
      "step": 5810
    },
    {
      "epoch": 6.068821689259646,
      "grad_norm": 1.8918962478637695,
      "learning_rate": 2.4674108750450127e-05,
      "loss": 0.0774,
      "step": 5820
    },
    {
      "epoch": 6.07924921793535,
      "grad_norm": 0.280955046415329,
      "learning_rate": 2.4645300684191574e-05,
      "loss": 0.1631,
      "step": 5830
    },
    {
      "epoch": 6.089676746611053,
      "grad_norm": 68.00267791748047,
      "learning_rate": 2.4616492617933024e-05,
      "loss": 0.093,
      "step": 5840
    },
    {
      "epoch": 6.100104275286757,
      "grad_norm": 0.26914966106414795,
      "learning_rate": 2.458768455167447e-05,
      "loss": 0.0999,
      "step": 5850
    },
    {
      "epoch": 6.110531803962461,
      "grad_norm": 73.01007843017578,
      "learning_rate": 2.4558876485415917e-05,
      "loss": 0.2246,
      "step": 5860
    },
    {
      "epoch": 6.120959332638165,
      "grad_norm": 0.7906867861747742,
      "learning_rate": 2.4530068419157368e-05,
      "loss": 0.2303,
      "step": 5870
    },
    {
      "epoch": 6.131386861313868,
      "grad_norm": 0.5334271788597107,
      "learning_rate": 2.4501260352898814e-05,
      "loss": 0.058,
      "step": 5880
    },
    {
      "epoch": 6.141814389989572,
      "grad_norm": 0.38578441739082336,
      "learning_rate": 2.447245228664026e-05,
      "loss": 0.1084,
      "step": 5890
    },
    {
      "epoch": 6.152241918665276,
      "grad_norm": 21.179729461669922,
      "learning_rate": 2.444364422038171e-05,
      "loss": 0.1395,
      "step": 5900
    },
    {
      "epoch": 6.16266944734098,
      "grad_norm": 0.3800790011882782,
      "learning_rate": 2.4414836154123158e-05,
      "loss": 0.12,
      "step": 5910
    },
    {
      "epoch": 6.173096976016684,
      "grad_norm": 34.923805236816406,
      "learning_rate": 2.4386028087864605e-05,
      "loss": 0.2509,
      "step": 5920
    },
    {
      "epoch": 6.183524504692388,
      "grad_norm": 2.6844100952148438,
      "learning_rate": 2.4357220021606048e-05,
      "loss": 0.1569,
      "step": 5930
    },
    {
      "epoch": 6.193952033368092,
      "grad_norm": 1.4029037952423096,
      "learning_rate": 2.4328411955347498e-05,
      "loss": 0.1303,
      "step": 5940
    },
    {
      "epoch": 6.204379562043796,
      "grad_norm": 273.3357849121094,
      "learning_rate": 2.4299603889088945e-05,
      "loss": 0.1324,
      "step": 5950
    },
    {
      "epoch": 6.2148070907195,
      "grad_norm": 0.41181451082229614,
      "learning_rate": 2.427079582283039e-05,
      "loss": 0.2311,
      "step": 5960
    },
    {
      "epoch": 6.225234619395203,
      "grad_norm": 0.43629190325737,
      "learning_rate": 2.424198775657184e-05,
      "loss": 0.11,
      "step": 5970
    },
    {
      "epoch": 6.235662148070907,
      "grad_norm": 0.3225855529308319,
      "learning_rate": 2.4213179690313288e-05,
      "loss": 0.195,
      "step": 5980
    },
    {
      "epoch": 6.246089676746611,
      "grad_norm": 4.788802623748779,
      "learning_rate": 2.4184371624054738e-05,
      "loss": 0.1044,
      "step": 5990
    },
    {
      "epoch": 6.256517205422315,
      "grad_norm": 0.25257742404937744,
      "learning_rate": 2.4155563557796185e-05,
      "loss": 0.1146,
      "step": 6000
    },
    {
      "epoch": 6.266944734098018,
      "grad_norm": 0.3791670799255371,
      "learning_rate": 2.4126755491537632e-05,
      "loss": 0.3065,
      "step": 6010
    },
    {
      "epoch": 6.2773722627737225,
      "grad_norm": 0.4943905472755432,
      "learning_rate": 2.4097947425279082e-05,
      "loss": 0.2051,
      "step": 6020
    },
    {
      "epoch": 6.287799791449427,
      "grad_norm": 0.4234406352043152,
      "learning_rate": 2.406913935902053e-05,
      "loss": 0.2485,
      "step": 6030
    },
    {
      "epoch": 6.298227320125131,
      "grad_norm": 0.5427554845809937,
      "learning_rate": 2.4040331292761975e-05,
      "loss": 0.1368,
      "step": 6040
    },
    {
      "epoch": 6.308654848800834,
      "grad_norm": 0.40585872530937195,
      "learning_rate": 2.4011523226503425e-05,
      "loss": 0.0789,
      "step": 6050
    },
    {
      "epoch": 6.319082377476538,
      "grad_norm": 9.493058204650879,
      "learning_rate": 2.3982715160244872e-05,
      "loss": 0.0892,
      "step": 6060
    },
    {
      "epoch": 6.329509906152242,
      "grad_norm": 39.429222106933594,
      "learning_rate": 2.395390709398632e-05,
      "loss": 0.1286,
      "step": 6070
    },
    {
      "epoch": 6.339937434827946,
      "grad_norm": 8.025157928466797,
      "learning_rate": 2.392509902772777e-05,
      "loss": 0.2029,
      "step": 6080
    },
    {
      "epoch": 6.350364963503649,
      "grad_norm": 0.31217160820961,
      "learning_rate": 2.3896290961469216e-05,
      "loss": 0.0577,
      "step": 6090
    },
    {
      "epoch": 6.360792492179353,
      "grad_norm": 183.91921997070312,
      "learning_rate": 2.3867482895210662e-05,
      "loss": 0.1995,
      "step": 6100
    },
    {
      "epoch": 6.371220020855057,
      "grad_norm": 0.3042183518409729,
      "learning_rate": 2.3838674828952106e-05,
      "loss": 0.0674,
      "step": 6110
    },
    {
      "epoch": 6.381647549530761,
      "grad_norm": 0.2670615613460541,
      "learning_rate": 2.3809866762693556e-05,
      "loss": 0.1196,
      "step": 6120
    },
    {
      "epoch": 6.3920750782064655,
      "grad_norm": 23.30002212524414,
      "learning_rate": 2.3781058696435002e-05,
      "loss": 0.134,
      "step": 6130
    },
    {
      "epoch": 6.402502606882169,
      "grad_norm": 0.21866250038146973,
      "learning_rate": 2.375225063017645e-05,
      "loss": 0.0727,
      "step": 6140
    },
    {
      "epoch": 6.412930135557873,
      "grad_norm": 98.08041381835938,
      "learning_rate": 2.37234425639179e-05,
      "loss": 0.2523,
      "step": 6150
    },
    {
      "epoch": 6.423357664233577,
      "grad_norm": 2.470553159713745,
      "learning_rate": 2.3694634497659346e-05,
      "loss": 0.2075,
      "step": 6160
    },
    {
      "epoch": 6.433785192909281,
      "grad_norm": 5.913374423980713,
      "learning_rate": 2.3665826431400793e-05,
      "loss": 0.1546,
      "step": 6170
    },
    {
      "epoch": 6.444212721584984,
      "grad_norm": 0.43609994649887085,
      "learning_rate": 2.3637018365142243e-05,
      "loss": 0.2026,
      "step": 6180
    },
    {
      "epoch": 6.454640250260688,
      "grad_norm": 0.7179551720619202,
      "learning_rate": 2.360821029888369e-05,
      "loss": 0.165,
      "step": 6190
    },
    {
      "epoch": 6.465067778936392,
      "grad_norm": 0.28685516119003296,
      "learning_rate": 2.3579402232625136e-05,
      "loss": 0.1967,
      "step": 6200
    },
    {
      "epoch": 6.475495307612096,
      "grad_norm": 0.7129431366920471,
      "learning_rate": 2.3550594166366586e-05,
      "loss": 0.1611,
      "step": 6210
    },
    {
      "epoch": 6.485922836287799,
      "grad_norm": 0.32435154914855957,
      "learning_rate": 2.3521786100108033e-05,
      "loss": 0.1708,
      "step": 6220
    },
    {
      "epoch": 6.4963503649635035,
      "grad_norm": 0.20597052574157715,
      "learning_rate": 2.349297803384948e-05,
      "loss": 0.0689,
      "step": 6230
    },
    {
      "epoch": 6.5067778936392076,
      "grad_norm": 0.2672581672668457,
      "learning_rate": 2.346416996759093e-05,
      "loss": 0.1651,
      "step": 6240
    },
    {
      "epoch": 6.517205422314912,
      "grad_norm": 1.3100104331970215,
      "learning_rate": 2.3435361901332376e-05,
      "loss": 0.1681,
      "step": 6250
    },
    {
      "epoch": 6.527632950990615,
      "grad_norm": 1.7600871324539185,
      "learning_rate": 2.3406553835073823e-05,
      "loss": 0.2951,
      "step": 6260
    },
    {
      "epoch": 6.538060479666319,
      "grad_norm": 0.4809955656528473,
      "learning_rate": 2.3377745768815273e-05,
      "loss": 0.1911,
      "step": 6270
    },
    {
      "epoch": 6.548488008342023,
      "grad_norm": 9.568557739257812,
      "learning_rate": 2.334893770255672e-05,
      "loss": 0.1027,
      "step": 6280
    },
    {
      "epoch": 6.558915537017727,
      "grad_norm": 0.7062386274337769,
      "learning_rate": 2.3320129636298163e-05,
      "loss": 0.0287,
      "step": 6290
    },
    {
      "epoch": 6.569343065693431,
      "grad_norm": 9.459824562072754,
      "learning_rate": 2.329132157003961e-05,
      "loss": 0.2643,
      "step": 6300
    },
    {
      "epoch": 6.579770594369134,
      "grad_norm": 9.45104694366455,
      "learning_rate": 2.326251350378106e-05,
      "loss": 0.1454,
      "step": 6310
    },
    {
      "epoch": 6.590198123044838,
      "grad_norm": 0.3783102035522461,
      "learning_rate": 2.3233705437522507e-05,
      "loss": 0.0906,
      "step": 6320
    },
    {
      "epoch": 6.600625651720542,
      "grad_norm": 1.453583836555481,
      "learning_rate": 2.3204897371263954e-05,
      "loss": 0.2543,
      "step": 6330
    },
    {
      "epoch": 6.6110531803962465,
      "grad_norm": 0.7541970014572144,
      "learning_rate": 2.3176089305005404e-05,
      "loss": 0.1135,
      "step": 6340
    },
    {
      "epoch": 6.62148070907195,
      "grad_norm": 0.37070226669311523,
      "learning_rate": 2.314728123874685e-05,
      "loss": 0.1633,
      "step": 6350
    },
    {
      "epoch": 6.631908237747654,
      "grad_norm": 64.19202423095703,
      "learning_rate": 2.3118473172488297e-05,
      "loss": 0.1392,
      "step": 6360
    },
    {
      "epoch": 6.642335766423358,
      "grad_norm": 0.3338592052459717,
      "learning_rate": 2.3089665106229747e-05,
      "loss": 0.0705,
      "step": 6370
    },
    {
      "epoch": 6.652763295099062,
      "grad_norm": 0.24101577699184418,
      "learning_rate": 2.3060857039971194e-05,
      "loss": 0.1423,
      "step": 6380
    },
    {
      "epoch": 6.663190823774765,
      "grad_norm": 1.3304611444473267,
      "learning_rate": 2.303204897371264e-05,
      "loss": 0.1826,
      "step": 6390
    },
    {
      "epoch": 6.673618352450469,
      "grad_norm": 4.675637245178223,
      "learning_rate": 2.300324090745409e-05,
      "loss": 0.2459,
      "step": 6400
    },
    {
      "epoch": 6.684045881126173,
      "grad_norm": 0.48817360401153564,
      "learning_rate": 2.2974432841195537e-05,
      "loss": 0.2072,
      "step": 6410
    },
    {
      "epoch": 6.694473409801877,
      "grad_norm": 0.5618556141853333,
      "learning_rate": 2.2945624774936984e-05,
      "loss": 0.1304,
      "step": 6420
    },
    {
      "epoch": 6.70490093847758,
      "grad_norm": 0.40298107266426086,
      "learning_rate": 2.2916816708678434e-05,
      "loss": 0.1438,
      "step": 6430
    },
    {
      "epoch": 6.7153284671532845,
      "grad_norm": 11.429348945617676,
      "learning_rate": 2.288800864241988e-05,
      "loss": 0.0947,
      "step": 6440
    },
    {
      "epoch": 6.7257559958289885,
      "grad_norm": 2.5243308544158936,
      "learning_rate": 2.2859200576161328e-05,
      "loss": 0.1631,
      "step": 6450
    },
    {
      "epoch": 6.736183524504693,
      "grad_norm": 0.3944357931613922,
      "learning_rate": 2.2830392509902778e-05,
      "loss": 0.1923,
      "step": 6460
    },
    {
      "epoch": 6.746611053180397,
      "grad_norm": 0.2964695990085602,
      "learning_rate": 2.280158444364422e-05,
      "loss": 0.0842,
      "step": 6470
    },
    {
      "epoch": 6.7570385818561,
      "grad_norm": 0.26698216795921326,
      "learning_rate": 2.2772776377385668e-05,
      "loss": 0.1462,
      "step": 6480
    },
    {
      "epoch": 6.767466110531804,
      "grad_norm": 0.4367745518684387,
      "learning_rate": 2.2743968311127114e-05,
      "loss": 0.1146,
      "step": 6490
    },
    {
      "epoch": 6.777893639207508,
      "grad_norm": 1.3328694105148315,
      "learning_rate": 2.2715160244868565e-05,
      "loss": 0.1004,
      "step": 6500
    },
    {
      "epoch": 6.788321167883212,
      "grad_norm": 2.282536029815674,
      "learning_rate": 2.268635217861001e-05,
      "loss": 0.2398,
      "step": 6510
    },
    {
      "epoch": 6.798748696558915,
      "grad_norm": 2.289480447769165,
      "learning_rate": 2.2657544112351458e-05,
      "loss": 0.2242,
      "step": 6520
    },
    {
      "epoch": 6.809176225234619,
      "grad_norm": 0.42231032252311707,
      "learning_rate": 2.2628736046092908e-05,
      "loss": 0.098,
      "step": 6530
    },
    {
      "epoch": 6.819603753910323,
      "grad_norm": 0.3346938490867615,
      "learning_rate": 2.2599927979834355e-05,
      "loss": 0.1009,
      "step": 6540
    },
    {
      "epoch": 6.830031282586027,
      "grad_norm": 0.9454687237739563,
      "learning_rate": 2.25711199135758e-05,
      "loss": 0.0966,
      "step": 6550
    },
    {
      "epoch": 6.840458811261731,
      "grad_norm": 0.33671513199806213,
      "learning_rate": 2.254231184731725e-05,
      "loss": 0.0341,
      "step": 6560
    },
    {
      "epoch": 6.850886339937435,
      "grad_norm": 27.050390243530273,
      "learning_rate": 2.2513503781058698e-05,
      "loss": 0.2627,
      "step": 6570
    },
    {
      "epoch": 6.861313868613139,
      "grad_norm": 0.29976966977119446,
      "learning_rate": 2.2484695714800145e-05,
      "loss": 0.1556,
      "step": 6580
    },
    {
      "epoch": 6.871741397288843,
      "grad_norm": 10.13693904876709,
      "learning_rate": 2.2455887648541595e-05,
      "loss": 0.2477,
      "step": 6590
    },
    {
      "epoch": 6.882168925964546,
      "grad_norm": 0.3205750584602356,
      "learning_rate": 2.2427079582283042e-05,
      "loss": 0.1921,
      "step": 6600
    },
    {
      "epoch": 6.89259645464025,
      "grad_norm": 0.7213905453681946,
      "learning_rate": 2.239827151602449e-05,
      "loss": 0.0701,
      "step": 6610
    },
    {
      "epoch": 6.903023983315954,
      "grad_norm": 25.269594192504883,
      "learning_rate": 2.236946344976594e-05,
      "loss": 0.1118,
      "step": 6620
    },
    {
      "epoch": 6.913451511991658,
      "grad_norm": 0.274358332157135,
      "learning_rate": 2.2340655383507385e-05,
      "loss": 0.1403,
      "step": 6630
    },
    {
      "epoch": 6.923879040667362,
      "grad_norm": 0.2229815274477005,
      "learning_rate": 2.2311847317248832e-05,
      "loss": 0.1814,
      "step": 6640
    },
    {
      "epoch": 6.934306569343065,
      "grad_norm": 0.17877358198165894,
      "learning_rate": 2.228303925099028e-05,
      "loss": 0.0589,
      "step": 6650
    },
    {
      "epoch": 6.9447340980187695,
      "grad_norm": 0.40962275862693787,
      "learning_rate": 2.2254231184731725e-05,
      "loss": 0.1161,
      "step": 6660
    },
    {
      "epoch": 6.955161626694474,
      "grad_norm": 2.834411859512329,
      "learning_rate": 2.2225423118473172e-05,
      "loss": 0.2122,
      "step": 6670
    },
    {
      "epoch": 6.965589155370178,
      "grad_norm": 45.2419319152832,
      "learning_rate": 2.2196615052214622e-05,
      "loss": 0.1389,
      "step": 6680
    },
    {
      "epoch": 6.976016684045881,
      "grad_norm": 0.4050484895706177,
      "learning_rate": 2.216780698595607e-05,
      "loss": 0.1169,
      "step": 6690
    },
    {
      "epoch": 6.986444212721585,
      "grad_norm": 2.983985662460327,
      "learning_rate": 2.2138998919697516e-05,
      "loss": 0.0689,
      "step": 6700
    },
    {
      "epoch": 6.996871741397289,
      "grad_norm": 0.2983343005180359,
      "learning_rate": 2.2110190853438966e-05,
      "loss": 0.1167,
      "step": 6710
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.7923839332290037,
      "eval_f1": 0.7058388765705839,
      "eval_loss": 1.0083099603652954,
      "eval_precision": 0.7357473035439137,
      "eval_recall": 0.6782670454545454,
      "eval_roc_auc": 0.7684410247882785,
      "eval_runtime": 14.1721,
      "eval_samples_per_second": 270.532,
      "eval_steps_per_second": 16.935,
      "step": 6713
    },
    {
      "epoch": 7.007299270072993,
      "grad_norm": 0.30243390798568726,
      "learning_rate": 2.2081382787180412e-05,
      "loss": 0.0926,
      "step": 6720
    },
    {
      "epoch": 7.017726798748696,
      "grad_norm": 2.266038656234741,
      "learning_rate": 2.205257472092186e-05,
      "loss": 0.0872,
      "step": 6730
    },
    {
      "epoch": 7.0281543274244,
      "grad_norm": 0.22236885130405426,
      "learning_rate": 2.202376665466331e-05,
      "loss": 0.0642,
      "step": 6740
    },
    {
      "epoch": 7.038581856100104,
      "grad_norm": 2.2788801193237305,
      "learning_rate": 2.1994958588404756e-05,
      "loss": 0.173,
      "step": 6750
    },
    {
      "epoch": 7.049009384775808,
      "grad_norm": 14.693632125854492,
      "learning_rate": 2.1966150522146203e-05,
      "loss": 0.1291,
      "step": 6760
    },
    {
      "epoch": 7.059436913451512,
      "grad_norm": 1.228857398033142,
      "learning_rate": 2.1937342455887653e-05,
      "loss": 0.211,
      "step": 6770
    },
    {
      "epoch": 7.069864442127216,
      "grad_norm": 0.4481326937675476,
      "learning_rate": 2.19085343896291e-05,
      "loss": 0.0784,
      "step": 6780
    },
    {
      "epoch": 7.08029197080292,
      "grad_norm": 0.22820664942264557,
      "learning_rate": 2.1879726323370546e-05,
      "loss": 0.068,
      "step": 6790
    },
    {
      "epoch": 7.090719499478624,
      "grad_norm": 42.27800750732422,
      "learning_rate": 2.1850918257111996e-05,
      "loss": 0.1284,
      "step": 6800
    },
    {
      "epoch": 7.101147028154328,
      "grad_norm": 95.60929870605469,
      "learning_rate": 2.1822110190853443e-05,
      "loss": 0.1597,
      "step": 6810
    },
    {
      "epoch": 7.111574556830031,
      "grad_norm": 0.25360652804374695,
      "learning_rate": 2.1793302124594886e-05,
      "loss": 0.1614,
      "step": 6820
    },
    {
      "epoch": 7.122002085505735,
      "grad_norm": 0.24914754927158356,
      "learning_rate": 2.1764494058336333e-05,
      "loss": 0.0536,
      "step": 6830
    },
    {
      "epoch": 7.132429614181439,
      "grad_norm": 0.25451675057411194,
      "learning_rate": 2.1735685992077783e-05,
      "loss": 0.114,
      "step": 6840
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 1.256299376487732,
      "learning_rate": 2.170687792581923e-05,
      "loss": 0.1573,
      "step": 6850
    },
    {
      "epoch": 7.153284671532846,
      "grad_norm": 0.18179462850093842,
      "learning_rate": 2.1678069859560677e-05,
      "loss": 0.0522,
      "step": 6860
    },
    {
      "epoch": 7.1637122002085505,
      "grad_norm": 2.1349010467529297,
      "learning_rate": 2.1649261793302127e-05,
      "loss": 0.1877,
      "step": 6870
    },
    {
      "epoch": 7.1741397288842546,
      "grad_norm": 1.2386661767959595,
      "learning_rate": 2.1620453727043573e-05,
      "loss": 0.0081,
      "step": 6880
    },
    {
      "epoch": 7.184567257559959,
      "grad_norm": 2.4456946849823,
      "learning_rate": 2.159164566078502e-05,
      "loss": 0.1613,
      "step": 6890
    },
    {
      "epoch": 7.194994786235662,
      "grad_norm": 126.79906463623047,
      "learning_rate": 2.156283759452647e-05,
      "loss": 0.1046,
      "step": 6900
    },
    {
      "epoch": 7.205422314911366,
      "grad_norm": 2.194485902786255,
      "learning_rate": 2.1534029528267917e-05,
      "loss": 0.1546,
      "step": 6910
    },
    {
      "epoch": 7.21584984358707,
      "grad_norm": 10.244300842285156,
      "learning_rate": 2.1505221462009364e-05,
      "loss": 0.2417,
      "step": 6920
    },
    {
      "epoch": 7.226277372262774,
      "grad_norm": 15.854921340942383,
      "learning_rate": 2.1476413395750814e-05,
      "loss": 0.215,
      "step": 6930
    },
    {
      "epoch": 7.236704900938477,
      "grad_norm": 4.417149543762207,
      "learning_rate": 2.144760532949226e-05,
      "loss": 0.1265,
      "step": 6940
    },
    {
      "epoch": 7.247132429614181,
      "grad_norm": 6.354562282562256,
      "learning_rate": 2.1418797263233707e-05,
      "loss": 0.0893,
      "step": 6950
    },
    {
      "epoch": 7.257559958289885,
      "grad_norm": 0.19732898473739624,
      "learning_rate": 2.1389989196975157e-05,
      "loss": 0.0292,
      "step": 6960
    },
    {
      "epoch": 7.267987486965589,
      "grad_norm": 0.17117314040660858,
      "learning_rate": 2.1361181130716604e-05,
      "loss": 0.0499,
      "step": 6970
    },
    {
      "epoch": 7.2784150156412935,
      "grad_norm": 20.76869010925293,
      "learning_rate": 2.133237306445805e-05,
      "loss": 0.0782,
      "step": 6980
    },
    {
      "epoch": 7.288842544316997,
      "grad_norm": 0.13667474687099457,
      "learning_rate": 2.13035649981995e-05,
      "loss": 0.059,
      "step": 6990
    },
    {
      "epoch": 7.299270072992701,
      "grad_norm": 63.5218505859375,
      "learning_rate": 2.1274756931940944e-05,
      "loss": 0.0384,
      "step": 7000
    },
    {
      "epoch": 7.309697601668405,
      "grad_norm": 0.14886574447155,
      "learning_rate": 2.124594886568239e-05,
      "loss": 0.1883,
      "step": 7010
    },
    {
      "epoch": 7.320125130344109,
      "grad_norm": 6.614601135253906,
      "learning_rate": 2.1217140799423837e-05,
      "loss": 0.0906,
      "step": 7020
    },
    {
      "epoch": 7.330552659019812,
      "grad_norm": 0.5301468372344971,
      "learning_rate": 2.1188332733165288e-05,
      "loss": 0.1612,
      "step": 7030
    },
    {
      "epoch": 7.340980187695516,
      "grad_norm": 0.19919361174106598,
      "learning_rate": 2.1159524666906734e-05,
      "loss": 0.1025,
      "step": 7040
    },
    {
      "epoch": 7.35140771637122,
      "grad_norm": 0.3765856921672821,
      "learning_rate": 2.113071660064818e-05,
      "loss": 0.0794,
      "step": 7050
    },
    {
      "epoch": 7.361835245046924,
      "grad_norm": 5.249907970428467,
      "learning_rate": 2.110190853438963e-05,
      "loss": 0.1206,
      "step": 7060
    },
    {
      "epoch": 7.372262773722627,
      "grad_norm": 7.123800754547119,
      "learning_rate": 2.1073100468131078e-05,
      "loss": 0.1854,
      "step": 7070
    },
    {
      "epoch": 7.3826903023983315,
      "grad_norm": 0.21611744165420532,
      "learning_rate": 2.1044292401872525e-05,
      "loss": 0.1146,
      "step": 7080
    },
    {
      "epoch": 7.3931178310740355,
      "grad_norm": 0.5482687950134277,
      "learning_rate": 2.1015484335613975e-05,
      "loss": 0.1242,
      "step": 7090
    },
    {
      "epoch": 7.40354535974974,
      "grad_norm": 2.158790349960327,
      "learning_rate": 2.098667626935542e-05,
      "loss": 0.1469,
      "step": 7100
    },
    {
      "epoch": 7.413972888425443,
      "grad_norm": 0.2280808389186859,
      "learning_rate": 2.0957868203096868e-05,
      "loss": 0.1673,
      "step": 7110
    },
    {
      "epoch": 7.424400417101147,
      "grad_norm": 0.28265708684921265,
      "learning_rate": 2.0929060136838318e-05,
      "loss": 0.1492,
      "step": 7120
    },
    {
      "epoch": 7.434827945776851,
      "grad_norm": 0.23135751485824585,
      "learning_rate": 2.0900252070579765e-05,
      "loss": 0.0821,
      "step": 7130
    },
    {
      "epoch": 7.445255474452555,
      "grad_norm": 0.21447442471981049,
      "learning_rate": 2.087144400432121e-05,
      "loss": 0.0721,
      "step": 7140
    },
    {
      "epoch": 7.455683003128259,
      "grad_norm": 0.35908350348472595,
      "learning_rate": 2.084263593806266e-05,
      "loss": 0.0961,
      "step": 7150
    },
    {
      "epoch": 7.466110531803962,
      "grad_norm": 0.21240642666816711,
      "learning_rate": 2.081382787180411e-05,
      "loss": 0.0675,
      "step": 7160
    },
    {
      "epoch": 7.476538060479666,
      "grad_norm": 0.7009350061416626,
      "learning_rate": 2.0785019805545555e-05,
      "loss": 0.1069,
      "step": 7170
    },
    {
      "epoch": 7.48696558915537,
      "grad_norm": 2.1000497341156006,
      "learning_rate": 2.0756211739287e-05,
      "loss": 0.1821,
      "step": 7180
    },
    {
      "epoch": 7.497393117831074,
      "grad_norm": 30.99710464477539,
      "learning_rate": 2.072740367302845e-05,
      "loss": 0.1691,
      "step": 7190
    },
    {
      "epoch": 7.507820646506778,
      "grad_norm": 3.8892762660980225,
      "learning_rate": 2.0698595606769895e-05,
      "loss": 0.2086,
      "step": 7200
    },
    {
      "epoch": 7.518248175182482,
      "grad_norm": 54.40302658081055,
      "learning_rate": 2.0669787540511342e-05,
      "loss": 0.1895,
      "step": 7210
    },
    {
      "epoch": 7.528675703858186,
      "grad_norm": 0.3577192723751068,
      "learning_rate": 2.0640979474252792e-05,
      "loss": 0.171,
      "step": 7220
    },
    {
      "epoch": 7.53910323253389,
      "grad_norm": 3.712629795074463,
      "learning_rate": 2.061217140799424e-05,
      "loss": 0.1087,
      "step": 7230
    },
    {
      "epoch": 7.549530761209593,
      "grad_norm": 2.510481357574463,
      "learning_rate": 2.0583363341735685e-05,
      "loss": 0.1664,
      "step": 7240
    },
    {
      "epoch": 7.559958289885297,
      "grad_norm": 1.2428263425827026,
      "learning_rate": 2.0554555275477136e-05,
      "loss": 0.1474,
      "step": 7250
    },
    {
      "epoch": 7.570385818561001,
      "grad_norm": 0.2597323954105377,
      "learning_rate": 2.0525747209218582e-05,
      "loss": 0.1358,
      "step": 7260
    },
    {
      "epoch": 7.580813347236705,
      "grad_norm": 2.777073621749878,
      "learning_rate": 2.049693914296003e-05,
      "loss": 0.1104,
      "step": 7270
    },
    {
      "epoch": 7.591240875912408,
      "grad_norm": 41.90812683105469,
      "learning_rate": 2.046813107670148e-05,
      "loss": 0.2385,
      "step": 7280
    },
    {
      "epoch": 7.601668404588112,
      "grad_norm": 9.40080738067627,
      "learning_rate": 2.0439323010442926e-05,
      "loss": 0.0828,
      "step": 7290
    },
    {
      "epoch": 7.6120959332638165,
      "grad_norm": 0.5348424315452576,
      "learning_rate": 2.0410514944184376e-05,
      "loss": 0.1246,
      "step": 7300
    },
    {
      "epoch": 7.622523461939521,
      "grad_norm": 1.3660269975662231,
      "learning_rate": 2.0381706877925823e-05,
      "loss": 0.0777,
      "step": 7310
    },
    {
      "epoch": 7.632950990615225,
      "grad_norm": 28.65335464477539,
      "learning_rate": 2.035289881166727e-05,
      "loss": 0.1505,
      "step": 7320
    },
    {
      "epoch": 7.643378519290928,
      "grad_norm": 2.4352972507476807,
      "learning_rate": 2.032409074540872e-05,
      "loss": 0.352,
      "step": 7330
    },
    {
      "epoch": 7.653806047966632,
      "grad_norm": 0.3004116415977478,
      "learning_rate": 2.0295282679150166e-05,
      "loss": 0.1306,
      "step": 7340
    },
    {
      "epoch": 7.664233576642336,
      "grad_norm": 0.30637526512145996,
      "learning_rate": 2.0266474612891613e-05,
      "loss": 0.1905,
      "step": 7350
    },
    {
      "epoch": 7.674661105318039,
      "grad_norm": 0.2602328360080719,
      "learning_rate": 2.0237666546633056e-05,
      "loss": 0.088,
      "step": 7360
    },
    {
      "epoch": 7.685088633993743,
      "grad_norm": 2.3025403022766113,
      "learning_rate": 2.0208858480374506e-05,
      "loss": 0.1503,
      "step": 7370
    },
    {
      "epoch": 7.695516162669447,
      "grad_norm": 1.6560897827148438,
      "learning_rate": 2.0180050414115953e-05,
      "loss": 0.2269,
      "step": 7380
    },
    {
      "epoch": 7.705943691345151,
      "grad_norm": 0.4710506498813629,
      "learning_rate": 2.01512423478574e-05,
      "loss": 0.0993,
      "step": 7390
    },
    {
      "epoch": 7.716371220020855,
      "grad_norm": 0.27249571681022644,
      "learning_rate": 2.012243428159885e-05,
      "loss": 0.0703,
      "step": 7400
    },
    {
      "epoch": 7.726798748696559,
      "grad_norm": 0.9179578423500061,
      "learning_rate": 2.0093626215340296e-05,
      "loss": 0.1837,
      "step": 7410
    },
    {
      "epoch": 7.737226277372263,
      "grad_norm": 3.807020664215088,
      "learning_rate": 2.0064818149081743e-05,
      "loss": 0.1078,
      "step": 7420
    },
    {
      "epoch": 7.747653806047967,
      "grad_norm": 115.34292602539062,
      "learning_rate": 2.0036010082823193e-05,
      "loss": 0.0843,
      "step": 7430
    },
    {
      "epoch": 7.758081334723671,
      "grad_norm": 0.20902983844280243,
      "learning_rate": 2.000720201656464e-05,
      "loss": 0.0761,
      "step": 7440
    },
    {
      "epoch": 7.768508863399374,
      "grad_norm": 0.1911754310131073,
      "learning_rate": 1.9978393950306087e-05,
      "loss": 0.0879,
      "step": 7450
    },
    {
      "epoch": 7.778936392075078,
      "grad_norm": 0.24528878927230835,
      "learning_rate": 1.9949585884047537e-05,
      "loss": 0.2452,
      "step": 7460
    },
    {
      "epoch": 7.789363920750782,
      "grad_norm": 0.332419753074646,
      "learning_rate": 1.9920777817788983e-05,
      "loss": 0.1697,
      "step": 7470
    },
    {
      "epoch": 7.799791449426486,
      "grad_norm": 0.23076459765434265,
      "learning_rate": 1.989196975153043e-05,
      "loss": 0.1071,
      "step": 7480
    },
    {
      "epoch": 7.81021897810219,
      "grad_norm": 0.24354767799377441,
      "learning_rate": 1.9863161685271877e-05,
      "loss": 0.1968,
      "step": 7490
    },
    {
      "epoch": 7.820646506777893,
      "grad_norm": 0.28452301025390625,
      "learning_rate": 1.9834353619013324e-05,
      "loss": 0.1116,
      "step": 7500
    },
    {
      "epoch": 7.8310740354535975,
      "grad_norm": 0.27973419427871704,
      "learning_rate": 1.9805545552754774e-05,
      "loss": 0.097,
      "step": 7510
    },
    {
      "epoch": 7.8415015641293015,
      "grad_norm": 0.20987410843372345,
      "learning_rate": 1.977673748649622e-05,
      "loss": 0.072,
      "step": 7520
    },
    {
      "epoch": 7.851929092805005,
      "grad_norm": 0.19229859113693237,
      "learning_rate": 1.9747929420237667e-05,
      "loss": 0.0386,
      "step": 7530
    },
    {
      "epoch": 7.862356621480709,
      "grad_norm": 1.297739863395691,
      "learning_rate": 1.9719121353979117e-05,
      "loss": 0.1027,
      "step": 7540
    },
    {
      "epoch": 7.872784150156413,
      "grad_norm": 0.19836896657943726,
      "learning_rate": 1.9690313287720564e-05,
      "loss": 0.1487,
      "step": 7550
    },
    {
      "epoch": 7.883211678832117,
      "grad_norm": 0.2720918357372284,
      "learning_rate": 1.966150522146201e-05,
      "loss": 0.1352,
      "step": 7560
    },
    {
      "epoch": 7.893639207507821,
      "grad_norm": 2.1170763969421387,
      "learning_rate": 1.963269715520346e-05,
      "loss": 0.2573,
      "step": 7570
    },
    {
      "epoch": 7.904066736183524,
      "grad_norm": 1.862537145614624,
      "learning_rate": 1.9603889088944904e-05,
      "loss": 0.166,
      "step": 7580
    },
    {
      "epoch": 7.914494264859228,
      "grad_norm": 0.3871411085128784,
      "learning_rate": 1.9575081022686354e-05,
      "loss": 0.1187,
      "step": 7590
    },
    {
      "epoch": 7.924921793534932,
      "grad_norm": 1.0759243965148926,
      "learning_rate": 1.95462729564278e-05,
      "loss": 0.1158,
      "step": 7600
    },
    {
      "epoch": 7.935349322210636,
      "grad_norm": 0.32360604405403137,
      "learning_rate": 1.9517464890169248e-05,
      "loss": 0.0477,
      "step": 7610
    },
    {
      "epoch": 7.94577685088634,
      "grad_norm": 0.27571919560432434,
      "learning_rate": 1.9488656823910698e-05,
      "loss": 0.079,
      "step": 7620
    },
    {
      "epoch": 7.956204379562044,
      "grad_norm": 1.159956932067871,
      "learning_rate": 1.9459848757652144e-05,
      "loss": 0.1596,
      "step": 7630
    },
    {
      "epoch": 7.966631908237748,
      "grad_norm": 1.6047165393829346,
      "learning_rate": 1.943104069139359e-05,
      "loss": 0.0765,
      "step": 7640
    },
    {
      "epoch": 7.977059436913452,
      "grad_norm": 0.3750671148300171,
      "learning_rate": 1.940223262513504e-05,
      "loss": 0.0999,
      "step": 7650
    },
    {
      "epoch": 7.987486965589156,
      "grad_norm": 0.42305466532707214,
      "learning_rate": 1.9373424558876488e-05,
      "loss": 0.1879,
      "step": 7660
    },
    {
      "epoch": 7.997914494264859,
      "grad_norm": 1.860980749130249,
      "learning_rate": 1.9344616492617935e-05,
      "loss": 0.1647,
      "step": 7670
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.7936880542514345,
      "eval_f1": 0.7155699388709097,
      "eval_loss": 0.9298483729362488,
      "eval_precision": 0.7246904588492352,
      "eval_recall": 0.7066761363636364,
      "eval_roc_auc": 0.7754320500449673,
      "eval_runtime": 14.1947,
      "eval_samples_per_second": 270.101,
      "eval_steps_per_second": 16.908,
      "step": 7672
    },
    {
      "epoch": 8.008342022940564,
      "grad_norm": 0.4436578154563904,
      "learning_rate": 1.931580842635938e-05,
      "loss": 0.1266,
      "step": 7680
    },
    {
      "epoch": 8.018769551616266,
      "grad_norm": 3.24049711227417,
      "learning_rate": 1.9287000360100828e-05,
      "loss": 0.1181,
      "step": 7690
    },
    {
      "epoch": 8.02919708029197,
      "grad_norm": 0.32047781348228455,
      "learning_rate": 1.9258192293842278e-05,
      "loss": 0.1111,
      "step": 7700
    },
    {
      "epoch": 8.039624608967674,
      "grad_norm": 1.0527162551879883,
      "learning_rate": 1.9229384227583725e-05,
      "loss": 0.0343,
      "step": 7710
    },
    {
      "epoch": 8.050052137643378,
      "grad_norm": 0.2155463546514511,
      "learning_rate": 1.920057616132517e-05,
      "loss": 0.0521,
      "step": 7720
    },
    {
      "epoch": 8.060479666319083,
      "grad_norm": 0.3729683458805084,
      "learning_rate": 1.917176809506662e-05,
      "loss": 0.1127,
      "step": 7730
    },
    {
      "epoch": 8.070907194994787,
      "grad_norm": 0.19060589373111725,
      "learning_rate": 1.914296002880807e-05,
      "loss": 0.0634,
      "step": 7740
    },
    {
      "epoch": 8.08133472367049,
      "grad_norm": 0.16866686940193176,
      "learning_rate": 1.9114151962549515e-05,
      "loss": 0.007,
      "step": 7750
    },
    {
      "epoch": 8.091762252346195,
      "grad_norm": 5.956084728240967,
      "learning_rate": 1.9085343896290962e-05,
      "loss": 0.1195,
      "step": 7760
    },
    {
      "epoch": 8.102189781021897,
      "grad_norm": 0.16658952832221985,
      "learning_rate": 1.905653583003241e-05,
      "loss": 0.0544,
      "step": 7770
    },
    {
      "epoch": 8.112617309697601,
      "grad_norm": 0.2773154079914093,
      "learning_rate": 1.902772776377386e-05,
      "loss": 0.0573,
      "step": 7780
    },
    {
      "epoch": 8.123044838373305,
      "grad_norm": 0.16449348628520966,
      "learning_rate": 1.8998919697515305e-05,
      "loss": 0.0963,
      "step": 7790
    },
    {
      "epoch": 8.13347236704901,
      "grad_norm": 0.1797148883342743,
      "learning_rate": 1.8970111631256752e-05,
      "loss": 0.1251,
      "step": 7800
    },
    {
      "epoch": 8.143899895724713,
      "grad_norm": 1.1454671621322632,
      "learning_rate": 1.8941303564998202e-05,
      "loss": 0.1279,
      "step": 7810
    },
    {
      "epoch": 8.154327424400417,
      "grad_norm": 0.28861117362976074,
      "learning_rate": 1.891249549873965e-05,
      "loss": 0.0797,
      "step": 7820
    },
    {
      "epoch": 8.164754953076121,
      "grad_norm": 0.24830542504787445,
      "learning_rate": 1.8883687432481096e-05,
      "loss": 0.0821,
      "step": 7830
    },
    {
      "epoch": 8.175182481751825,
      "grad_norm": 2.9434053897857666,
      "learning_rate": 1.8854879366222546e-05,
      "loss": 0.1098,
      "step": 7840
    },
    {
      "epoch": 8.185610010427528,
      "grad_norm": 1.201729655265808,
      "learning_rate": 1.882607129996399e-05,
      "loss": 0.1311,
      "step": 7850
    },
    {
      "epoch": 8.196037539103232,
      "grad_norm": 0.21624088287353516,
      "learning_rate": 1.879726323370544e-05,
      "loss": 0.045,
      "step": 7860
    },
    {
      "epoch": 8.206465067778936,
      "grad_norm": 0.25223052501678467,
      "learning_rate": 1.8768455167446886e-05,
      "loss": 0.1412,
      "step": 7870
    },
    {
      "epoch": 8.21689259645464,
      "grad_norm": 0.2137528955936432,
      "learning_rate": 1.8739647101188332e-05,
      "loss": 0.1378,
      "step": 7880
    },
    {
      "epoch": 8.227320125130344,
      "grad_norm": 0.1974918693304062,
      "learning_rate": 1.8710839034929783e-05,
      "loss": 0.0821,
      "step": 7890
    },
    {
      "epoch": 8.237747653806048,
      "grad_norm": 81.54304504394531,
      "learning_rate": 1.868203096867123e-05,
      "loss": 0.0332,
      "step": 7900
    },
    {
      "epoch": 8.248175182481752,
      "grad_norm": 23.732769012451172,
      "learning_rate": 1.8653222902412676e-05,
      "loss": 0.1019,
      "step": 7910
    },
    {
      "epoch": 8.258602711157456,
      "grad_norm": 0.11630751937627792,
      "learning_rate": 1.8624414836154126e-05,
      "loss": 0.1745,
      "step": 7920
    },
    {
      "epoch": 8.26903023983316,
      "grad_norm": 0.1195245310664177,
      "learning_rate": 1.8595606769895573e-05,
      "loss": 0.065,
      "step": 7930
    },
    {
      "epoch": 8.279457768508863,
      "grad_norm": 0.12193752080202103,
      "learning_rate": 1.856679870363702e-05,
      "loss": 0.101,
      "step": 7940
    },
    {
      "epoch": 8.289885297184567,
      "grad_norm": 0.11051349341869354,
      "learning_rate": 1.8537990637378466e-05,
      "loss": 0.005,
      "step": 7950
    },
    {
      "epoch": 8.30031282586027,
      "grad_norm": 0.2185225486755371,
      "learning_rate": 1.8509182571119916e-05,
      "loss": 0.1812,
      "step": 7960
    },
    {
      "epoch": 8.310740354535975,
      "grad_norm": 0.2641153037548065,
      "learning_rate": 1.8480374504861363e-05,
      "loss": 0.1682,
      "step": 7970
    },
    {
      "epoch": 8.321167883211679,
      "grad_norm": 69.68311309814453,
      "learning_rate": 1.845156643860281e-05,
      "loss": 0.1658,
      "step": 7980
    },
    {
      "epoch": 8.331595411887383,
      "grad_norm": 0.16206520795822144,
      "learning_rate": 1.842275837234426e-05,
      "loss": 0.0216,
      "step": 7990
    },
    {
      "epoch": 8.342022940563087,
      "grad_norm": 0.13877584040164948,
      "learning_rate": 1.8393950306085707e-05,
      "loss": 0.1123,
      "step": 8000
    },
    {
      "epoch": 8.352450469238791,
      "grad_norm": 0.1857367604970932,
      "learning_rate": 1.8365142239827153e-05,
      "loss": 0.136,
      "step": 8010
    },
    {
      "epoch": 8.362877997914495,
      "grad_norm": 0.2531202733516693,
      "learning_rate": 1.8336334173568603e-05,
      "loss": 0.1011,
      "step": 8020
    },
    {
      "epoch": 8.373305526590197,
      "grad_norm": 0.14419446885585785,
      "learning_rate": 1.8307526107310047e-05,
      "loss": 0.0768,
      "step": 8030
    },
    {
      "epoch": 8.383733055265902,
      "grad_norm": 4.097238540649414,
      "learning_rate": 1.8278718041051497e-05,
      "loss": 0.1277,
      "step": 8040
    },
    {
      "epoch": 8.394160583941606,
      "grad_norm": 1.299095630645752,
      "learning_rate": 1.8249909974792943e-05,
      "loss": 0.1642,
      "step": 8050
    },
    {
      "epoch": 8.40458811261731,
      "grad_norm": 0.4078013002872467,
      "learning_rate": 1.822110190853439e-05,
      "loss": 0.1804,
      "step": 8060
    },
    {
      "epoch": 8.415015641293014,
      "grad_norm": 0.22739280760288239,
      "learning_rate": 1.819229384227584e-05,
      "loss": 0.0564,
      "step": 8070
    },
    {
      "epoch": 8.425443169968718,
      "grad_norm": 2.3461594581604004,
      "learning_rate": 1.8163485776017287e-05,
      "loss": 0.1313,
      "step": 8080
    },
    {
      "epoch": 8.435870698644422,
      "grad_norm": 1.993106484413147,
      "learning_rate": 1.8134677709758734e-05,
      "loss": 0.1559,
      "step": 8090
    },
    {
      "epoch": 8.446298227320126,
      "grad_norm": 0.3254243731498718,
      "learning_rate": 1.8105869643500184e-05,
      "loss": 0.0335,
      "step": 8100
    },
    {
      "epoch": 8.456725755995828,
      "grad_norm": 0.22511427104473114,
      "learning_rate": 1.807706157724163e-05,
      "loss": 0.0543,
      "step": 8110
    },
    {
      "epoch": 8.467153284671532,
      "grad_norm": 0.3690996766090393,
      "learning_rate": 1.8048253510983077e-05,
      "loss": 0.3024,
      "step": 8120
    },
    {
      "epoch": 8.477580813347236,
      "grad_norm": 0.22342021763324738,
      "learning_rate": 1.8019445444724524e-05,
      "loss": 0.1156,
      "step": 8130
    },
    {
      "epoch": 8.48800834202294,
      "grad_norm": 11.512334823608398,
      "learning_rate": 1.799063737846597e-05,
      "loss": 0.0871,
      "step": 8140
    },
    {
      "epoch": 8.498435870698644,
      "grad_norm": 3.119873523712158,
      "learning_rate": 1.796182931220742e-05,
      "loss": 0.1413,
      "step": 8150
    },
    {
      "epoch": 8.508863399374349,
      "grad_norm": 12.325425148010254,
      "learning_rate": 1.7933021245948867e-05,
      "loss": 0.1355,
      "step": 8160
    },
    {
      "epoch": 8.519290928050053,
      "grad_norm": 22.87070655822754,
      "learning_rate": 1.7904213179690314e-05,
      "loss": 0.0845,
      "step": 8170
    },
    {
      "epoch": 8.529718456725757,
      "grad_norm": 0.20641282200813293,
      "learning_rate": 1.7875405113431764e-05,
      "loss": 0.1044,
      "step": 8180
    },
    {
      "epoch": 8.540145985401459,
      "grad_norm": 0.42050984501838684,
      "learning_rate": 1.784659704717321e-05,
      "loss": 0.2356,
      "step": 8190
    },
    {
      "epoch": 8.550573514077163,
      "grad_norm": 0.42753365635871887,
      "learning_rate": 1.7817788980914658e-05,
      "loss": 0.0991,
      "step": 8200
    },
    {
      "epoch": 8.561001042752867,
      "grad_norm": 0.24382054805755615,
      "learning_rate": 1.7788980914656104e-05,
      "loss": 0.0277,
      "step": 8210
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.19915656745433807,
      "learning_rate": 1.776017284839755e-05,
      "loss": 0.0358,
      "step": 8220
    },
    {
      "epoch": 8.581856100104275,
      "grad_norm": 88.6968994140625,
      "learning_rate": 1.7731364782139e-05,
      "loss": 0.204,
      "step": 8230
    },
    {
      "epoch": 8.59228362877998,
      "grad_norm": 7.7972211837768555,
      "learning_rate": 1.7702556715880448e-05,
      "loss": 0.1818,
      "step": 8240
    },
    {
      "epoch": 8.602711157455683,
      "grad_norm": 18.136260986328125,
      "learning_rate": 1.7673748649621895e-05,
      "loss": 0.0917,
      "step": 8250
    },
    {
      "epoch": 8.613138686131387,
      "grad_norm": 156.99246215820312,
      "learning_rate": 1.7644940583363345e-05,
      "loss": 0.1397,
      "step": 8260
    },
    {
      "epoch": 8.623566214807092,
      "grad_norm": 111.12399291992188,
      "learning_rate": 1.761613251710479e-05,
      "loss": 0.1843,
      "step": 8270
    },
    {
      "epoch": 8.633993743482794,
      "grad_norm": 2.55723237991333,
      "learning_rate": 1.7587324450846238e-05,
      "loss": 0.1141,
      "step": 8280
    },
    {
      "epoch": 8.644421272158498,
      "grad_norm": 0.24209897220134735,
      "learning_rate": 1.7558516384587685e-05,
      "loss": 0.1313,
      "step": 8290
    },
    {
      "epoch": 8.654848800834202,
      "grad_norm": 0.2360186129808426,
      "learning_rate": 1.752970831832913e-05,
      "loss": 0.0774,
      "step": 8300
    },
    {
      "epoch": 8.665276329509906,
      "grad_norm": 0.20845988392829895,
      "learning_rate": 1.750090025207058e-05,
      "loss": 0.0083,
      "step": 8310
    },
    {
      "epoch": 8.67570385818561,
      "grad_norm": 0.5070065259933472,
      "learning_rate": 1.747209218581203e-05,
      "loss": 0.0707,
      "step": 8320
    },
    {
      "epoch": 8.686131386861314,
      "grad_norm": 0.9952930212020874,
      "learning_rate": 1.7443284119553475e-05,
      "loss": 0.1474,
      "step": 8330
    },
    {
      "epoch": 8.696558915537018,
      "grad_norm": 2.0994350910186768,
      "learning_rate": 1.7414476053294925e-05,
      "loss": 0.1803,
      "step": 8340
    },
    {
      "epoch": 8.706986444212722,
      "grad_norm": 0.2985491156578064,
      "learning_rate": 1.7385667987036372e-05,
      "loss": 0.0516,
      "step": 8350
    },
    {
      "epoch": 8.717413972888426,
      "grad_norm": 4.888949871063232,
      "learning_rate": 1.735685992077782e-05,
      "loss": 0.0858,
      "step": 8360
    },
    {
      "epoch": 8.727841501564129,
      "grad_norm": 0.25238168239593506,
      "learning_rate": 1.732805185451927e-05,
      "loss": 0.0956,
      "step": 8370
    },
    {
      "epoch": 8.738269030239833,
      "grad_norm": 0.22880685329437256,
      "learning_rate": 1.7299243788260712e-05,
      "loss": 0.0474,
      "step": 8380
    },
    {
      "epoch": 8.748696558915537,
      "grad_norm": 0.18426306545734406,
      "learning_rate": 1.7270435722002162e-05,
      "loss": 0.0071,
      "step": 8390
    },
    {
      "epoch": 8.75912408759124,
      "grad_norm": 0.15781407058238983,
      "learning_rate": 1.724162765574361e-05,
      "loss": 0.1157,
      "step": 8400
    },
    {
      "epoch": 8.769551616266945,
      "grad_norm": 0.20039284229278564,
      "learning_rate": 1.7212819589485056e-05,
      "loss": 0.1848,
      "step": 8410
    },
    {
      "epoch": 8.779979144942649,
      "grad_norm": 83.16275024414062,
      "learning_rate": 1.7184011523226506e-05,
      "loss": 0.2096,
      "step": 8420
    },
    {
      "epoch": 8.790406673618353,
      "grad_norm": 3.091756820678711,
      "learning_rate": 1.7155203456967952e-05,
      "loss": 0.1626,
      "step": 8430
    },
    {
      "epoch": 8.800834202294057,
      "grad_norm": 0.38552966713905334,
      "learning_rate": 1.71263953907094e-05,
      "loss": 0.0475,
      "step": 8440
    },
    {
      "epoch": 8.81126173096976,
      "grad_norm": 0.24860410392284393,
      "learning_rate": 1.709758732445085e-05,
      "loss": 0.1283,
      "step": 8450
    },
    {
      "epoch": 8.821689259645463,
      "grad_norm": 2.077301263809204,
      "learning_rate": 1.7068779258192296e-05,
      "loss": 0.0844,
      "step": 8460
    },
    {
      "epoch": 8.832116788321168,
      "grad_norm": 1.506995677947998,
      "learning_rate": 1.7039971191933743e-05,
      "loss": 0.0824,
      "step": 8470
    },
    {
      "epoch": 8.842544316996872,
      "grad_norm": 0.2553907334804535,
      "learning_rate": 1.701116312567519e-05,
      "loss": 0.1319,
      "step": 8480
    },
    {
      "epoch": 8.852971845672576,
      "grad_norm": 2.2055861949920654,
      "learning_rate": 1.6982355059416636e-05,
      "loss": 0.1069,
      "step": 8490
    },
    {
      "epoch": 8.86339937434828,
      "grad_norm": 704.170166015625,
      "learning_rate": 1.6953546993158086e-05,
      "loss": 0.0189,
      "step": 8500
    },
    {
      "epoch": 8.873826903023984,
      "grad_norm": 0.23794250190258026,
      "learning_rate": 1.6924738926899533e-05,
      "loss": 0.1843,
      "step": 8510
    },
    {
      "epoch": 8.884254431699688,
      "grad_norm": 21.310714721679688,
      "learning_rate": 1.689593086064098e-05,
      "loss": 0.065,
      "step": 8520
    },
    {
      "epoch": 8.89468196037539,
      "grad_norm": 0.20652036368846893,
      "learning_rate": 1.686712279438243e-05,
      "loss": 0.0583,
      "step": 8530
    },
    {
      "epoch": 8.905109489051094,
      "grad_norm": 0.18538214266300201,
      "learning_rate": 1.6838314728123876e-05,
      "loss": 0.1115,
      "step": 8540
    },
    {
      "epoch": 8.915537017726798,
      "grad_norm": 0.164119690656662,
      "learning_rate": 1.6809506661865323e-05,
      "loss": 0.0927,
      "step": 8550
    },
    {
      "epoch": 8.925964546402502,
      "grad_norm": 0.3855932354927063,
      "learning_rate": 1.678069859560677e-05,
      "loss": 0.1824,
      "step": 8560
    },
    {
      "epoch": 8.936392075078206,
      "grad_norm": 17.812097549438477,
      "learning_rate": 1.675189052934822e-05,
      "loss": 0.1987,
      "step": 8570
    },
    {
      "epoch": 8.94681960375391,
      "grad_norm": 0.31071028113365173,
      "learning_rate": 1.6723082463089667e-05,
      "loss": 0.0819,
      "step": 8580
    },
    {
      "epoch": 8.957247132429615,
      "grad_norm": 1.619239330291748,
      "learning_rate": 1.6694274396831113e-05,
      "loss": 0.0905,
      "step": 8590
    },
    {
      "epoch": 8.967674661105319,
      "grad_norm": 0.35085996985435486,
      "learning_rate": 1.6665466330572563e-05,
      "loss": 0.1242,
      "step": 8600
    },
    {
      "epoch": 8.978102189781023,
      "grad_norm": 0.20947131514549255,
      "learning_rate": 1.663665826431401e-05,
      "loss": 0.1482,
      "step": 8610
    },
    {
      "epoch": 8.988529718456725,
      "grad_norm": 0.9513867497444153,
      "learning_rate": 1.6607850198055457e-05,
      "loss": 0.0511,
      "step": 8620
    },
    {
      "epoch": 8.998957247132429,
      "grad_norm": 0.17356345057487488,
      "learning_rate": 1.6579042131796907e-05,
      "loss": 0.1254,
      "step": 8630
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.7738654147104851,
      "eval_f1": 0.7152709359605911,
      "eval_loss": 1.0448561906814575,
      "eval_precision": 0.6652412950519242,
      "eval_recall": 0.7734375,
      "eval_roc_auc": 0.7737756337592745,
      "eval_runtime": 13.6358,
      "eval_samples_per_second": 281.171,
      "eval_steps_per_second": 17.601,
      "step": 8631
    },
    {
      "epoch": 9.009384775808133,
      "grad_norm": 0.24862003326416016,
      "learning_rate": 1.6550234065538354e-05,
      "loss": 0.1912,
      "step": 8640
    },
    {
      "epoch": 9.019812304483837,
      "grad_norm": 0.19231422245502472,
      "learning_rate": 1.65214259992798e-05,
      "loss": 0.0081,
      "step": 8650
    },
    {
      "epoch": 9.030239833159541,
      "grad_norm": 0.15632785856723785,
      "learning_rate": 1.6492617933021247e-05,
      "loss": 0.0308,
      "step": 8660
    },
    {
      "epoch": 9.040667361835245,
      "grad_norm": 18.17394256591797,
      "learning_rate": 1.6463809866762694e-05,
      "loss": 0.1424,
      "step": 8670
    },
    {
      "epoch": 9.05109489051095,
      "grad_norm": 1.3021674156188965,
      "learning_rate": 1.6435001800504144e-05,
      "loss": 0.0383,
      "step": 8680
    },
    {
      "epoch": 9.061522419186653,
      "grad_norm": 0.24971862137317657,
      "learning_rate": 1.640619373424559e-05,
      "loss": 0.0935,
      "step": 8690
    },
    {
      "epoch": 9.071949947862356,
      "grad_norm": 0.162899449467659,
      "learning_rate": 1.6377385667987037e-05,
      "loss": 0.1563,
      "step": 8700
    },
    {
      "epoch": 9.08237747653806,
      "grad_norm": 0.17069397866725922,
      "learning_rate": 1.6348577601728487e-05,
      "loss": 0.0509,
      "step": 8710
    },
    {
      "epoch": 9.092805005213764,
      "grad_norm": 0.16639646887779236,
      "learning_rate": 1.6319769535469934e-05,
      "loss": 0.0737,
      "step": 8720
    },
    {
      "epoch": 9.103232533889468,
      "grad_norm": 0.17469292879104614,
      "learning_rate": 1.629096146921138e-05,
      "loss": 0.109,
      "step": 8730
    },
    {
      "epoch": 9.113660062565172,
      "grad_norm": 0.16093318164348602,
      "learning_rate": 1.6262153402952827e-05,
      "loss": 0.0371,
      "step": 8740
    },
    {
      "epoch": 9.124087591240876,
      "grad_norm": 32.63687515258789,
      "learning_rate": 1.6233345336694274e-05,
      "loss": 0.1485,
      "step": 8750
    },
    {
      "epoch": 9.13451511991658,
      "grad_norm": 2.327155113220215,
      "learning_rate": 1.6204537270435724e-05,
      "loss": 0.1222,
      "step": 8760
    },
    {
      "epoch": 9.144942648592284,
      "grad_norm": 0.31954920291900635,
      "learning_rate": 1.617572920417717e-05,
      "loss": 0.0563,
      "step": 8770
    },
    {
      "epoch": 9.155370177267988,
      "grad_norm": 0.1841932237148285,
      "learning_rate": 1.6146921137918618e-05,
      "loss": 0.1462,
      "step": 8780
    },
    {
      "epoch": 9.16579770594369,
      "grad_norm": 0.1919015645980835,
      "learning_rate": 1.6118113071660068e-05,
      "loss": 0.0567,
      "step": 8790
    },
    {
      "epoch": 9.176225234619395,
      "grad_norm": 0.19692356884479523,
      "learning_rate": 1.6089305005401514e-05,
      "loss": 0.1283,
      "step": 8800
    },
    {
      "epoch": 9.186652763295099,
      "grad_norm": 0.20207059383392334,
      "learning_rate": 1.606049693914296e-05,
      "loss": 0.0435,
      "step": 8810
    },
    {
      "epoch": 9.197080291970803,
      "grad_norm": 0.17167140543460846,
      "learning_rate": 1.603168887288441e-05,
      "loss": 0.0309,
      "step": 8820
    },
    {
      "epoch": 9.207507820646507,
      "grad_norm": 0.15439578890800476,
      "learning_rate": 1.6002880806625855e-05,
      "loss": 0.074,
      "step": 8830
    },
    {
      "epoch": 9.217935349322211,
      "grad_norm": 0.7050434947013855,
      "learning_rate": 1.5974072740367305e-05,
      "loss": 0.0576,
      "step": 8840
    },
    {
      "epoch": 9.228362877997915,
      "grad_norm": 0.14499446749687195,
      "learning_rate": 1.594526467410875e-05,
      "loss": 0.1538,
      "step": 8850
    },
    {
      "epoch": 9.238790406673619,
      "grad_norm": 0.14777128398418427,
      "learning_rate": 1.5916456607850198e-05,
      "loss": 0.0369,
      "step": 8860
    },
    {
      "epoch": 9.249217935349321,
      "grad_norm": 0.14859536290168762,
      "learning_rate": 1.5887648541591648e-05,
      "loss": 0.0852,
      "step": 8870
    },
    {
      "epoch": 9.259645464025025,
      "grad_norm": 1.8338868618011475,
      "learning_rate": 1.5858840475333095e-05,
      "loss": 0.0667,
      "step": 8880
    },
    {
      "epoch": 9.27007299270073,
      "grad_norm": 0.14096282422542572,
      "learning_rate": 1.583003240907454e-05,
      "loss": 0.069,
      "step": 8890
    },
    {
      "epoch": 9.280500521376434,
      "grad_norm": 90.1634292602539,
      "learning_rate": 1.5801224342815992e-05,
      "loss": 0.1667,
      "step": 8900
    },
    {
      "epoch": 9.290928050052138,
      "grad_norm": 0.12909506261348724,
      "learning_rate": 1.577241627655744e-05,
      "loss": 0.0051,
      "step": 8910
    },
    {
      "epoch": 9.301355578727842,
      "grad_norm": 0.17317889630794525,
      "learning_rate": 1.5743608210298885e-05,
      "loss": 0.0657,
      "step": 8920
    },
    {
      "epoch": 9.311783107403546,
      "grad_norm": 0.11098964512348175,
      "learning_rate": 1.5714800144040332e-05,
      "loss": 0.0296,
      "step": 8930
    },
    {
      "epoch": 9.32221063607925,
      "grad_norm": 0.09682808816432953,
      "learning_rate": 1.568599207778178e-05,
      "loss": 0.0671,
      "step": 8940
    },
    {
      "epoch": 9.332638164754954,
      "grad_norm": 94.9344711303711,
      "learning_rate": 1.565718401152323e-05,
      "loss": 0.1801,
      "step": 8950
    },
    {
      "epoch": 9.343065693430656,
      "grad_norm": 60.281982421875,
      "learning_rate": 1.5628375945264675e-05,
      "loss": 0.2332,
      "step": 8960
    },
    {
      "epoch": 9.35349322210636,
      "grad_norm": 0.1620955616235733,
      "learning_rate": 1.5599567879006122e-05,
      "loss": 0.0526,
      "step": 8970
    },
    {
      "epoch": 9.363920750782064,
      "grad_norm": 31.934864044189453,
      "learning_rate": 1.5570759812747572e-05,
      "loss": 0.1632,
      "step": 8980
    },
    {
      "epoch": 9.374348279457768,
      "grad_norm": 0.6321656703948975,
      "learning_rate": 1.554195174648902e-05,
      "loss": 0.1473,
      "step": 8990
    },
    {
      "epoch": 9.384775808133472,
      "grad_norm": 0.17091508209705353,
      "learning_rate": 1.5513143680230466e-05,
      "loss": 0.074,
      "step": 9000
    },
    {
      "epoch": 9.395203336809177,
      "grad_norm": 0.14912055432796478,
      "learning_rate": 1.5484335613971912e-05,
      "loss": 0.0676,
      "step": 9010
    },
    {
      "epoch": 9.40563086548488,
      "grad_norm": 0.18106625974178314,
      "learning_rate": 1.545552754771336e-05,
      "loss": 0.11,
      "step": 9020
    },
    {
      "epoch": 9.416058394160585,
      "grad_norm": 0.17071813344955444,
      "learning_rate": 1.542671948145481e-05,
      "loss": 0.0499,
      "step": 9030
    },
    {
      "epoch": 9.426485922836287,
      "grad_norm": 2.77487850189209,
      "learning_rate": 1.5397911415196256e-05,
      "loss": 0.1298,
      "step": 9040
    },
    {
      "epoch": 9.436913451511991,
      "grad_norm": 0.15336324274539948,
      "learning_rate": 1.5369103348937703e-05,
      "loss": 0.1102,
      "step": 9050
    },
    {
      "epoch": 9.447340980187695,
      "grad_norm": 0.15727664530277252,
      "learning_rate": 1.5340295282679153e-05,
      "loss": 0.0496,
      "step": 9060
    },
    {
      "epoch": 9.4577685088634,
      "grad_norm": 18.57365608215332,
      "learning_rate": 1.53114872164206e-05,
      "loss": 0.0918,
      "step": 9070
    },
    {
      "epoch": 9.468196037539103,
      "grad_norm": 0.13664180040359497,
      "learning_rate": 1.5282679150162046e-05,
      "loss": 0.0056,
      "step": 9080
    },
    {
      "epoch": 9.478623566214807,
      "grad_norm": 0.5003829598426819,
      "learning_rate": 1.5253871083903493e-05,
      "loss": 0.1044,
      "step": 9090
    },
    {
      "epoch": 9.489051094890511,
      "grad_norm": 0.1268462836742401,
      "learning_rate": 1.5225063017644941e-05,
      "loss": 0.063,
      "step": 9100
    },
    {
      "epoch": 9.499478623566215,
      "grad_norm": 0.15936364233493805,
      "learning_rate": 1.519625495138639e-05,
      "loss": 0.0854,
      "step": 9110
    },
    {
      "epoch": 9.50990615224192,
      "grad_norm": 2.167297840118408,
      "learning_rate": 1.5167446885127836e-05,
      "loss": 0.1411,
      "step": 9120
    },
    {
      "epoch": 9.520333680917622,
      "grad_norm": 0.17469745874404907,
      "learning_rate": 1.5138638818869285e-05,
      "loss": 0.1019,
      "step": 9130
    },
    {
      "epoch": 9.530761209593326,
      "grad_norm": 0.18427444994449615,
      "learning_rate": 1.5109830752610733e-05,
      "loss": 0.0616,
      "step": 9140
    },
    {
      "epoch": 9.54118873826903,
      "grad_norm": 0.5165883898735046,
      "learning_rate": 1.508102268635218e-05,
      "loss": 0.0196,
      "step": 9150
    },
    {
      "epoch": 9.551616266944734,
      "grad_norm": 0.16144202649593353,
      "learning_rate": 1.5052214620093628e-05,
      "loss": 0.0686,
      "step": 9160
    },
    {
      "epoch": 9.562043795620438,
      "grad_norm": 0.183614119887352,
      "learning_rate": 1.5023406553835077e-05,
      "loss": 0.0564,
      "step": 9170
    },
    {
      "epoch": 9.572471324296142,
      "grad_norm": 0.1185927614569664,
      "learning_rate": 1.4994598487576522e-05,
      "loss": 0.0787,
      "step": 9180
    },
    {
      "epoch": 9.582898852971846,
      "grad_norm": 0.17675131559371948,
      "learning_rate": 1.496579042131797e-05,
      "loss": 0.0759,
      "step": 9190
    },
    {
      "epoch": 9.59332638164755,
      "grad_norm": 225.07142639160156,
      "learning_rate": 1.4936982355059417e-05,
      "loss": 0.0713,
      "step": 9200
    },
    {
      "epoch": 9.603753910323253,
      "grad_norm": 0.21102173626422882,
      "learning_rate": 1.4908174288800865e-05,
      "loss": 0.0989,
      "step": 9210
    },
    {
      "epoch": 9.614181438998957,
      "grad_norm": 0.16053558886051178,
      "learning_rate": 1.4879366222542314e-05,
      "loss": 0.1115,
      "step": 9220
    },
    {
      "epoch": 9.62460896767466,
      "grad_norm": 0.7372764945030212,
      "learning_rate": 1.485055815628376e-05,
      "loss": 0.1511,
      "step": 9230
    },
    {
      "epoch": 9.635036496350365,
      "grad_norm": 0.15108931064605713,
      "learning_rate": 1.4821750090025209e-05,
      "loss": 0.0568,
      "step": 9240
    },
    {
      "epoch": 9.645464025026069,
      "grad_norm": 0.1561630517244339,
      "learning_rate": 1.4792942023766657e-05,
      "loss": 0.0487,
      "step": 9250
    },
    {
      "epoch": 9.655891553701773,
      "grad_norm": 0.17072519659996033,
      "learning_rate": 1.4764133957508104e-05,
      "loss": 0.121,
      "step": 9260
    },
    {
      "epoch": 9.666319082377477,
      "grad_norm": 0.17606283724308014,
      "learning_rate": 1.473532589124955e-05,
      "loss": 0.179,
      "step": 9270
    },
    {
      "epoch": 9.676746611053181,
      "grad_norm": 0.18144740164279938,
      "learning_rate": 1.4706517824990997e-05,
      "loss": 0.0968,
      "step": 9280
    },
    {
      "epoch": 9.687174139728885,
      "grad_norm": 0.20907635986804962,
      "learning_rate": 1.4677709758732446e-05,
      "loss": 0.0908,
      "step": 9290
    },
    {
      "epoch": 9.697601668404587,
      "grad_norm": 2.3638851642608643,
      "learning_rate": 1.4648901692473894e-05,
      "loss": 0.0633,
      "step": 9300
    },
    {
      "epoch": 9.708029197080291,
      "grad_norm": 0.159892275929451,
      "learning_rate": 1.462009362621534e-05,
      "loss": 0.0341,
      "step": 9310
    },
    {
      "epoch": 9.718456725755996,
      "grad_norm": 0.17179900407791138,
      "learning_rate": 1.4591285559956789e-05,
      "loss": 0.1738,
      "step": 9320
    },
    {
      "epoch": 9.7288842544317,
      "grad_norm": 0.39452797174453735,
      "learning_rate": 1.4562477493698238e-05,
      "loss": 0.0941,
      "step": 9330
    },
    {
      "epoch": 9.739311783107404,
      "grad_norm": 115.98982238769531,
      "learning_rate": 1.4533669427439684e-05,
      "loss": 0.1086,
      "step": 9340
    },
    {
      "epoch": 9.749739311783108,
      "grad_norm": 2.3038597106933594,
      "learning_rate": 1.4504861361181133e-05,
      "loss": 0.0901,
      "step": 9350
    },
    {
      "epoch": 9.760166840458812,
      "grad_norm": 0.19148318469524384,
      "learning_rate": 1.4476053294922578e-05,
      "loss": 0.0095,
      "step": 9360
    },
    {
      "epoch": 9.770594369134516,
      "grad_norm": 0.1607433706521988,
      "learning_rate": 1.4447245228664026e-05,
      "loss": 0.0592,
      "step": 9370
    },
    {
      "epoch": 9.78102189781022,
      "grad_norm": 0.17751221358776093,
      "learning_rate": 1.4418437162405474e-05,
      "loss": 0.1108,
      "step": 9380
    },
    {
      "epoch": 9.791449426485922,
      "grad_norm": 0.19396665692329407,
      "learning_rate": 1.4389629096146923e-05,
      "loss": 0.0965,
      "step": 9390
    },
    {
      "epoch": 9.801876955161626,
      "grad_norm": 0.1780242919921875,
      "learning_rate": 1.436082102988837e-05,
      "loss": 0.0313,
      "step": 9400
    },
    {
      "epoch": 9.81230448383733,
      "grad_norm": 1.305856466293335,
      "learning_rate": 1.4332012963629818e-05,
      "loss": 0.0871,
      "step": 9410
    },
    {
      "epoch": 9.822732012513034,
      "grad_norm": 0.24210549890995026,
      "learning_rate": 1.4303204897371266e-05,
      "loss": 0.1657,
      "step": 9420
    },
    {
      "epoch": 9.833159541188738,
      "grad_norm": 0.17564639449119568,
      "learning_rate": 1.4274396831112713e-05,
      "loss": 0.0466,
      "step": 9430
    },
    {
      "epoch": 9.843587069864443,
      "grad_norm": 25.221025466918945,
      "learning_rate": 1.4245588764854162e-05,
      "loss": 0.112,
      "step": 9440
    },
    {
      "epoch": 9.854014598540147,
      "grad_norm": 0.6215439438819885,
      "learning_rate": 1.4216780698595607e-05,
      "loss": 0.0299,
      "step": 9450
    },
    {
      "epoch": 9.86444212721585,
      "grad_norm": 0.15753495693206787,
      "learning_rate": 1.4187972632337055e-05,
      "loss": 0.0558,
      "step": 9460
    },
    {
      "epoch": 9.874869655891553,
      "grad_norm": 0.14299733936786652,
      "learning_rate": 1.4159164566078503e-05,
      "loss": 0.0561,
      "step": 9470
    },
    {
      "epoch": 9.885297184567257,
      "grad_norm": 0.12894029915332794,
      "learning_rate": 1.413035649981995e-05,
      "loss": 0.0661,
      "step": 9480
    },
    {
      "epoch": 9.895724713242961,
      "grad_norm": 0.1366252899169922,
      "learning_rate": 1.4101548433561398e-05,
      "loss": 0.2058,
      "step": 9490
    },
    {
      "epoch": 9.906152241918665,
      "grad_norm": 0.1793668419122696,
      "learning_rate": 1.4072740367302847e-05,
      "loss": 0.1075,
      "step": 9500
    },
    {
      "epoch": 9.91657977059437,
      "grad_norm": 15.297500610351562,
      "learning_rate": 1.4043932301044294e-05,
      "loss": 0.0761,
      "step": 9510
    },
    {
      "epoch": 9.927007299270073,
      "grad_norm": 0.22127215564250946,
      "learning_rate": 1.4015124234785742e-05,
      "loss": 0.1184,
      "step": 9520
    },
    {
      "epoch": 9.937434827945777,
      "grad_norm": 0.15451130270957947,
      "learning_rate": 1.398631616852719e-05,
      "loss": 0.0826,
      "step": 9530
    },
    {
      "epoch": 9.947862356621481,
      "grad_norm": 38.903438568115234,
      "learning_rate": 1.3957508102268635e-05,
      "loss": 0.1289,
      "step": 9540
    },
    {
      "epoch": 9.958289885297184,
      "grad_norm": 46.7094612121582,
      "learning_rate": 1.3928700036010084e-05,
      "loss": 0.1177,
      "step": 9550
    },
    {
      "epoch": 9.968717413972888,
      "grad_norm": 54.1380729675293,
      "learning_rate": 1.389989196975153e-05,
      "loss": 0.0605,
      "step": 9560
    },
    {
      "epoch": 9.979144942648592,
      "grad_norm": 0.16558630764484406,
      "learning_rate": 1.3871083903492979e-05,
      "loss": 0.1604,
      "step": 9570
    },
    {
      "epoch": 9.989572471324296,
      "grad_norm": 0.15465781092643738,
      "learning_rate": 1.3842275837234427e-05,
      "loss": 0.1723,
      "step": 9580
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.3020763397216797,
      "learning_rate": 1.3813467770975874e-05,
      "loss": 0.0649,
      "step": 9590
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.7949921752738655,
      "eval_f1": 0.7078066914498141,
      "eval_loss": 1.0863738059997559,
      "eval_precision": 0.7425897035881436,
      "eval_recall": 0.6761363636363636,
      "eval_roc_auc": 0.7700549913812487,
      "eval_runtime": 13.5818,
      "eval_samples_per_second": 282.291,
      "eval_steps_per_second": 17.671,
      "step": 9590
    },
    {
      "epoch": 10.010427528675704,
      "grad_norm": 0.16781559586524963,
      "learning_rate": 1.3784659704717322e-05,
      "loss": 0.0354,
      "step": 9600
    },
    {
      "epoch": 10.020855057351408,
      "grad_norm": 2.151499032974243,
      "learning_rate": 1.375585163845877e-05,
      "loss": 0.0586,
      "step": 9610
    },
    {
      "epoch": 10.031282586027112,
      "grad_norm": 0.13732698559761047,
      "learning_rate": 1.3727043572200218e-05,
      "loss": 0.0304,
      "step": 9620
    },
    {
      "epoch": 10.041710114702816,
      "grad_norm": 0.12915398180484772,
      "learning_rate": 1.3698235505941664e-05,
      "loss": 0.1265,
      "step": 9630
    },
    {
      "epoch": 10.052137643378519,
      "grad_norm": 0.1769280582666397,
      "learning_rate": 1.3669427439683111e-05,
      "loss": 0.172,
      "step": 9640
    },
    {
      "epoch": 10.062565172054223,
      "grad_norm": 0.1581023931503296,
      "learning_rate": 1.364061937342456e-05,
      "loss": 0.0655,
      "step": 9650
    },
    {
      "epoch": 10.072992700729927,
      "grad_norm": 0.15982559323310852,
      "learning_rate": 1.3611811307166008e-05,
      "loss": 0.0683,
      "step": 9660
    },
    {
      "epoch": 10.08342022940563,
      "grad_norm": 54.1312370300293,
      "learning_rate": 1.3583003240907454e-05,
      "loss": 0.0787,
      "step": 9670
    },
    {
      "epoch": 10.093847758081335,
      "grad_norm": 0.5640804171562195,
      "learning_rate": 1.3554195174648903e-05,
      "loss": 0.1573,
      "step": 9680
    },
    {
      "epoch": 10.104275286757039,
      "grad_norm": 0.26358118653297424,
      "learning_rate": 1.3525387108390351e-05,
      "loss": 0.0774,
      "step": 9690
    },
    {
      "epoch": 10.114702815432743,
      "grad_norm": 0.40523433685302734,
      "learning_rate": 1.3496579042131798e-05,
      "loss": 0.1039,
      "step": 9700
    },
    {
      "epoch": 10.125130344108447,
      "grad_norm": 0.20552699267864227,
      "learning_rate": 1.3467770975873246e-05,
      "loss": 0.1511,
      "step": 9710
    },
    {
      "epoch": 10.13555787278415,
      "grad_norm": 4.553500175476074,
      "learning_rate": 1.3438962909614693e-05,
      "loss": 0.0079,
      "step": 9720
    },
    {
      "epoch": 10.145985401459853,
      "grad_norm": 0.179287388920784,
      "learning_rate": 1.341015484335614e-05,
      "loss": 0.0742,
      "step": 9730
    },
    {
      "epoch": 10.156412930135557,
      "grad_norm": 4.9796833992004395,
      "learning_rate": 1.3381346777097588e-05,
      "loss": 0.1665,
      "step": 9740
    },
    {
      "epoch": 10.166840458811262,
      "grad_norm": 0.16421785950660706,
      "learning_rate": 1.3352538710839037e-05,
      "loss": 0.0636,
      "step": 9750
    },
    {
      "epoch": 10.177267987486966,
      "grad_norm": 0.1588706076145172,
      "learning_rate": 1.3323730644580483e-05,
      "loss": 0.0254,
      "step": 9760
    },
    {
      "epoch": 10.18769551616267,
      "grad_norm": 4.213564395904541,
      "learning_rate": 1.3294922578321932e-05,
      "loss": 0.0871,
      "step": 9770
    },
    {
      "epoch": 10.198123044838374,
      "grad_norm": 0.19488103687763214,
      "learning_rate": 1.326611451206338e-05,
      "loss": 0.0049,
      "step": 9780
    },
    {
      "epoch": 10.208550573514078,
      "grad_norm": 2.6333441734313965,
      "learning_rate": 1.3237306445804827e-05,
      "loss": 0.1527,
      "step": 9790
    },
    {
      "epoch": 10.218978102189782,
      "grad_norm": 0.12872205674648285,
      "learning_rate": 1.3208498379546275e-05,
      "loss": 0.0046,
      "step": 9800
    },
    {
      "epoch": 10.229405630865484,
      "grad_norm": 0.12243814021348953,
      "learning_rate": 1.317969031328772e-05,
      "loss": 0.1314,
      "step": 9810
    },
    {
      "epoch": 10.239833159541188,
      "grad_norm": 0.1459740549325943,
      "learning_rate": 1.3150882247029169e-05,
      "loss": 0.0961,
      "step": 9820
    },
    {
      "epoch": 10.250260688216892,
      "grad_norm": 0.17548681795597076,
      "learning_rate": 1.3122074180770617e-05,
      "loss": 0.0695,
      "step": 9830
    },
    {
      "epoch": 10.260688216892596,
      "grad_norm": 1.3678646087646484,
      "learning_rate": 1.3093266114512064e-05,
      "loss": 0.1441,
      "step": 9840
    },
    {
      "epoch": 10.2711157455683,
      "grad_norm": 0.17218956351280212,
      "learning_rate": 1.3064458048253512e-05,
      "loss": 0.008,
      "step": 9850
    },
    {
      "epoch": 10.281543274244004,
      "grad_norm": 0.17258702218532562,
      "learning_rate": 1.303564998199496e-05,
      "loss": 0.0825,
      "step": 9860
    },
    {
      "epoch": 10.291970802919709,
      "grad_norm": 0.1942005157470703,
      "learning_rate": 1.3006841915736407e-05,
      "loss": 0.1026,
      "step": 9870
    },
    {
      "epoch": 10.302398331595413,
      "grad_norm": 0.16514521837234497,
      "learning_rate": 1.2978033849477856e-05,
      "loss": 0.0647,
      "step": 9880
    },
    {
      "epoch": 10.312825860271115,
      "grad_norm": 1.4479302167892456,
      "learning_rate": 1.2949225783219304e-05,
      "loss": 0.1159,
      "step": 9890
    },
    {
      "epoch": 10.323253388946819,
      "grad_norm": 0.15606191754341125,
      "learning_rate": 1.2920417716960749e-05,
      "loss": 0.0247,
      "step": 9900
    },
    {
      "epoch": 10.333680917622523,
      "grad_norm": 0.13039810955524445,
      "learning_rate": 1.2891609650702198e-05,
      "loss": 0.0395,
      "step": 9910
    },
    {
      "epoch": 10.344108446298227,
      "grad_norm": 0.11864178627729416,
      "learning_rate": 1.2862801584443644e-05,
      "loss": 0.0401,
      "step": 9920
    },
    {
      "epoch": 10.354535974973931,
      "grad_norm": 0.09183698892593384,
      "learning_rate": 1.2833993518185093e-05,
      "loss": 0.0698,
      "step": 9930
    },
    {
      "epoch": 10.364963503649635,
      "grad_norm": 0.12280704826116562,
      "learning_rate": 1.2805185451926541e-05,
      "loss": 0.1703,
      "step": 9940
    },
    {
      "epoch": 10.37539103232534,
      "grad_norm": 4.208337783813477,
      "learning_rate": 1.2776377385667988e-05,
      "loss": 0.0633,
      "step": 9950
    },
    {
      "epoch": 10.385818561001043,
      "grad_norm": 0.10968603193759918,
      "learning_rate": 1.2747569319409436e-05,
      "loss": 0.0915,
      "step": 9960
    },
    {
      "epoch": 10.396246089676747,
      "grad_norm": 0.21852938830852509,
      "learning_rate": 1.2718761253150885e-05,
      "loss": 0.0047,
      "step": 9970
    },
    {
      "epoch": 10.40667361835245,
      "grad_norm": 0.10089114308357239,
      "learning_rate": 1.268995318689233e-05,
      "loss": 0.0039,
      "step": 9980
    },
    {
      "epoch": 10.417101147028154,
      "grad_norm": 11.36947250366211,
      "learning_rate": 1.2661145120633778e-05,
      "loss": 0.0702,
      "step": 9990
    },
    {
      "epoch": 10.427528675703858,
      "grad_norm": 0.09875167906284332,
      "learning_rate": 1.2632337054375225e-05,
      "loss": 0.0619,
      "step": 10000
    },
    {
      "epoch": 10.437956204379562,
      "grad_norm": 0.09749369323253632,
      "learning_rate": 1.2603528988116673e-05,
      "loss": 0.0507,
      "step": 10010
    },
    {
      "epoch": 10.448383733055266,
      "grad_norm": 0.30555039644241333,
      "learning_rate": 1.2574720921858122e-05,
      "loss": 0.0453,
      "step": 10020
    },
    {
      "epoch": 10.45881126173097,
      "grad_norm": 0.10035964846611023,
      "learning_rate": 1.254591285559957e-05,
      "loss": 0.0353,
      "step": 10030
    },
    {
      "epoch": 10.469238790406674,
      "grad_norm": 0.08629801869392395,
      "learning_rate": 1.2517104789341017e-05,
      "loss": 0.0038,
      "step": 10040
    },
    {
      "epoch": 10.479666319082378,
      "grad_norm": 0.08990383893251419,
      "learning_rate": 1.2488296723082465e-05,
      "loss": 0.1535,
      "step": 10050
    },
    {
      "epoch": 10.49009384775808,
      "grad_norm": 0.3153510093688965,
      "learning_rate": 1.2459488656823913e-05,
      "loss": 0.0502,
      "step": 10060
    },
    {
      "epoch": 10.500521376433785,
      "grad_norm": 0.37793809175491333,
      "learning_rate": 1.2430680590565358e-05,
      "loss": 0.0716,
      "step": 10070
    },
    {
      "epoch": 10.510948905109489,
      "grad_norm": 0.08778388053178787,
      "learning_rate": 1.2401872524306807e-05,
      "loss": 0.0751,
      "step": 10080
    },
    {
      "epoch": 10.521376433785193,
      "grad_norm": 0.45940905809402466,
      "learning_rate": 1.2373064458048254e-05,
      "loss": 0.0518,
      "step": 10090
    },
    {
      "epoch": 10.531803962460897,
      "grad_norm": 0.09763537347316742,
      "learning_rate": 1.2344256391789702e-05,
      "loss": 0.024,
      "step": 10100
    },
    {
      "epoch": 10.5422314911366,
      "grad_norm": 4.772476673126221,
      "learning_rate": 1.231544832553115e-05,
      "loss": 0.1891,
      "step": 10110
    },
    {
      "epoch": 10.552659019812305,
      "grad_norm": 0.11418034881353378,
      "learning_rate": 1.2286640259272597e-05,
      "loss": 0.0304,
      "step": 10120
    },
    {
      "epoch": 10.563086548488009,
      "grad_norm": 0.10439331084489822,
      "learning_rate": 1.2257832193014045e-05,
      "loss": 0.0499,
      "step": 10130
    },
    {
      "epoch": 10.573514077163711,
      "grad_norm": 0.12807606160640717,
      "learning_rate": 1.2229024126755494e-05,
      "loss": 0.0471,
      "step": 10140
    },
    {
      "epoch": 10.583941605839415,
      "grad_norm": 0.08912359178066254,
      "learning_rate": 1.220021606049694e-05,
      "loss": 0.0084,
      "step": 10150
    },
    {
      "epoch": 10.59436913451512,
      "grad_norm": 0.18438155949115753,
      "learning_rate": 1.2171407994238387e-05,
      "loss": 0.1853,
      "step": 10160
    },
    {
      "epoch": 10.604796663190823,
      "grad_norm": 0.1497696340084076,
      "learning_rate": 1.2142599927979834e-05,
      "loss": 0.0322,
      "step": 10170
    },
    {
      "epoch": 10.615224191866528,
      "grad_norm": 0.10523469746112823,
      "learning_rate": 1.2113791861721282e-05,
      "loss": 0.0273,
      "step": 10180
    },
    {
      "epoch": 10.625651720542232,
      "grad_norm": 0.10500717163085938,
      "learning_rate": 1.208498379546273e-05,
      "loss": 0.126,
      "step": 10190
    },
    {
      "epoch": 10.636079249217936,
      "grad_norm": 2.327328681945801,
      "learning_rate": 1.2056175729204178e-05,
      "loss": 0.1406,
      "step": 10200
    },
    {
      "epoch": 10.64650677789364,
      "grad_norm": 20.960031509399414,
      "learning_rate": 1.2027367662945626e-05,
      "loss": 0.0871,
      "step": 10210
    },
    {
      "epoch": 10.656934306569344,
      "grad_norm": 0.11049903929233551,
      "learning_rate": 1.1998559596687074e-05,
      "loss": 0.0847,
      "step": 10220
    },
    {
      "epoch": 10.667361835245046,
      "grad_norm": 0.11009692400693893,
      "learning_rate": 1.1969751530428521e-05,
      "loss": 0.1376,
      "step": 10230
    },
    {
      "epoch": 10.67778936392075,
      "grad_norm": 0.10930431634187698,
      "learning_rate": 1.194094346416997e-05,
      "loss": 0.0347,
      "step": 10240
    },
    {
      "epoch": 10.688216892596454,
      "grad_norm": 0.135453000664711,
      "learning_rate": 1.1912135397911414e-05,
      "loss": 0.043,
      "step": 10250
    },
    {
      "epoch": 10.698644421272158,
      "grad_norm": 0.09416045248508453,
      "learning_rate": 1.1883327331652863e-05,
      "loss": 0.0069,
      "step": 10260
    },
    {
      "epoch": 10.709071949947862,
      "grad_norm": 16.435888290405273,
      "learning_rate": 1.1854519265394311e-05,
      "loss": 0.0494,
      "step": 10270
    },
    {
      "epoch": 10.719499478623566,
      "grad_norm": 0.08717233687639236,
      "learning_rate": 1.1825711199135758e-05,
      "loss": 0.0546,
      "step": 10280
    },
    {
      "epoch": 10.72992700729927,
      "grad_norm": 0.10256084054708481,
      "learning_rate": 1.1796903132877206e-05,
      "loss": 0.0752,
      "step": 10290
    },
    {
      "epoch": 10.740354535974975,
      "grad_norm": 0.09770136326551437,
      "learning_rate": 1.1768095066618655e-05,
      "loss": 0.0917,
      "step": 10300
    },
    {
      "epoch": 10.750782064650679,
      "grad_norm": 1.2732778787612915,
      "learning_rate": 1.1739287000360101e-05,
      "loss": 0.0317,
      "step": 10310
    },
    {
      "epoch": 10.761209593326381,
      "grad_norm": 136.95974731445312,
      "learning_rate": 1.171047893410155e-05,
      "loss": 0.0811,
      "step": 10320
    },
    {
      "epoch": 10.771637122002085,
      "grad_norm": 0.1166747584939003,
      "learning_rate": 1.1681670867842998e-05,
      "loss": 0.0654,
      "step": 10330
    },
    {
      "epoch": 10.782064650677789,
      "grad_norm": 0.4606769382953644,
      "learning_rate": 1.1652862801584443e-05,
      "loss": 0.1396,
      "step": 10340
    },
    {
      "epoch": 10.792492179353493,
      "grad_norm": 0.1396973580121994,
      "learning_rate": 1.1624054735325892e-05,
      "loss": 0.0826,
      "step": 10350
    },
    {
      "epoch": 10.802919708029197,
      "grad_norm": 0.14186792075634003,
      "learning_rate": 1.159524666906734e-05,
      "loss": 0.0327,
      "step": 10360
    },
    {
      "epoch": 10.813347236704901,
      "grad_norm": 0.13370317220687866,
      "learning_rate": 1.1566438602808787e-05,
      "loss": 0.0054,
      "step": 10370
    },
    {
      "epoch": 10.823774765380605,
      "grad_norm": 0.13733656704425812,
      "learning_rate": 1.1537630536550235e-05,
      "loss": 0.1172,
      "step": 10380
    },
    {
      "epoch": 10.83420229405631,
      "grad_norm": 0.15819962322711945,
      "learning_rate": 1.1508822470291684e-05,
      "loss": 0.0088,
      "step": 10390
    },
    {
      "epoch": 10.844629822732012,
      "grad_norm": 0.13826602697372437,
      "learning_rate": 1.148001440403313e-05,
      "loss": 0.1165,
      "step": 10400
    },
    {
      "epoch": 10.855057351407716,
      "grad_norm": 0.14184314012527466,
      "learning_rate": 1.1451206337774579e-05,
      "loss": 0.082,
      "step": 10410
    },
    {
      "epoch": 10.86548488008342,
      "grad_norm": 0.7784100770950317,
      "learning_rate": 1.1422398271516027e-05,
      "loss": 0.0521,
      "step": 10420
    },
    {
      "epoch": 10.875912408759124,
      "grad_norm": 14.528794288635254,
      "learning_rate": 1.1393590205257472e-05,
      "loss": 0.1464,
      "step": 10430
    },
    {
      "epoch": 10.886339937434828,
      "grad_norm": 0.15911921858787537,
      "learning_rate": 1.136478213899892e-05,
      "loss": 0.0274,
      "step": 10440
    },
    {
      "epoch": 10.896767466110532,
      "grad_norm": 0.15528108179569244,
      "learning_rate": 1.1335974072740367e-05,
      "loss": 0.0056,
      "step": 10450
    },
    {
      "epoch": 10.907194994786236,
      "grad_norm": 0.11990748345851898,
      "learning_rate": 1.1307166006481816e-05,
      "loss": 0.1151,
      "step": 10460
    },
    {
      "epoch": 10.91762252346194,
      "grad_norm": 0.12734001874923706,
      "learning_rate": 1.1278357940223264e-05,
      "loss": 0.0719,
      "step": 10470
    },
    {
      "epoch": 10.928050052137642,
      "grad_norm": 10.837762832641602,
      "learning_rate": 1.124954987396471e-05,
      "loss": 0.0574,
      "step": 10480
    },
    {
      "epoch": 10.938477580813347,
      "grad_norm": 0.15140500664710999,
      "learning_rate": 1.122074180770616e-05,
      "loss": 0.1152,
      "step": 10490
    },
    {
      "epoch": 10.94890510948905,
      "grad_norm": 0.20670275390148163,
      "learning_rate": 1.1191933741447608e-05,
      "loss": 0.0791,
      "step": 10500
    },
    {
      "epoch": 10.959332638164755,
      "grad_norm": 0.1880507916212082,
      "learning_rate": 1.1163125675189054e-05,
      "loss": 0.079,
      "step": 10510
    },
    {
      "epoch": 10.969760166840459,
      "grad_norm": 0.9078909754753113,
      "learning_rate": 1.1134317608930501e-05,
      "loss": 0.0431,
      "step": 10520
    },
    {
      "epoch": 10.980187695516163,
      "grad_norm": 0.14720794558525085,
      "learning_rate": 1.1105509542671948e-05,
      "loss": 0.1504,
      "step": 10530
    },
    {
      "epoch": 10.990615224191867,
      "grad_norm": 0.15311670303344727,
      "learning_rate": 1.1076701476413396e-05,
      "loss": 0.0838,
      "step": 10540
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.798904538341158,
      "eval_f1": 0.7040307101727448,
      "eval_loss": 1.1129167079925537,
      "eval_precision": 0.7660818713450293,
      "eval_recall": 0.6512784090909091,
      "eval_roc_auc": 0.7679310429626022,
      "eval_runtime": 13.6618,
      "eval_samples_per_second": 280.636,
      "eval_steps_per_second": 17.567,
      "step": 10549
    },
    {
      "epoch": 11.001042752867571,
      "grad_norm": 0.3144415020942688,
      "learning_rate": 1.1047893410154845e-05,
      "loss": 0.0941,
      "step": 10550
    },
    {
      "epoch": 11.011470281543275,
      "grad_norm": 0.20232492685317993,
      "learning_rate": 1.1019085343896291e-05,
      "loss": 0.0835,
      "step": 10560
    },
    {
      "epoch": 11.021897810218977,
      "grad_norm": 0.1794540137052536,
      "learning_rate": 1.099027727763774e-05,
      "loss": 0.0445,
      "step": 10570
    },
    {
      "epoch": 11.032325338894681,
      "grad_norm": 2.9265387058258057,
      "learning_rate": 1.0961469211379188e-05,
      "loss": 0.0799,
      "step": 10580
    },
    {
      "epoch": 11.042752867570385,
      "grad_norm": 0.16158711910247803,
      "learning_rate": 1.0932661145120635e-05,
      "loss": 0.0062,
      "step": 10590
    },
    {
      "epoch": 11.05318039624609,
      "grad_norm": 0.14832787215709686,
      "learning_rate": 1.0903853078862083e-05,
      "loss": 0.0057,
      "step": 10600
    },
    {
      "epoch": 11.063607924921794,
      "grad_norm": 0.11915760487318039,
      "learning_rate": 1.0875045012603528e-05,
      "loss": 0.0711,
      "step": 10610
    },
    {
      "epoch": 11.074035453597498,
      "grad_norm": 0.11364369839429855,
      "learning_rate": 1.0846236946344977e-05,
      "loss": 0.0045,
      "step": 10620
    },
    {
      "epoch": 11.084462982273202,
      "grad_norm": 0.1213875561952591,
      "learning_rate": 1.0817428880086425e-05,
      "loss": 0.1778,
      "step": 10630
    },
    {
      "epoch": 11.094890510948906,
      "grad_norm": 0.13455939292907715,
      "learning_rate": 1.0788620813827872e-05,
      "loss": 0.1472,
      "step": 10640
    },
    {
      "epoch": 11.10531803962461,
      "grad_norm": 0.13870713114738464,
      "learning_rate": 1.075981274756932e-05,
      "loss": 0.0315,
      "step": 10650
    },
    {
      "epoch": 11.115745568300312,
      "grad_norm": 0.1264488697052002,
      "learning_rate": 1.0731004681310769e-05,
      "loss": 0.0484,
      "step": 10660
    },
    {
      "epoch": 11.126173096976016,
      "grad_norm": 1.4139809608459473,
      "learning_rate": 1.0702196615052215e-05,
      "loss": 0.0805,
      "step": 10670
    },
    {
      "epoch": 11.13660062565172,
      "grad_norm": 0.15553370118141174,
      "learning_rate": 1.0673388548793664e-05,
      "loss": 0.0045,
      "step": 10680
    },
    {
      "epoch": 11.147028154327424,
      "grad_norm": 0.12196748703718185,
      "learning_rate": 1.0644580482535112e-05,
      "loss": 0.0895,
      "step": 10690
    },
    {
      "epoch": 11.157455683003128,
      "grad_norm": 5.90073299407959,
      "learning_rate": 1.0615772416276557e-05,
      "loss": 0.051,
      "step": 10700
    },
    {
      "epoch": 11.167883211678832,
      "grad_norm": 0.10917893052101135,
      "learning_rate": 1.0586964350018005e-05,
      "loss": 0.0271,
      "step": 10710
    },
    {
      "epoch": 11.178310740354537,
      "grad_norm": 0.09702948480844498,
      "learning_rate": 1.0558156283759454e-05,
      "loss": 0.0646,
      "step": 10720
    },
    {
      "epoch": 11.18873826903024,
      "grad_norm": 308.4808044433594,
      "learning_rate": 1.05293482175009e-05,
      "loss": 0.0238,
      "step": 10730
    },
    {
      "epoch": 11.199165797705943,
      "grad_norm": 0.335503488779068,
      "learning_rate": 1.0500540151242349e-05,
      "loss": 0.1005,
      "step": 10740
    },
    {
      "epoch": 11.209593326381647,
      "grad_norm": 0.4090026915073395,
      "learning_rate": 1.0471732084983797e-05,
      "loss": 0.1608,
      "step": 10750
    },
    {
      "epoch": 11.220020855057351,
      "grad_norm": 0.1456325501203537,
      "learning_rate": 1.0442924018725244e-05,
      "loss": 0.0338,
      "step": 10760
    },
    {
      "epoch": 11.230448383733055,
      "grad_norm": 0.4438185691833496,
      "learning_rate": 1.0414115952466693e-05,
      "loss": 0.1616,
      "step": 10770
    },
    {
      "epoch": 11.24087591240876,
      "grad_norm": 0.15481586754322052,
      "learning_rate": 1.0385307886208141e-05,
      "loss": 0.1415,
      "step": 10780
    },
    {
      "epoch": 11.251303441084463,
      "grad_norm": 0.1513419896364212,
      "learning_rate": 1.0356499819949586e-05,
      "loss": 0.052,
      "step": 10790
    },
    {
      "epoch": 11.261730969760167,
      "grad_norm": 0.11044870316982269,
      "learning_rate": 1.0327691753691034e-05,
      "loss": 0.049,
      "step": 10800
    },
    {
      "epoch": 11.272158498435871,
      "grad_norm": 0.1178102195262909,
      "learning_rate": 1.0298883687432481e-05,
      "loss": 0.0602,
      "step": 10810
    },
    {
      "epoch": 11.282586027111574,
      "grad_norm": 0.12873338162899017,
      "learning_rate": 1.027007562117393e-05,
      "loss": 0.0346,
      "step": 10820
    },
    {
      "epoch": 11.293013555787278,
      "grad_norm": 0.11944718658924103,
      "learning_rate": 1.0241267554915378e-05,
      "loss": 0.0758,
      "step": 10830
    },
    {
      "epoch": 11.303441084462982,
      "grad_norm": 0.11197780817747116,
      "learning_rate": 1.0212459488656825e-05,
      "loss": 0.0045,
      "step": 10840
    },
    {
      "epoch": 11.313868613138686,
      "grad_norm": 0.10864785313606262,
      "learning_rate": 1.0183651422398273e-05,
      "loss": 0.1072,
      "step": 10850
    },
    {
      "epoch": 11.32429614181439,
      "grad_norm": 0.17038513720035553,
      "learning_rate": 1.0154843356139721e-05,
      "loss": 0.1055,
      "step": 10860
    },
    {
      "epoch": 11.334723670490094,
      "grad_norm": 0.11145885288715363,
      "learning_rate": 1.0126035289881166e-05,
      "loss": 0.0354,
      "step": 10870
    },
    {
      "epoch": 11.345151199165798,
      "grad_norm": 0.12307509034872055,
      "learning_rate": 1.0097227223622615e-05,
      "loss": 0.1281,
      "step": 10880
    },
    {
      "epoch": 11.355578727841502,
      "grad_norm": 0.2755338251590729,
      "learning_rate": 1.0068419157364061e-05,
      "loss": 0.0538,
      "step": 10890
    },
    {
      "epoch": 11.366006256517206,
      "grad_norm": 0.11857152730226517,
      "learning_rate": 1.003961109110551e-05,
      "loss": 0.031,
      "step": 10900
    },
    {
      "epoch": 11.376433785192908,
      "grad_norm": 0.11913985759019852,
      "learning_rate": 1.0010803024846958e-05,
      "loss": 0.0667,
      "step": 10910
    },
    {
      "epoch": 11.386861313868613,
      "grad_norm": 38.07299041748047,
      "learning_rate": 9.981994958588405e-06,
      "loss": 0.0047,
      "step": 10920
    },
    {
      "epoch": 11.397288842544317,
      "grad_norm": 24.13555335998535,
      "learning_rate": 9.953186892329853e-06,
      "loss": 0.2061,
      "step": 10930
    },
    {
      "epoch": 11.40771637122002,
      "grad_norm": 0.10094108432531357,
      "learning_rate": 9.9243788260713e-06,
      "loss": 0.0042,
      "step": 10940
    },
    {
      "epoch": 11.418143899895725,
      "grad_norm": 0.10039542615413666,
      "learning_rate": 9.895570759812749e-06,
      "loss": 0.0325,
      "step": 10950
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 0.16670067608356476,
      "learning_rate": 9.866762693554195e-06,
      "loss": 0.1255,
      "step": 10960
    },
    {
      "epoch": 11.438998957247133,
      "grad_norm": 0.11730330437421799,
      "learning_rate": 9.837954627295644e-06,
      "loss": 0.1432,
      "step": 10970
    },
    {
      "epoch": 11.449426485922837,
      "grad_norm": 0.11874638497829437,
      "learning_rate": 9.809146561037092e-06,
      "loss": 0.0483,
      "step": 10980
    },
    {
      "epoch": 11.459854014598541,
      "grad_norm": 0.3843066692352295,
      "learning_rate": 9.780338494778539e-06,
      "loss": 0.0222,
      "step": 10990
    },
    {
      "epoch": 11.470281543274243,
      "grad_norm": 0.11169125884771347,
      "learning_rate": 9.751530428519987e-06,
      "loss": 0.0829,
      "step": 11000
    },
    {
      "epoch": 11.480709071949947,
      "grad_norm": 0.5258092880249023,
      "learning_rate": 9.722722362261434e-06,
      "loss": 0.0125,
      "step": 11010
    },
    {
      "epoch": 11.491136600625651,
      "grad_norm": 0.15742629766464233,
      "learning_rate": 9.693914296002882e-06,
      "loss": 0.0866,
      "step": 11020
    },
    {
      "epoch": 11.501564129301356,
      "grad_norm": 0.3265674412250519,
      "learning_rate": 9.665106229744329e-06,
      "loss": 0.0648,
      "step": 11030
    },
    {
      "epoch": 11.51199165797706,
      "grad_norm": 0.11268638074398041,
      "learning_rate": 9.636298163485777e-06,
      "loss": 0.0395,
      "step": 11040
    },
    {
      "epoch": 11.522419186652764,
      "grad_norm": 2.6394386291503906,
      "learning_rate": 9.607490097227224e-06,
      "loss": 0.0824,
      "step": 11050
    },
    {
      "epoch": 11.532846715328468,
      "grad_norm": 0.1020113006234169,
      "learning_rate": 9.578682030968673e-06,
      "loss": 0.1148,
      "step": 11060
    },
    {
      "epoch": 11.543274244004172,
      "grad_norm": 0.10362143069505692,
      "learning_rate": 9.54987396471012e-06,
      "loss": 0.0557,
      "step": 11070
    },
    {
      "epoch": 11.553701772679874,
      "grad_norm": 0.4852520227432251,
      "learning_rate": 9.521065898451568e-06,
      "loss": 0.0047,
      "step": 11080
    },
    {
      "epoch": 11.564129301355578,
      "grad_norm": 0.11180371791124344,
      "learning_rate": 9.492257832193014e-06,
      "loss": 0.0349,
      "step": 11090
    },
    {
      "epoch": 11.574556830031282,
      "grad_norm": 1.6311349868774414,
      "learning_rate": 9.463449765934463e-06,
      "loss": 0.0297,
      "step": 11100
    },
    {
      "epoch": 11.584984358706986,
      "grad_norm": 0.09950597584247589,
      "learning_rate": 9.434641699675911e-06,
      "loss": 0.1573,
      "step": 11110
    },
    {
      "epoch": 11.59541188738269,
      "grad_norm": 0.11255466938018799,
      "learning_rate": 9.405833633417358e-06,
      "loss": 0.0976,
      "step": 11120
    },
    {
      "epoch": 11.605839416058394,
      "grad_norm": 4.800380229949951,
      "learning_rate": 9.377025567158805e-06,
      "loss": 0.0925,
      "step": 11130
    },
    {
      "epoch": 11.616266944734098,
      "grad_norm": 1.3129206895828247,
      "learning_rate": 9.348217500900253e-06,
      "loss": 0.0637,
      "step": 11140
    },
    {
      "epoch": 11.626694473409803,
      "grad_norm": 0.11594114452600479,
      "learning_rate": 9.319409434641701e-06,
      "loss": 0.031,
      "step": 11150
    },
    {
      "epoch": 11.637122002085505,
      "grad_norm": 0.4904272258281708,
      "learning_rate": 9.290601368383148e-06,
      "loss": 0.0517,
      "step": 11160
    },
    {
      "epoch": 11.647549530761209,
      "grad_norm": 12.899497985839844,
      "learning_rate": 9.261793302124595e-06,
      "loss": 0.0819,
      "step": 11170
    },
    {
      "epoch": 11.657977059436913,
      "grad_norm": 0.12791427969932556,
      "learning_rate": 9.232985235866043e-06,
      "loss": 0.0631,
      "step": 11180
    },
    {
      "epoch": 11.668404588112617,
      "grad_norm": 0.12508444488048553,
      "learning_rate": 9.204177169607492e-06,
      "loss": 0.0513,
      "step": 11190
    },
    {
      "epoch": 11.678832116788321,
      "grad_norm": 67.32670593261719,
      "learning_rate": 9.175369103348938e-06,
      "loss": 0.0321,
      "step": 11200
    },
    {
      "epoch": 11.689259645464025,
      "grad_norm": 0.10491731762886047,
      "learning_rate": 9.146561037090385e-06,
      "loss": 0.0874,
      "step": 11210
    },
    {
      "epoch": 11.69968717413973,
      "grad_norm": 1.6496198177337646,
      "learning_rate": 9.117752970831833e-06,
      "loss": 0.0058,
      "step": 11220
    },
    {
      "epoch": 11.710114702815433,
      "grad_norm": 0.10553936660289764,
      "learning_rate": 9.088944904573282e-06,
      "loss": 0.079,
      "step": 11230
    },
    {
      "epoch": 11.720542231491137,
      "grad_norm": 0.1127665787935257,
      "learning_rate": 9.060136838314729e-06,
      "loss": 0.0485,
      "step": 11240
    },
    {
      "epoch": 11.73096976016684,
      "grad_norm": 1.4016437530517578,
      "learning_rate": 9.031328772056175e-06,
      "loss": 0.0733,
      "step": 11250
    },
    {
      "epoch": 11.741397288842544,
      "grad_norm": 0.10676698386669159,
      "learning_rate": 9.002520705797624e-06,
      "loss": 0.0482,
      "step": 11260
    },
    {
      "epoch": 11.751824817518248,
      "grad_norm": 0.11237844079732895,
      "learning_rate": 8.973712639539072e-06,
      "loss": 0.1141,
      "step": 11270
    },
    {
      "epoch": 11.762252346193952,
      "grad_norm": 0.1246412917971611,
      "learning_rate": 8.944904573280519e-06,
      "loss": 0.0315,
      "step": 11280
    },
    {
      "epoch": 11.772679874869656,
      "grad_norm": 0.1157696545124054,
      "learning_rate": 8.916096507021967e-06,
      "loss": 0.045,
      "step": 11290
    },
    {
      "epoch": 11.78310740354536,
      "grad_norm": 0.19559632241725922,
      "learning_rate": 8.887288440763414e-06,
      "loss": 0.0985,
      "step": 11300
    },
    {
      "epoch": 11.793534932221064,
      "grad_norm": 0.1113138496875763,
      "learning_rate": 8.858480374504862e-06,
      "loss": 0.0062,
      "step": 11310
    },
    {
      "epoch": 11.803962460896768,
      "grad_norm": 0.10271282494068146,
      "learning_rate": 8.82967230824631e-06,
      "loss": 0.0293,
      "step": 11320
    },
    {
      "epoch": 11.814389989572472,
      "grad_norm": 0.10670675337314606,
      "learning_rate": 8.800864241987757e-06,
      "loss": 0.0045,
      "step": 11330
    },
    {
      "epoch": 11.824817518248175,
      "grad_norm": 0.09310785681009293,
      "learning_rate": 8.772056175729204e-06,
      "loss": 0.0708,
      "step": 11340
    },
    {
      "epoch": 11.835245046923879,
      "grad_norm": 0.08787614852190018,
      "learning_rate": 8.743248109470653e-06,
      "loss": 0.0302,
      "step": 11350
    },
    {
      "epoch": 11.845672575599583,
      "grad_norm": 0.10181447863578796,
      "learning_rate": 8.714440043212101e-06,
      "loss": 0.0518,
      "step": 11360
    },
    {
      "epoch": 11.856100104275287,
      "grad_norm": 0.0929761454463005,
      "learning_rate": 8.685631976953548e-06,
      "loss": 0.0303,
      "step": 11370
    },
    {
      "epoch": 11.86652763295099,
      "grad_norm": 0.09099478274583817,
      "learning_rate": 8.656823910694996e-06,
      "loss": 0.0302,
      "step": 11380
    },
    {
      "epoch": 11.876955161626695,
      "grad_norm": 0.08819638937711716,
      "learning_rate": 8.628015844436443e-06,
      "loss": 0.0519,
      "step": 11390
    },
    {
      "epoch": 11.887382690302399,
      "grad_norm": 0.06863854080438614,
      "learning_rate": 8.599207778177891e-06,
      "loss": 0.0031,
      "step": 11400
    },
    {
      "epoch": 11.897810218978103,
      "grad_norm": 0.0788901299238205,
      "learning_rate": 8.570399711919338e-06,
      "loss": 0.0438,
      "step": 11410
    },
    {
      "epoch": 11.908237747653805,
      "grad_norm": 0.12830066680908203,
      "learning_rate": 8.541591645660786e-06,
      "loss": 0.0346,
      "step": 11420
    },
    {
      "epoch": 11.91866527632951,
      "grad_norm": 0.864299476146698,
      "learning_rate": 8.512783579402233e-06,
      "loss": 0.033,
      "step": 11430
    },
    {
      "epoch": 11.929092805005213,
      "grad_norm": 0.0585002601146698,
      "learning_rate": 8.483975513143681e-06,
      "loss": 0.0947,
      "step": 11440
    },
    {
      "epoch": 11.939520333680917,
      "grad_norm": 0.11835748702287674,
      "learning_rate": 8.455167446885128e-06,
      "loss": 0.0961,
      "step": 11450
    },
    {
      "epoch": 11.949947862356622,
      "grad_norm": 0.0729990154504776,
      "learning_rate": 8.426359380626576e-06,
      "loss": 0.0743,
      "step": 11460
    },
    {
      "epoch": 11.960375391032326,
      "grad_norm": 0.11193104833364487,
      "learning_rate": 8.397551314368025e-06,
      "loss": 0.0398,
      "step": 11470
    },
    {
      "epoch": 11.97080291970803,
      "grad_norm": 2.2486019134521484,
      "learning_rate": 8.368743248109472e-06,
      "loss": 0.1501,
      "step": 11480
    },
    {
      "epoch": 11.981230448383734,
      "grad_norm": 0.6773170232772827,
      "learning_rate": 8.339935181850918e-06,
      "loss": 0.0084,
      "step": 11490
    },
    {
      "epoch": 11.991657977059436,
      "grad_norm": 0.2496633380651474,
      "learning_rate": 8.311127115592367e-06,
      "loss": 0.0311,
      "step": 11500
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.7955138236828377,
      "eval_f1": 0.7123991195891416,
      "eval_loss": 1.2380515336990356,
      "eval_precision": 0.7367223065250379,
      "eval_recall": 0.6896306818181818,
      "eval_roc_auc": 0.7732984406617701,
      "eval_runtime": 14.0171,
      "eval_samples_per_second": 273.524,
      "eval_steps_per_second": 17.122,
      "step": 11508
    },
    {
      "epoch": 12.00208550573514,
      "grad_norm": 0.08412394672632217,
      "learning_rate": 8.282319049333815e-06,
      "loss": 0.0847,
      "step": 11510
    },
    {
      "epoch": 12.012513034410844,
      "grad_norm": 0.08698565512895584,
      "learning_rate": 8.253510983075262e-06,
      "loss": 0.0948,
      "step": 11520
    },
    {
      "epoch": 12.022940563086548,
      "grad_norm": 0.09949764609336853,
      "learning_rate": 8.224702916816709e-06,
      "loss": 0.0843,
      "step": 11530
    },
    {
      "epoch": 12.033368091762252,
      "grad_norm": 0.11991285532712936,
      "learning_rate": 8.195894850558157e-06,
      "loss": 0.0792,
      "step": 11540
    },
    {
      "epoch": 12.043795620437956,
      "grad_norm": 2.189314365386963,
      "learning_rate": 8.167086784299605e-06,
      "loss": 0.0506,
      "step": 11550
    },
    {
      "epoch": 12.05422314911366,
      "grad_norm": 0.1111144945025444,
      "learning_rate": 8.138278718041052e-06,
      "loss": 0.082,
      "step": 11560
    },
    {
      "epoch": 12.064650677789365,
      "grad_norm": 0.15045487880706787,
      "learning_rate": 8.109470651782499e-06,
      "loss": 0.0368,
      "step": 11570
    },
    {
      "epoch": 12.075078206465069,
      "grad_norm": 8.522217750549316,
      "learning_rate": 8.080662585523947e-06,
      "loss": 0.1124,
      "step": 11580
    },
    {
      "epoch": 12.08550573514077,
      "grad_norm": 0.1324550211429596,
      "learning_rate": 8.051854519265396e-06,
      "loss": 0.0048,
      "step": 11590
    },
    {
      "epoch": 12.095933263816475,
      "grad_norm": 2.222611427307129,
      "learning_rate": 8.023046453006842e-06,
      "loss": 0.1012,
      "step": 11600
    },
    {
      "epoch": 12.106360792492179,
      "grad_norm": 0.11944931745529175,
      "learning_rate": 7.994238386748289e-06,
      "loss": 0.0045,
      "step": 11610
    },
    {
      "epoch": 12.116788321167883,
      "grad_norm": 0.11713391542434692,
      "learning_rate": 7.965430320489737e-06,
      "loss": 0.0533,
      "step": 11620
    },
    {
      "epoch": 12.127215849843587,
      "grad_norm": 0.11463220417499542,
      "learning_rate": 7.936622254231186e-06,
      "loss": 0.0685,
      "step": 11630
    },
    {
      "epoch": 12.137643378519291,
      "grad_norm": 0.2054140716791153,
      "learning_rate": 7.907814187972632e-06,
      "loss": 0.0832,
      "step": 11640
    },
    {
      "epoch": 12.148070907194995,
      "grad_norm": 0.10265359282493591,
      "learning_rate": 7.879006121714081e-06,
      "loss": 0.0045,
      "step": 11650
    },
    {
      "epoch": 12.1584984358707,
      "grad_norm": 0.11477841436862946,
      "learning_rate": 7.850198055455528e-06,
      "loss": 0.0064,
      "step": 11660
    },
    {
      "epoch": 12.168925964546402,
      "grad_norm": 0.11601486057043076,
      "learning_rate": 7.821389989196976e-06,
      "loss": 0.0861,
      "step": 11670
    },
    {
      "epoch": 12.179353493222106,
      "grad_norm": 0.09896566718816757,
      "learning_rate": 7.792581922938424e-06,
      "loss": 0.004,
      "step": 11680
    },
    {
      "epoch": 12.18978102189781,
      "grad_norm": 0.2810088098049164,
      "learning_rate": 7.763773856679871e-06,
      "loss": 0.0266,
      "step": 11690
    },
    {
      "epoch": 12.200208550573514,
      "grad_norm": 0.07913903146982193,
      "learning_rate": 7.734965790421318e-06,
      "loss": 0.0325,
      "step": 11700
    },
    {
      "epoch": 12.210636079249218,
      "grad_norm": 2.8905279636383057,
      "learning_rate": 7.706157724162766e-06,
      "loss": 0.0788,
      "step": 11710
    },
    {
      "epoch": 12.221063607924922,
      "grad_norm": 0.3136194348335266,
      "learning_rate": 7.677349657904215e-06,
      "loss": 0.022,
      "step": 11720
    },
    {
      "epoch": 12.231491136600626,
      "grad_norm": 0.09047019481658936,
      "learning_rate": 7.648541591645661e-06,
      "loss": 0.0763,
      "step": 11730
    },
    {
      "epoch": 12.24191866527633,
      "grad_norm": 0.08630886673927307,
      "learning_rate": 7.619733525387109e-06,
      "loss": 0.1379,
      "step": 11740
    },
    {
      "epoch": 12.252346193952034,
      "grad_norm": 0.15061278641223907,
      "learning_rate": 7.5909254591285565e-06,
      "loss": 0.0085,
      "step": 11750
    },
    {
      "epoch": 12.262773722627736,
      "grad_norm": 0.07924164086580276,
      "learning_rate": 7.562117392870004e-06,
      "loss": 0.0399,
      "step": 11760
    },
    {
      "epoch": 12.27320125130344,
      "grad_norm": 0.08827399462461472,
      "learning_rate": 7.5333093266114524e-06,
      "loss": 0.0289,
      "step": 11770
    },
    {
      "epoch": 12.283628779979145,
      "grad_norm": 0.08253271877765656,
      "learning_rate": 7.5045012603529e-06,
      "loss": 0.0032,
      "step": 11780
    },
    {
      "epoch": 12.294056308654849,
      "grad_norm": 0.2768575847148895,
      "learning_rate": 7.475693194094347e-06,
      "loss": 0.0522,
      "step": 11790
    },
    {
      "epoch": 12.304483837330553,
      "grad_norm": 0.12952695786952972,
      "learning_rate": 7.446885127835794e-06,
      "loss": 0.003,
      "step": 11800
    },
    {
      "epoch": 12.314911366006257,
      "grad_norm": 0.06648633629083633,
      "learning_rate": 7.418077061577243e-06,
      "loss": 0.0402,
      "step": 11810
    },
    {
      "epoch": 12.32533889468196,
      "grad_norm": 0.25009578466415405,
      "learning_rate": 7.38926899531869e-06,
      "loss": 0.0579,
      "step": 11820
    },
    {
      "epoch": 12.335766423357665,
      "grad_norm": 0.23657682538032532,
      "learning_rate": 7.360460929060137e-06,
      "loss": 0.1374,
      "step": 11830
    },
    {
      "epoch": 12.346193952033367,
      "grad_norm": 0.08158320933580399,
      "learning_rate": 7.3316528628015845e-06,
      "loss": 0.0032,
      "step": 11840
    },
    {
      "epoch": 12.356621480709071,
      "grad_norm": 0.08686234056949615,
      "learning_rate": 7.302844796543033e-06,
      "loss": 0.0222,
      "step": 11850
    },
    {
      "epoch": 12.367049009384775,
      "grad_norm": 1.2703416347503662,
      "learning_rate": 7.2740367302844804e-06,
      "loss": 0.0515,
      "step": 11860
    },
    {
      "epoch": 12.37747653806048,
      "grad_norm": 0.07328696548938751,
      "learning_rate": 7.245228664025928e-06,
      "loss": 0.032,
      "step": 11870
    },
    {
      "epoch": 12.387904066736183,
      "grad_norm": 0.07258908450603485,
      "learning_rate": 7.2164205977673756e-06,
      "loss": 0.0715,
      "step": 11880
    },
    {
      "epoch": 12.398331595411888,
      "grad_norm": 0.30953294038772583,
      "learning_rate": 7.187612531508823e-06,
      "loss": 0.0571,
      "step": 11890
    },
    {
      "epoch": 12.408759124087592,
      "grad_norm": 0.07461464405059814,
      "learning_rate": 7.158804465250271e-06,
      "loss": 0.0323,
      "step": 11900
    },
    {
      "epoch": 12.419186652763296,
      "grad_norm": 0.07304571568965912,
      "learning_rate": 7.129996398991719e-06,
      "loss": 0.0029,
      "step": 11910
    },
    {
      "epoch": 12.429614181439,
      "grad_norm": 0.10493344068527222,
      "learning_rate": 7.101188332733166e-06,
      "loss": 0.033,
      "step": 11920
    },
    {
      "epoch": 12.440041710114702,
      "grad_norm": 0.07839164137840271,
      "learning_rate": 7.072380266474613e-06,
      "loss": 0.0861,
      "step": 11930
    },
    {
      "epoch": 12.450469238790406,
      "grad_norm": 2.166057825088501,
      "learning_rate": 7.043572200216061e-06,
      "loss": 0.099,
      "step": 11940
    },
    {
      "epoch": 12.46089676746611,
      "grad_norm": 0.07193010300397873,
      "learning_rate": 7.014764133957509e-06,
      "loss": 0.0322,
      "step": 11950
    },
    {
      "epoch": 12.471324296141814,
      "grad_norm": 0.07878570258617401,
      "learning_rate": 6.985956067698956e-06,
      "loss": 0.0504,
      "step": 11960
    },
    {
      "epoch": 12.481751824817518,
      "grad_norm": 0.08474101126194,
      "learning_rate": 6.9571480014404036e-06,
      "loss": 0.0611,
      "step": 11970
    },
    {
      "epoch": 12.492179353493222,
      "grad_norm": 0.11523758620023727,
      "learning_rate": 6.928339935181851e-06,
      "loss": 0.0932,
      "step": 11980
    },
    {
      "epoch": 12.502606882168926,
      "grad_norm": 0.07409852743148804,
      "learning_rate": 6.8995318689232995e-06,
      "loss": 0.0032,
      "step": 11990
    },
    {
      "epoch": 12.51303441084463,
      "grad_norm": 0.07339435815811157,
      "learning_rate": 6.870723802664747e-06,
      "loss": 0.0666,
      "step": 12000
    },
    {
      "epoch": 12.523461939520335,
      "grad_norm": 0.07443686574697495,
      "learning_rate": 6.841915736406194e-06,
      "loss": 0.003,
      "step": 12010
    },
    {
      "epoch": 12.533889468196037,
      "grad_norm": 0.22585609555244446,
      "learning_rate": 6.813107670147641e-06,
      "loss": 0.0577,
      "step": 12020
    },
    {
      "epoch": 12.544316996871741,
      "grad_norm": 0.06487207114696503,
      "learning_rate": 6.78429960388909e-06,
      "loss": 0.0779,
      "step": 12030
    },
    {
      "epoch": 12.554744525547445,
      "grad_norm": 0.06950891017913818,
      "learning_rate": 6.755491537630537e-06,
      "loss": 0.0505,
      "step": 12040
    },
    {
      "epoch": 12.565172054223149,
      "grad_norm": 0.09879814833402634,
      "learning_rate": 6.726683471371984e-06,
      "loss": 0.0312,
      "step": 12050
    },
    {
      "epoch": 12.575599582898853,
      "grad_norm": 0.06164608895778656,
      "learning_rate": 6.6978754051134324e-06,
      "loss": 0.1567,
      "step": 12060
    },
    {
      "epoch": 12.586027111574557,
      "grad_norm": 0.07995515316724777,
      "learning_rate": 6.66906733885488e-06,
      "loss": 0.087,
      "step": 12070
    },
    {
      "epoch": 12.596454640250261,
      "grad_norm": 0.07638009637594223,
      "learning_rate": 6.6402592725963275e-06,
      "loss": 0.0525,
      "step": 12080
    },
    {
      "epoch": 12.606882168925965,
      "grad_norm": 0.08805584162473679,
      "learning_rate": 6.611451206337776e-06,
      "loss": 0.0554,
      "step": 12090
    },
    {
      "epoch": 12.617309697601668,
      "grad_norm": 0.09561841189861298,
      "learning_rate": 6.582643140079223e-06,
      "loss": 0.0509,
      "step": 12100
    },
    {
      "epoch": 12.627737226277372,
      "grad_norm": 0.09433923661708832,
      "learning_rate": 6.55383507382067e-06,
      "loss": 0.0037,
      "step": 12110
    },
    {
      "epoch": 12.638164754953076,
      "grad_norm": 1.3920536041259766,
      "learning_rate": 6.525027007562118e-06,
      "loss": 0.0595,
      "step": 12120
    },
    {
      "epoch": 12.64859228362878,
      "grad_norm": 0.06902499496936798,
      "learning_rate": 6.496218941303566e-06,
      "loss": 0.003,
      "step": 12130
    },
    {
      "epoch": 12.659019812304484,
      "grad_norm": 0.09059750288724899,
      "learning_rate": 6.467410875045013e-06,
      "loss": 0.0559,
      "step": 12140
    },
    {
      "epoch": 12.669447340980188,
      "grad_norm": 0.23655225336551666,
      "learning_rate": 6.4386028087864604e-06,
      "loss": 0.0497,
      "step": 12150
    },
    {
      "epoch": 12.679874869655892,
      "grad_norm": 0.07998579740524292,
      "learning_rate": 6.409794742527908e-06,
      "loss": 0.048,
      "step": 12160
    },
    {
      "epoch": 12.690302398331596,
      "grad_norm": 2.9253740310668945,
      "learning_rate": 6.380986676269356e-06,
      "loss": 0.1001,
      "step": 12170
    },
    {
      "epoch": 12.700729927007298,
      "grad_norm": 9.369612693786621,
      "learning_rate": 6.352178610010804e-06,
      "loss": 0.0593,
      "step": 12180
    },
    {
      "epoch": 12.711157455683002,
      "grad_norm": 1.3695100545883179,
      "learning_rate": 6.323370543752251e-06,
      "loss": 0.0251,
      "step": 12190
    },
    {
      "epoch": 12.721584984358707,
      "grad_norm": 0.09535671770572662,
      "learning_rate": 6.294562477493698e-06,
      "loss": 0.1179,
      "step": 12200
    },
    {
      "epoch": 12.73201251303441,
      "grad_norm": 0.13459689915180206,
      "learning_rate": 6.265754411235147e-06,
      "loss": 0.0036,
      "step": 12210
    },
    {
      "epoch": 12.742440041710115,
      "grad_norm": 0.12864862382411957,
      "learning_rate": 6.236946344976594e-06,
      "loss": 0.0039,
      "step": 12220
    },
    {
      "epoch": 12.752867570385819,
      "grad_norm": 0.07789556682109833,
      "learning_rate": 6.208138278718041e-06,
      "loss": 0.0033,
      "step": 12230
    },
    {
      "epoch": 12.763295099061523,
      "grad_norm": 0.07756966352462769,
      "learning_rate": 6.179330212459489e-06,
      "loss": 0.0801,
      "step": 12240
    },
    {
      "epoch": 12.773722627737227,
      "grad_norm": 0.6205630898475647,
      "learning_rate": 6.150522146200937e-06,
      "loss": 0.0326,
      "step": 12250
    },
    {
      "epoch": 12.784150156412931,
      "grad_norm": 0.07192735373973846,
      "learning_rate": 6.121714079942384e-06,
      "loss": 0.036,
      "step": 12260
    },
    {
      "epoch": 12.794577685088633,
      "grad_norm": 0.06066823750734329,
      "learning_rate": 6.092906013683833e-06,
      "loss": 0.0628,
      "step": 12270
    },
    {
      "epoch": 12.805005213764337,
      "grad_norm": 0.0675736740231514,
      "learning_rate": 6.0640979474252795e-06,
      "loss": 0.0333,
      "step": 12280
    },
    {
      "epoch": 12.815432742440041,
      "grad_norm": 0.06670640408992767,
      "learning_rate": 6.035289881166727e-06,
      "loss": 0.052,
      "step": 12290
    },
    {
      "epoch": 12.825860271115745,
      "grad_norm": 0.21851380169391632,
      "learning_rate": 6.006481814908175e-06,
      "loss": 0.0627,
      "step": 12300
    },
    {
      "epoch": 12.83628779979145,
      "grad_norm": 0.43186864256858826,
      "learning_rate": 5.977673748649623e-06,
      "loss": 0.0334,
      "step": 12310
    },
    {
      "epoch": 12.846715328467154,
      "grad_norm": 0.2705390155315399,
      "learning_rate": 5.94886568239107e-06,
      "loss": 0.0471,
      "step": 12320
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 0.08207888156175613,
      "learning_rate": 5.920057616132517e-06,
      "loss": 0.0034,
      "step": 12330
    },
    {
      "epoch": 12.867570385818562,
      "grad_norm": 0.08501698821783066,
      "learning_rate": 5.891249549873965e-06,
      "loss": 0.0811,
      "step": 12340
    },
    {
      "epoch": 12.877997914494266,
      "grad_norm": 0.06514862924814224,
      "learning_rate": 5.862441483615413e-06,
      "loss": 0.056,
      "step": 12350
    },
    {
      "epoch": 12.888425443169968,
      "grad_norm": 0.10508106648921967,
      "learning_rate": 5.833633417356861e-06,
      "loss": 0.1141,
      "step": 12360
    },
    {
      "epoch": 12.898852971845672,
      "grad_norm": 0.0730053186416626,
      "learning_rate": 5.8048253510983075e-06,
      "loss": 0.0033,
      "step": 12370
    },
    {
      "epoch": 12.909280500521376,
      "grad_norm": 0.0710534080862999,
      "learning_rate": 5.776017284839756e-06,
      "loss": 0.0331,
      "step": 12380
    },
    {
      "epoch": 12.91970802919708,
      "grad_norm": 0.06870495527982712,
      "learning_rate": 5.7472092185812035e-06,
      "loss": 0.0028,
      "step": 12390
    },
    {
      "epoch": 12.930135557872784,
      "grad_norm": 0.08143248409032822,
      "learning_rate": 5.718401152322651e-06,
      "loss": 0.0779,
      "step": 12400
    },
    {
      "epoch": 12.940563086548488,
      "grad_norm": 0.06971774250268936,
      "learning_rate": 5.689593086064098e-06,
      "loss": 0.0026,
      "step": 12410
    },
    {
      "epoch": 12.950990615224192,
      "grad_norm": 0.07057145237922668,
      "learning_rate": 5.660785019805546e-06,
      "loss": 0.0764,
      "step": 12420
    },
    {
      "epoch": 12.961418143899897,
      "grad_norm": 0.06736313551664352,
      "learning_rate": 5.631976953546994e-06,
      "loss": 0.0087,
      "step": 12430
    },
    {
      "epoch": 12.971845672575599,
      "grad_norm": 0.07734864950180054,
      "learning_rate": 5.603168887288441e-06,
      "loss": 0.0762,
      "step": 12440
    },
    {
      "epoch": 12.982273201251303,
      "grad_norm": 0.06576098501682281,
      "learning_rate": 5.574360821029888e-06,
      "loss": 0.0849,
      "step": 12450
    },
    {
      "epoch": 12.992700729927007,
      "grad_norm": 0.05694691836833954,
      "learning_rate": 5.545552754771336e-06,
      "loss": 0.0272,
      "step": 12460
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.7994261867501304,
      "eval_f1": 0.7171754321441707,
      "eval_loss": 1.2720470428466797,
      "eval_precision": 0.7437070938215103,
      "eval_recall": 0.6924715909090909,
      "eval_roc_auc": 0.7769860015551224,
      "eval_runtime": 14.2487,
      "eval_samples_per_second": 269.078,
      "eval_steps_per_second": 16.844,
      "step": 12467
    },
    {
      "epoch": 13.003128258602711,
      "grad_norm": 0.06631637364625931,
      "learning_rate": 5.516744688512784e-06,
      "loss": 0.0609,
      "step": 12470
    },
    {
      "epoch": 13.013555787278415,
      "grad_norm": 58.12031173706055,
      "learning_rate": 5.4879366222542315e-06,
      "loss": 0.0383,
      "step": 12480
    },
    {
      "epoch": 13.02398331595412,
      "grad_norm": 4.1145453453063965,
      "learning_rate": 5.45912855599568e-06,
      "loss": 0.0343,
      "step": 12490
    },
    {
      "epoch": 13.034410844629823,
      "grad_norm": 0.0642155259847641,
      "learning_rate": 5.430320489737127e-06,
      "loss": 0.0582,
      "step": 12500
    },
    {
      "epoch": 13.044838373305527,
      "grad_norm": 0.07625631988048553,
      "learning_rate": 5.401512423478574e-06,
      "loss": 0.0579,
      "step": 12510
    },
    {
      "epoch": 13.05526590198123,
      "grad_norm": 0.07353261858224869,
      "learning_rate": 5.372704357220022e-06,
      "loss": 0.0554,
      "step": 12520
    },
    {
      "epoch": 13.065693430656934,
      "grad_norm": 0.0864829495549202,
      "learning_rate": 5.34389629096147e-06,
      "loss": 0.1099,
      "step": 12530
    },
    {
      "epoch": 13.076120959332638,
      "grad_norm": 0.067219577729702,
      "learning_rate": 5.315088224702917e-06,
      "loss": 0.0175,
      "step": 12540
    },
    {
      "epoch": 13.086548488008342,
      "grad_norm": 0.17439238727092743,
      "learning_rate": 5.286280158444364e-06,
      "loss": 0.0053,
      "step": 12550
    },
    {
      "epoch": 13.096976016684046,
      "grad_norm": 0.09657325595617294,
      "learning_rate": 5.257472092185813e-06,
      "loss": 0.0601,
      "step": 12560
    },
    {
      "epoch": 13.10740354535975,
      "grad_norm": 0.07477250695228577,
      "learning_rate": 5.22866402592726e-06,
      "loss": 0.1018,
      "step": 12570
    },
    {
      "epoch": 13.117831074035454,
      "grad_norm": 0.08568982779979706,
      "learning_rate": 5.199855959668708e-06,
      "loss": 0.0222,
      "step": 12580
    },
    {
      "epoch": 13.128258602711158,
      "grad_norm": 0.07991164922714233,
      "learning_rate": 5.171047893410155e-06,
      "loss": 0.054,
      "step": 12590
    },
    {
      "epoch": 13.138686131386862,
      "grad_norm": 0.0635628029704094,
      "learning_rate": 5.142239827151603e-06,
      "loss": 0.0419,
      "step": 12600
    },
    {
      "epoch": 13.149113660062564,
      "grad_norm": 0.06740553677082062,
      "learning_rate": 5.113431760893051e-06,
      "loss": 0.0029,
      "step": 12610
    },
    {
      "epoch": 13.159541188738269,
      "grad_norm": 0.06082899495959282,
      "learning_rate": 5.084623694634498e-06,
      "loss": 0.053,
      "step": 12620
    },
    {
      "epoch": 13.169968717413973,
      "grad_norm": 0.07217252999544144,
      "learning_rate": 5.055815628375945e-06,
      "loss": 0.085,
      "step": 12630
    },
    {
      "epoch": 13.180396246089677,
      "grad_norm": 0.07368007302284241,
      "learning_rate": 5.027007562117393e-06,
      "loss": 0.0157,
      "step": 12640
    },
    {
      "epoch": 13.19082377476538,
      "grad_norm": 0.10856736451387405,
      "learning_rate": 4.998199495858841e-06,
      "loss": 0.0297,
      "step": 12650
    },
    {
      "epoch": 13.201251303441085,
      "grad_norm": 0.7115175724029541,
      "learning_rate": 4.969391429600288e-06,
      "loss": 0.0031,
      "step": 12660
    },
    {
      "epoch": 13.211678832116789,
      "grad_norm": 2.0871474742889404,
      "learning_rate": 4.940583363341736e-06,
      "loss": 0.0541,
      "step": 12670
    },
    {
      "epoch": 13.222106360792493,
      "grad_norm": 1.3541232347488403,
      "learning_rate": 4.9117752970831835e-06,
      "loss": 0.0522,
      "step": 12680
    },
    {
      "epoch": 13.232533889468195,
      "grad_norm": 0.8839514851570129,
      "learning_rate": 4.882967230824631e-06,
      "loss": 0.0204,
      "step": 12690
    },
    {
      "epoch": 13.2429614181439,
      "grad_norm": 0.061919327825307846,
      "learning_rate": 4.8541591645660795e-06,
      "loss": 0.0192,
      "step": 12700
    },
    {
      "epoch": 13.253388946819603,
      "grad_norm": 0.37079647183418274,
      "learning_rate": 4.825351098307526e-06,
      "loss": 0.0754,
      "step": 12710
    },
    {
      "epoch": 13.263816475495307,
      "grad_norm": 3.039479970932007,
      "learning_rate": 4.7965430320489746e-06,
      "loss": 0.1105,
      "step": 12720
    },
    {
      "epoch": 13.274244004171011,
      "grad_norm": 0.30662602186203003,
      "learning_rate": 4.767734965790421e-06,
      "loss": 0.0024,
      "step": 12730
    },
    {
      "epoch": 13.284671532846716,
      "grad_norm": 0.6186097264289856,
      "learning_rate": 4.73892689953187e-06,
      "loss": 0.0553,
      "step": 12740
    },
    {
      "epoch": 13.29509906152242,
      "grad_norm": 0.06148029491305351,
      "learning_rate": 4.710118833273316e-06,
      "loss": 0.0332,
      "step": 12750
    },
    {
      "epoch": 13.305526590198124,
      "grad_norm": 0.05977539345622063,
      "learning_rate": 4.681310767014765e-06,
      "loss": 0.0028,
      "step": 12760
    },
    {
      "epoch": 13.315954118873828,
      "grad_norm": 0.1570982038974762,
      "learning_rate": 4.652502700756212e-06,
      "loss": 0.0064,
      "step": 12770
    },
    {
      "epoch": 13.32638164754953,
      "grad_norm": 0.04517459496855736,
      "learning_rate": 4.62369463449766e-06,
      "loss": 0.0344,
      "step": 12780
    },
    {
      "epoch": 13.336809176225234,
      "grad_norm": 0.05839047580957413,
      "learning_rate": 4.5948865682391075e-06,
      "loss": 0.0922,
      "step": 12790
    },
    {
      "epoch": 13.347236704900938,
      "grad_norm": 2.9950220584869385,
      "learning_rate": 4.566078501980555e-06,
      "loss": 0.1187,
      "step": 12800
    },
    {
      "epoch": 13.357664233576642,
      "grad_norm": 0.5343064665794373,
      "learning_rate": 4.537270435722003e-06,
      "loss": 0.0563,
      "step": 12810
    },
    {
      "epoch": 13.368091762252346,
      "grad_norm": 0.12638254463672638,
      "learning_rate": 4.50846236946345e-06,
      "loss": 0.0031,
      "step": 12820
    },
    {
      "epoch": 13.37851929092805,
      "grad_norm": 0.06512785702943802,
      "learning_rate": 4.479654303204898e-06,
      "loss": 0.0638,
      "step": 12830
    },
    {
      "epoch": 13.388946819603754,
      "grad_norm": 0.06933852285146713,
      "learning_rate": 4.450846236946345e-06,
      "loss": 0.0024,
      "step": 12840
    },
    {
      "epoch": 13.399374348279459,
      "grad_norm": 0.06790675967931747,
      "learning_rate": 4.422038170687793e-06,
      "loss": 0.041,
      "step": 12850
    },
    {
      "epoch": 13.40980187695516,
      "grad_norm": 0.06578048318624496,
      "learning_rate": 4.393230104429241e-06,
      "loss": 0.0023,
      "step": 12860
    },
    {
      "epoch": 13.420229405630865,
      "grad_norm": 0.0546039417386055,
      "learning_rate": 4.364422038170688e-06,
      "loss": 0.0446,
      "step": 12870
    },
    {
      "epoch": 13.430656934306569,
      "grad_norm": 0.059913668781518936,
      "learning_rate": 4.335613971912136e-06,
      "loss": 0.0668,
      "step": 12880
    },
    {
      "epoch": 13.441084462982273,
      "grad_norm": 0.0563187375664711,
      "learning_rate": 4.306805905653583e-06,
      "loss": 0.0023,
      "step": 12890
    },
    {
      "epoch": 13.451511991657977,
      "grad_norm": 0.5809781551361084,
      "learning_rate": 4.2779978393950314e-06,
      "loss": 0.0606,
      "step": 12900
    },
    {
      "epoch": 13.461939520333681,
      "grad_norm": 0.06311992555856705,
      "learning_rate": 4.249189773136478e-06,
      "loss": 0.0641,
      "step": 12910
    },
    {
      "epoch": 13.472367049009385,
      "grad_norm": 0.06060809642076492,
      "learning_rate": 4.2203817068779266e-06,
      "loss": 0.0031,
      "step": 12920
    },
    {
      "epoch": 13.48279457768509,
      "grad_norm": 0.05455905199050903,
      "learning_rate": 4.191573640619373e-06,
      "loss": 0.033,
      "step": 12930
    },
    {
      "epoch": 13.493222106360793,
      "grad_norm": 0.06819222122430801,
      "learning_rate": 4.162765574360822e-06,
      "loss": 0.0577,
      "step": 12940
    },
    {
      "epoch": 13.503649635036496,
      "grad_norm": 0.06092970445752144,
      "learning_rate": 4.133957508102268e-06,
      "loss": 0.0826,
      "step": 12950
    },
    {
      "epoch": 13.5140771637122,
      "grad_norm": 0.062147900462150574,
      "learning_rate": 4.105149441843717e-06,
      "loss": 0.0329,
      "step": 12960
    },
    {
      "epoch": 13.524504692387904,
      "grad_norm": 0.06750081479549408,
      "learning_rate": 4.076341375585164e-06,
      "loss": 0.0915,
      "step": 12970
    },
    {
      "epoch": 13.534932221063608,
      "grad_norm": 0.061223968863487244,
      "learning_rate": 4.047533309326612e-06,
      "loss": 0.0542,
      "step": 12980
    },
    {
      "epoch": 13.545359749739312,
      "grad_norm": 0.06944938004016876,
      "learning_rate": 4.0187252430680595e-06,
      "loss": 0.0542,
      "step": 12990
    },
    {
      "epoch": 13.555787278415016,
      "grad_norm": 0.06973593682050705,
      "learning_rate": 3.989917176809507e-06,
      "loss": 0.0668,
      "step": 13000
    },
    {
      "epoch": 13.56621480709072,
      "grad_norm": 1.6044789552688599,
      "learning_rate": 3.9611091105509546e-06,
      "loss": 0.1085,
      "step": 13010
    },
    {
      "epoch": 13.576642335766424,
      "grad_norm": 0.07732395827770233,
      "learning_rate": 3.932301044292402e-06,
      "loss": 0.0046,
      "step": 13020
    },
    {
      "epoch": 13.587069864442126,
      "grad_norm": 0.7081419229507446,
      "learning_rate": 3.90349297803385e-06,
      "loss": 0.0473,
      "step": 13030
    },
    {
      "epoch": 13.59749739311783,
      "grad_norm": 2.111658811569214,
      "learning_rate": 3.874684911775297e-06,
      "loss": 0.114,
      "step": 13040
    },
    {
      "epoch": 13.607924921793535,
      "grad_norm": 0.07074932008981705,
      "learning_rate": 3.845876845516745e-06,
      "loss": 0.0089,
      "step": 13050
    },
    {
      "epoch": 13.618352450469239,
      "grad_norm": 0.05766339600086212,
      "learning_rate": 3.817068779258193e-06,
      "loss": 0.0026,
      "step": 13060
    },
    {
      "epoch": 13.628779979144943,
      "grad_norm": 0.06286754459142685,
      "learning_rate": 3.7882607129996403e-06,
      "loss": 0.051,
      "step": 13070
    },
    {
      "epoch": 13.639207507820647,
      "grad_norm": 0.06407634913921356,
      "learning_rate": 3.759452646741088e-06,
      "loss": 0.0024,
      "step": 13080
    },
    {
      "epoch": 13.64963503649635,
      "grad_norm": 0.05585753172636032,
      "learning_rate": 3.7306445804825355e-06,
      "loss": 0.051,
      "step": 13090
    },
    {
      "epoch": 13.660062565172055,
      "grad_norm": 0.0624222531914711,
      "learning_rate": 3.701836514223983e-06,
      "loss": 0.0506,
      "step": 13100
    },
    {
      "epoch": 13.670490093847757,
      "grad_norm": 0.06799252331256866,
      "learning_rate": 3.6730284479654306e-06,
      "loss": 0.028,
      "step": 13110
    },
    {
      "epoch": 13.680917622523461,
      "grad_norm": 51.03664016723633,
      "learning_rate": 3.644220381706878e-06,
      "loss": 0.0715,
      "step": 13120
    },
    {
      "epoch": 13.691345151199165,
      "grad_norm": 0.06112062558531761,
      "learning_rate": 3.6154123154483257e-06,
      "loss": 0.0021,
      "step": 13130
    },
    {
      "epoch": 13.70177267987487,
      "grad_norm": 0.16762033104896545,
      "learning_rate": 3.5866042491897737e-06,
      "loss": 0.1597,
      "step": 13140
    },
    {
      "epoch": 13.712200208550573,
      "grad_norm": 0.06341483443975449,
      "learning_rate": 3.5577961829312212e-06,
      "loss": 0.0023,
      "step": 13150
    },
    {
      "epoch": 13.722627737226277,
      "grad_norm": 0.05854400619864464,
      "learning_rate": 3.5289881166726688e-06,
      "loss": 0.0511,
      "step": 13160
    },
    {
      "epoch": 13.733055265901982,
      "grad_norm": 0.05693020299077034,
      "learning_rate": 3.5001800504141163e-06,
      "loss": 0.0026,
      "step": 13170
    },
    {
      "epoch": 13.743482794577686,
      "grad_norm": 0.0629592016339302,
      "learning_rate": 3.471371984155564e-06,
      "loss": 0.0025,
      "step": 13180
    },
    {
      "epoch": 13.75391032325339,
      "grad_norm": 0.05372088402509689,
      "learning_rate": 3.4425639178970114e-06,
      "loss": 0.0768,
      "step": 13190
    },
    {
      "epoch": 13.764337851929092,
      "grad_norm": 1.4163663387298584,
      "learning_rate": 3.413755851638459e-06,
      "loss": 0.0598,
      "step": 13200
    },
    {
      "epoch": 13.774765380604796,
      "grad_norm": 0.06593509018421173,
      "learning_rate": 3.3849477853799066e-06,
      "loss": 0.0026,
      "step": 13210
    },
    {
      "epoch": 13.7851929092805,
      "grad_norm": 0.06012088060379028,
      "learning_rate": 3.356139719121354e-06,
      "loss": 0.0021,
      "step": 13220
    },
    {
      "epoch": 13.795620437956204,
      "grad_norm": 0.057459305971860886,
      "learning_rate": 3.327331652862802e-06,
      "loss": 0.0026,
      "step": 13230
    },
    {
      "epoch": 13.806047966631908,
      "grad_norm": 0.05100744217634201,
      "learning_rate": 3.2985235866042492e-06,
      "loss": 0.0437,
      "step": 13240
    },
    {
      "epoch": 13.816475495307612,
      "grad_norm": 1.2689653635025024,
      "learning_rate": 3.269715520345697e-06,
      "loss": 0.0841,
      "step": 13250
    },
    {
      "epoch": 13.826903023983316,
      "grad_norm": 0.062239162623882294,
      "learning_rate": 3.2409074540871448e-06,
      "loss": 0.0023,
      "step": 13260
    },
    {
      "epoch": 13.83733055265902,
      "grad_norm": 0.05359642952680588,
      "learning_rate": 3.2120993878285923e-06,
      "loss": 0.0602,
      "step": 13270
    },
    {
      "epoch": 13.847758081334725,
      "grad_norm": 0.3255148231983185,
      "learning_rate": 3.18329132157004e-06,
      "loss": 0.0517,
      "step": 13280
    },
    {
      "epoch": 13.858185610010427,
      "grad_norm": 0.04842660203576088,
      "learning_rate": 3.1544832553114874e-06,
      "loss": 0.0023,
      "step": 13290
    },
    {
      "epoch": 13.86861313868613,
      "grad_norm": 0.05072200670838356,
      "learning_rate": 3.1256751890529354e-06,
      "loss": 0.0409,
      "step": 13300
    },
    {
      "epoch": 13.879040667361835,
      "grad_norm": 0.26712721586227417,
      "learning_rate": 3.0968671227943825e-06,
      "loss": 0.0335,
      "step": 13310
    },
    {
      "epoch": 13.889468196037539,
      "grad_norm": 0.05172866955399513,
      "learning_rate": 3.0680590565358305e-06,
      "loss": 0.0474,
      "step": 13320
    },
    {
      "epoch": 13.899895724713243,
      "grad_norm": 2.796133279800415,
      "learning_rate": 3.0392509902772777e-06,
      "loss": 0.0977,
      "step": 13330
    },
    {
      "epoch": 13.910323253388947,
      "grad_norm": 0.05508817732334137,
      "learning_rate": 3.0104429240187256e-06,
      "loss": 0.0985,
      "step": 13340
    },
    {
      "epoch": 13.920750782064651,
      "grad_norm": 0.057092003524303436,
      "learning_rate": 2.981634857760173e-06,
      "loss": 0.0327,
      "step": 13350
    },
    {
      "epoch": 13.931178310740355,
      "grad_norm": 0.05893217772245407,
      "learning_rate": 2.9528267915016208e-06,
      "loss": 0.0023,
      "step": 13360
    },
    {
      "epoch": 13.941605839416058,
      "grad_norm": 0.05778670310974121,
      "learning_rate": 2.9240187252430683e-06,
      "loss": 0.0028,
      "step": 13370
    },
    {
      "epoch": 13.952033368091762,
      "grad_norm": 0.08069705218076706,
      "learning_rate": 2.895210658984516e-06,
      "loss": 0.0543,
      "step": 13380
    },
    {
      "epoch": 13.962460896767466,
      "grad_norm": 1.4342666864395142,
      "learning_rate": 2.866402592725964e-06,
      "loss": 0.0824,
      "step": 13390
    },
    {
      "epoch": 13.97288842544317,
      "grad_norm": 0.055511169135570526,
      "learning_rate": 2.837594526467411e-06,
      "loss": 0.0384,
      "step": 13400
    },
    {
      "epoch": 13.983315954118874,
      "grad_norm": 0.0722518265247345,
      "learning_rate": 2.808786460208859e-06,
      "loss": 0.0626,
      "step": 13410
    },
    {
      "epoch": 13.993743482794578,
      "grad_norm": 16.986644744873047,
      "learning_rate": 2.779978393950306e-06,
      "loss": 0.0144,
      "step": 13420
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.7955138236828377,
      "eval_f1": 0.7100591715976331,
      "eval_loss": 1.3090590238571167,
      "eval_precision": 0.7407407407407407,
      "eval_recall": 0.6818181818181818,
      "eval_roc_auc": 0.7716592970096678,
      "eval_runtime": 13.8379,
      "eval_samples_per_second": 277.066,
      "eval_steps_per_second": 17.344,
      "step": 13426
    },
    {
      "epoch": 14.004171011470282,
      "grad_norm": 0.08797567337751389,
      "learning_rate": 2.751170327691754e-06,
      "loss": 0.0022,
      "step": 13430
    },
    {
      "epoch": 14.014598540145986,
      "grad_norm": 0.05963047221302986,
      "learning_rate": 2.7223622614332012e-06,
      "loss": 0.1054,
      "step": 13440
    },
    {
      "epoch": 14.02502606882169,
      "grad_norm": 0.083591990172863,
      "learning_rate": 2.693554195174649e-06,
      "loss": 0.0026,
      "step": 13450
    },
    {
      "epoch": 14.035453597497392,
      "grad_norm": 0.061896808445453644,
      "learning_rate": 2.664746128916097e-06,
      "loss": 0.0867,
      "step": 13460
    },
    {
      "epoch": 14.045881126173096,
      "grad_norm": 0.06568124145269394,
      "learning_rate": 2.6359380626575443e-06,
      "loss": 0.0315,
      "step": 13470
    },
    {
      "epoch": 14.0563086548488,
      "grad_norm": 0.06147250533103943,
      "learning_rate": 2.6071299963989923e-06,
      "loss": 0.0025,
      "step": 13480
    },
    {
      "epoch": 14.066736183524505,
      "grad_norm": 0.06267742067575455,
      "learning_rate": 2.5783219301404394e-06,
      "loss": 0.0025,
      "step": 13490
    },
    {
      "epoch": 14.077163712200209,
      "grad_norm": 0.05403328314423561,
      "learning_rate": 2.5495138638818874e-06,
      "loss": 0.0023,
      "step": 13500
    },
    {
      "epoch": 14.087591240875913,
      "grad_norm": 0.06323903799057007,
      "learning_rate": 2.5207057976233345e-06,
      "loss": 0.0995,
      "step": 13510
    },
    {
      "epoch": 14.098018769551617,
      "grad_norm": 0.05930829048156738,
      "learning_rate": 2.4918977313647825e-06,
      "loss": 0.0312,
      "step": 13520
    },
    {
      "epoch": 14.10844629822732,
      "grad_norm": 0.06591642647981644,
      "learning_rate": 2.46308966510623e-06,
      "loss": 0.0024,
      "step": 13530
    },
    {
      "epoch": 14.118873826903023,
      "grad_norm": 0.06718079745769501,
      "learning_rate": 2.4342815988476776e-06,
      "loss": 0.0527,
      "step": 13540
    },
    {
      "epoch": 14.129301355578727,
      "grad_norm": 0.06264904141426086,
      "learning_rate": 2.405473532589125e-06,
      "loss": 0.0887,
      "step": 13550
    },
    {
      "epoch": 14.139728884254431,
      "grad_norm": 0.05650262162089348,
      "learning_rate": 2.3766654663305727e-06,
      "loss": 0.0024,
      "step": 13560
    },
    {
      "epoch": 14.150156412930135,
      "grad_norm": 0.06461895257234573,
      "learning_rate": 2.3478574000720203e-06,
      "loss": 0.0453,
      "step": 13570
    },
    {
      "epoch": 14.16058394160584,
      "grad_norm": 0.059852201491594315,
      "learning_rate": 2.319049333813468e-06,
      "loss": 0.0866,
      "step": 13580
    },
    {
      "epoch": 14.171011470281544,
      "grad_norm": 0.06345910578966141,
      "learning_rate": 2.2902412675549154e-06,
      "loss": 0.1177,
      "step": 13590
    },
    {
      "epoch": 14.181438998957248,
      "grad_norm": 0.06765900552272797,
      "learning_rate": 2.2614332012963634e-06,
      "loss": 0.0359,
      "step": 13600
    },
    {
      "epoch": 14.191866527632952,
      "grad_norm": 0.09244988858699799,
      "learning_rate": 2.232625135037811e-06,
      "loss": 0.0115,
      "step": 13610
    },
    {
      "epoch": 14.202294056308656,
      "grad_norm": 0.0638335719704628,
      "learning_rate": 2.2038170687792585e-06,
      "loss": 0.0334,
      "step": 13620
    },
    {
      "epoch": 14.212721584984358,
      "grad_norm": 0.06521692126989365,
      "learning_rate": 2.175009002520706e-06,
      "loss": 0.0023,
      "step": 13630
    },
    {
      "epoch": 14.223149113660062,
      "grad_norm": 2.800318479537964,
      "learning_rate": 2.1462009362621536e-06,
      "loss": 0.1344,
      "step": 13640
    },
    {
      "epoch": 14.233576642335766,
      "grad_norm": 0.15102073550224304,
      "learning_rate": 2.117392870003601e-06,
      "loss": 0.0042,
      "step": 13650
    },
    {
      "epoch": 14.24400417101147,
      "grad_norm": 0.08222229033708572,
      "learning_rate": 2.0885848037450487e-06,
      "loss": 0.0176,
      "step": 13660
    },
    {
      "epoch": 14.254431699687174,
      "grad_norm": 0.26862218976020813,
      "learning_rate": 2.0597767374864963e-06,
      "loss": 0.0193,
      "step": 13670
    },
    {
      "epoch": 14.264859228362878,
      "grad_norm": 5.6594343185424805,
      "learning_rate": 2.030968671227944e-06,
      "loss": 0.0036,
      "step": 13680
    },
    {
      "epoch": 14.275286757038582,
      "grad_norm": 2.9754209518432617,
      "learning_rate": 2.0021606049693914e-06,
      "loss": 0.0176,
      "step": 13690
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.057490523904561996,
      "learning_rate": 1.9733525387108394e-06,
      "loss": 0.0306,
      "step": 13700
    },
    {
      "epoch": 14.296141814389989,
      "grad_norm": 1.3364388942718506,
      "learning_rate": 1.944544472452287e-06,
      "loss": 0.0317,
      "step": 13710
    },
    {
      "epoch": 14.306569343065693,
      "grad_norm": 0.046477388590574265,
      "learning_rate": 1.9157364061937345e-06,
      "loss": 0.0021,
      "step": 13720
    },
    {
      "epoch": 14.316996871741397,
      "grad_norm": 0.05629913508892059,
      "learning_rate": 1.886928339935182e-06,
      "loss": 0.0864,
      "step": 13730
    },
    {
      "epoch": 14.327424400417101,
      "grad_norm": 0.05796736851334572,
      "learning_rate": 1.8581202736766296e-06,
      "loss": 0.0293,
      "step": 13740
    },
    {
      "epoch": 14.337851929092805,
      "grad_norm": 0.05803588032722473,
      "learning_rate": 1.8293122074180772e-06,
      "loss": 0.0943,
      "step": 13750
    },
    {
      "epoch": 14.348279457768509,
      "grad_norm": 0.1455284059047699,
      "learning_rate": 1.8005041411595247e-06,
      "loss": 0.0162,
      "step": 13760
    },
    {
      "epoch": 14.358706986444213,
      "grad_norm": 0.06389562785625458,
      "learning_rate": 1.7716960749009723e-06,
      "loss": 0.0023,
      "step": 13770
    },
    {
      "epoch": 14.369134515119917,
      "grad_norm": 0.051460374146699905,
      "learning_rate": 1.7428880086424198e-06,
      "loss": 0.0835,
      "step": 13780
    },
    {
      "epoch": 14.37956204379562,
      "grad_norm": 0.0586121641099453,
      "learning_rate": 1.7140799423838674e-06,
      "loss": 0.0301,
      "step": 13790
    },
    {
      "epoch": 14.389989572471324,
      "grad_norm": 0.053351785987615585,
      "learning_rate": 1.6852718761253154e-06,
      "loss": 0.0024,
      "step": 13800
    },
    {
      "epoch": 14.400417101147028,
      "grad_norm": 129.76348876953125,
      "learning_rate": 1.656463809866763e-06,
      "loss": 0.0115,
      "step": 13810
    },
    {
      "epoch": 14.410844629822732,
      "grad_norm": 0.06276214867830276,
      "learning_rate": 1.6276557436082105e-06,
      "loss": 0.0771,
      "step": 13820
    },
    {
      "epoch": 14.421272158498436,
      "grad_norm": 0.054590534418821335,
      "learning_rate": 1.598847677349658e-06,
      "loss": 0.0384,
      "step": 13830
    },
    {
      "epoch": 14.43169968717414,
      "grad_norm": 0.05868223309516907,
      "learning_rate": 1.5700396110911056e-06,
      "loss": 0.0022,
      "step": 13840
    },
    {
      "epoch": 14.442127215849844,
      "grad_norm": 0.04645071178674698,
      "learning_rate": 1.5412315448325532e-06,
      "loss": 0.0357,
      "step": 13850
    },
    {
      "epoch": 14.452554744525548,
      "grad_norm": 0.05363292992115021,
      "learning_rate": 1.5124234785740007e-06,
      "loss": 0.002,
      "step": 13860
    },
    {
      "epoch": 14.462982273201252,
      "grad_norm": 0.05306261405348778,
      "learning_rate": 1.4836154123154483e-06,
      "loss": 0.0023,
      "step": 13870
    },
    {
      "epoch": 14.473409801876954,
      "grad_norm": 0.05213132128119469,
      "learning_rate": 1.454807346056896e-06,
      "loss": 0.0208,
      "step": 13880
    },
    {
      "epoch": 14.483837330552658,
      "grad_norm": 0.05719625577330589,
      "learning_rate": 1.4259992797983436e-06,
      "loss": 0.0024,
      "step": 13890
    },
    {
      "epoch": 14.494264859228362,
      "grad_norm": 0.05214587599039078,
      "learning_rate": 1.3971912135397914e-06,
      "loss": 0.0019,
      "step": 13900
    },
    {
      "epoch": 14.504692387904067,
      "grad_norm": 0.04367920011281967,
      "learning_rate": 1.368383147281239e-06,
      "loss": 0.0551,
      "step": 13910
    },
    {
      "epoch": 14.51511991657977,
      "grad_norm": 0.22002574801445007,
      "learning_rate": 1.3395750810226865e-06,
      "loss": 0.1059,
      "step": 13920
    },
    {
      "epoch": 14.525547445255475,
      "grad_norm": 0.051675744354724884,
      "learning_rate": 1.310767014764134e-06,
      "loss": 0.002,
      "step": 13930
    },
    {
      "epoch": 14.535974973931179,
      "grad_norm": 0.19101089239120483,
      "learning_rate": 1.2819589485055816e-06,
      "loss": 0.002,
      "step": 13940
    },
    {
      "epoch": 14.546402502606883,
      "grad_norm": 0.05408790335059166,
      "learning_rate": 1.2531508822470292e-06,
      "loss": 0.0318,
      "step": 13950
    },
    {
      "epoch": 14.556830031282587,
      "grad_norm": 0.04829580709338188,
      "learning_rate": 1.2243428159884767e-06,
      "loss": 0.0126,
      "step": 13960
    },
    {
      "epoch": 14.56725755995829,
      "grad_norm": 0.04729308933019638,
      "learning_rate": 1.1955347497299245e-06,
      "loss": 0.002,
      "step": 13970
    },
    {
      "epoch": 14.577685088633993,
      "grad_norm": 0.2471577227115631,
      "learning_rate": 1.166726683471372e-06,
      "loss": 0.0059,
      "step": 13980
    },
    {
      "epoch": 14.588112617309697,
      "grad_norm": 0.04844319820404053,
      "learning_rate": 1.1379186172128196e-06,
      "loss": 0.049,
      "step": 13990
    },
    {
      "epoch": 14.598540145985401,
      "grad_norm": 1.4579381942749023,
      "learning_rate": 1.1091105509542672e-06,
      "loss": 0.0346,
      "step": 14000
    },
    {
      "epoch": 14.608967674661105,
      "grad_norm": 0.054527655243873596,
      "learning_rate": 1.080302484695715e-06,
      "loss": 0.1262,
      "step": 14010
    },
    {
      "epoch": 14.61939520333681,
      "grad_norm": 0.052411407232284546,
      "learning_rate": 1.0514944184371625e-06,
      "loss": 0.0905,
      "step": 14020
    },
    {
      "epoch": 14.629822732012514,
      "grad_norm": 0.040493179112672806,
      "learning_rate": 1.02268635217861e-06,
      "loss": 0.002,
      "step": 14030
    },
    {
      "epoch": 14.640250260688218,
      "grad_norm": 0.052181124687194824,
      "learning_rate": 9.938782859200576e-07,
      "loss": 0.0019,
      "step": 14040
    },
    {
      "epoch": 14.65067778936392,
      "grad_norm": 0.043412480503320694,
      "learning_rate": 9.650702196615054e-07,
      "loss": 0.0019,
      "step": 14050
    },
    {
      "epoch": 14.661105318039624,
      "grad_norm": 0.04400334134697914,
      "learning_rate": 9.362621534029528e-07,
      "loss": 0.0019,
      "step": 14060
    },
    {
      "epoch": 14.671532846715328,
      "grad_norm": 0.04578305035829544,
      "learning_rate": 9.074540871444006e-07,
      "loss": 0.0018,
      "step": 14070
    },
    {
      "epoch": 14.681960375391032,
      "grad_norm": 0.048186786472797394,
      "learning_rate": 8.786460208858481e-07,
      "loss": 0.0112,
      "step": 14080
    },
    {
      "epoch": 14.692387904066736,
      "grad_norm": 0.05170707404613495,
      "learning_rate": 8.498379546272957e-07,
      "loss": 0.0019,
      "step": 14090
    },
    {
      "epoch": 14.70281543274244,
      "grad_norm": 0.145624041557312,
      "learning_rate": 8.210298883687433e-07,
      "loss": 0.0399,
      "step": 14100
    },
    {
      "epoch": 14.713242961418144,
      "grad_norm": 0.049204595386981964,
      "learning_rate": 7.922218221101908e-07,
      "loss": 0.0828,
      "step": 14110
    },
    {
      "epoch": 14.723670490093848,
      "grad_norm": 0.11531251668930054,
      "learning_rate": 7.634137558516386e-07,
      "loss": 0.002,
      "step": 14120
    },
    {
      "epoch": 14.73409801876955,
      "grad_norm": 0.04756966233253479,
      "learning_rate": 7.346056895930861e-07,
      "loss": 0.0019,
      "step": 14130
    },
    {
      "epoch": 14.744525547445255,
      "grad_norm": 7.210785865783691,
      "learning_rate": 7.057976233345337e-07,
      "loss": 0.0939,
      "step": 14140
    },
    {
      "epoch": 14.754953076120959,
      "grad_norm": 25.028879165649414,
      "learning_rate": 6.769895570759812e-07,
      "loss": 0.0735,
      "step": 14150
    },
    {
      "epoch": 14.765380604796663,
      "grad_norm": 1.3982423543930054,
      "learning_rate": 6.481814908174289e-07,
      "loss": 0.102,
      "step": 14160
    },
    {
      "epoch": 14.775808133472367,
      "grad_norm": 0.05400343984365463,
      "learning_rate": 6.193734245588765e-07,
      "loss": 0.0312,
      "step": 14170
    },
    {
      "epoch": 14.786235662148071,
      "grad_norm": 0.07244128733873367,
      "learning_rate": 5.905653583003241e-07,
      "loss": 0.0591,
      "step": 14180
    },
    {
      "epoch": 14.796663190823775,
      "grad_norm": 0.06909967213869095,
      "learning_rate": 5.617572920417717e-07,
      "loss": 0.0345,
      "step": 14190
    },
    {
      "epoch": 14.80709071949948,
      "grad_norm": 0.05590097978711128,
      "learning_rate": 5.329492257832194e-07,
      "loss": 0.002,
      "step": 14200
    },
    {
      "epoch": 14.817518248175183,
      "grad_norm": 0.056236039847135544,
      "learning_rate": 5.041411595246669e-07,
      "loss": 0.155,
      "step": 14210
    },
    {
      "epoch": 14.827945776850886,
      "grad_norm": 0.048432737588882446,
      "learning_rate": 4.753330932661145e-07,
      "loss": 0.0039,
      "step": 14220
    },
    {
      "epoch": 14.83837330552659,
      "grad_norm": 0.05356881394982338,
      "learning_rate": 4.465250270075622e-07,
      "loss": 0.0103,
      "step": 14230
    },
    {
      "epoch": 14.848800834202294,
      "grad_norm": 0.057305000722408295,
      "learning_rate": 4.1771696074900974e-07,
      "loss": 0.0626,
      "step": 14240
    },
    {
      "epoch": 14.859228362877998,
      "grad_norm": 0.04448854923248291,
      "learning_rate": 3.889088944904574e-07,
      "loss": 0.0174,
      "step": 14250
    },
    {
      "epoch": 14.869655891553702,
      "grad_norm": 2.895047187805176,
      "learning_rate": 3.6010082823190496e-07,
      "loss": 0.0194,
      "step": 14260
    },
    {
      "epoch": 14.880083420229406,
      "grad_norm": 0.0638677105307579,
      "learning_rate": 3.3129276197335257e-07,
      "loss": 0.0023,
      "step": 14270
    },
    {
      "epoch": 14.89051094890511,
      "grad_norm": 0.07256577908992767,
      "learning_rate": 3.024846957148002e-07,
      "loss": 0.0036,
      "step": 14280
    },
    {
      "epoch": 14.900938477580814,
      "grad_norm": 0.05066460743546486,
      "learning_rate": 2.736766294562478e-07,
      "loss": 0.0032,
      "step": 14290
    },
    {
      "epoch": 14.911366006256518,
      "grad_norm": 0.054524168372154236,
      "learning_rate": 2.448685631976954e-07,
      "loss": 0.061,
      "step": 14300
    },
    {
      "epoch": 14.92179353493222,
      "grad_norm": 0.054966770112514496,
      "learning_rate": 2.1606049693914298e-07,
      "loss": 0.0127,
      "step": 14310
    },
    {
      "epoch": 14.932221063607924,
      "grad_norm": 0.055793650448322296,
      "learning_rate": 1.872524306805906e-07,
      "loss": 0.0596,
      "step": 14320
    },
    {
      "epoch": 14.942648592283629,
      "grad_norm": 0.05517491698265076,
      "learning_rate": 1.584443644220382e-07,
      "loss": 0.002,
      "step": 14330
    },
    {
      "epoch": 14.953076120959333,
      "grad_norm": 0.05220453813672066,
      "learning_rate": 1.2963629816348578e-07,
      "loss": 0.0367,
      "step": 14340
    },
    {
      "epoch": 14.963503649635037,
      "grad_norm": 0.046169307082891464,
      "learning_rate": 1.0082823190493338e-07,
      "loss": 0.0561,
      "step": 14350
    },
    {
      "epoch": 14.97393117831074,
      "grad_norm": 0.46125340461730957,
      "learning_rate": 7.202016564638099e-08,
      "loss": 0.0094,
      "step": 14360
    },
    {
      "epoch": 14.984358706986445,
      "grad_norm": 0.053263891488313675,
      "learning_rate": 4.321209938782859e-08,
      "loss": 0.0313,
      "step": 14370
    },
    {
      "epoch": 14.994786235662149,
      "grad_norm": 0.05056397244334221,
      "learning_rate": 1.44040331292762e-08,
      "loss": 0.002,
      "step": 14380
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.800208659363589,
      "eval_f1": 0.7179675994108984,
      "eval_loss": 1.3606771230697632,
      "eval_precision": 0.7454128440366973,
      "eval_recall": 0.6924715909090909,
      "eval_roc_auc": 0.7776043032863673,
      "eval_runtime": 14.231,
      "eval_samples_per_second": 269.412,
      "eval_steps_per_second": 16.865,
      "step": 14385
    }
  ],
  "logging_steps": 10,
  "max_steps": 14385,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.51285567943808e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
